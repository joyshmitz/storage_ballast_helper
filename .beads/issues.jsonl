{"id":"bd-112","title":"Multi-channel notification system","description":"## Deliverable\nConfigurable notification system that alerts users through multiple channels when pressure levels change, predictions trigger, or major cleanups happen.\n\n## Notification Channels\n1. Desktop: notify-send (Linux), osascript (macOS) — for interactive users\n2. File: append to /var/lib/sbh/notifications.jsonl — for agents to watch\n3. Journal: systemd journal with structured fields (PRIORITY, SBH_EVENT, SBH_MOUNT)\n4. Webhook: HTTP POST to configurable URL — for Slack/Teams/PagerDuty (simple curl, no deps)\n\n## Configuration\n```toml\n[notifications]\nenabled = true\nchannels = [\"journal\", \"file\"]  # which channels to use\n\n[notifications.desktop]\nenabled = false                  # opt-in (requires display server)\nmin_level = \"orange\"             # only notify at orange+ pressure\n\n[notifications.webhook]\nenabled = false\nurl = \"https://hooks.slack.com/services/...\"\nmin_level = \"red\"\ntemplate = '{\"text\": \"sbh: ${MOUNT} at ${FREE_PCT}% free (${LEVEL})\"}'\n\n[notifications.file]\npath = \"/var/lib/sbh/notifications.jsonl\"\n```\n\n## Notification Events\n- Pressure level change (any transition)\n- Predictive early warning (from predictive action pipeline)\n- Major cleanup completed (>10 items or >10 GB freed)\n- Ballast released or replenished\n- Daemon startup/shutdown\n- Error (circuit breaker, permission denied, etc.)\n\n## Design Rationale\nUsers need to know sbh is working. Without notifications, sbh is invisible — users don't know if it's running, if it prevented a problem, or if it needs attention. The multi-channel approach means every deployment scenario is covered: desktop for dev machines, journal for servers, webhook for team alerting.\n\n## Acceptance Criteria\n- All 4 channels implemented and configurable\n- Desktop notifications work on Linux (notify-send) and macOS (osascript)\n- File notifications are append-only JSONL (same as activity log)\n- Webhook uses simple HTTP POST (no external deps beyond std)\n- Min-level filtering prevents notification spam\n- Notifications include structured data (mount, level, free_pct, action taken)\n- Daemon sends startup notification (\"sbh monitoring 4 volumes\")\n- Unit tests for each channel (mock HTTP for webhook)\n- Integration test: trigger pressure -> verify notification on all channels","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T18:33:48.866465053Z","created_by":"ubuntu","updated_at":"2026-02-15T00:21:35.564205613Z","closed_at":"2026-02-15T00:21:35.564124461Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["daemon"],"dependencies":[{"issue_id":"bd-112","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-112","depends_on_id":"bd-sth","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":237,"issue_id":"bd-112","author":"Dicklesworthstone","text":"REVIEW: Webhook HTTPS implementation — std::net::TcpStream only supports plain HTTP. Options: (1) Shell out to curl (available on all target platforms, zero deps). (2) Add ureq as optional dependency behind 'webhook' feature flag. (3) For MVP, document that webhook URL must be plain HTTP or behind a local reverse proxy. Recommendation: use curl shellout with 10s timeout. curl is universally available, handles HTTPS/TLS natively, and avoids adding a TLS dependency to sbh. Implementation: std::process::Command::new('curl').args(['-s', '-X', 'POST', '-H', 'Content-Type: application/json', '-d', payload, '--max-time', '10', url]).spawn() — fire-and-forget, don't block the daemon.","created_at":"2026-02-14T18:54:01Z"},{"id":238,"issue_id":"bd-112","author":"Dicklesworthstone","text":"REVIEW: Test coverage requirements: (1) Unit test: each channel sends correctly (mock notify-send, mock curl, verify file JSONL format, verify journal structured fields). (2) Unit test: min_level filtering — Orange event with min_level=Red should NOT trigger notification. (3) Integration test: trigger pressure transition -> verify notification appears on all configured channels. (4) Test: webhook timeout (mock server with 15s delay) -> verify daemon is not blocked (fire-and-forget). (5) Test: channel failure (notify-send not found) -> graceful fallback, no daemon crash.","created_at":"2026-02-14T18:54:18Z"},{"id":239,"issue_id":"bd-112","author":"Dicklesworthstone","text":"REVIEW-2: Event subscription path — NotificationSender receives events by subscribing to the ActivityEvent channel (from bd-1gm). The logger thread forwards events matching notification min_level to the NotificationSender via a separate bounded channel. NotificationSender runs in its own thread, consuming events and dispatching to configured channels (notify-send, curl, file append, journal). bd-112 does not need a hard dep on bd-48o — it is wired in at startup by the daemon initialization code.","created_at":"2026-02-14T19:03:44Z"}]}
{"id":"bd-137","title":"Add dropped-event counter to logger for observability","description":"When the logger channel is full, events are silently dropped via try_send(). Add a counter that tracks dropped events and periodically logs a warning so operators know events are being lost. Helps with capacity tuning.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-15T22:50:38.174496242Z","created_by":"ubuntu","updated_at":"2026-02-15T23:10:52.579782931Z","closed_at":"2026-02-15T23:10:52.579690729Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-15l","title":"Daemon should break main loop when scanner/executor exceed respawn limit","description":"When respawn limit exceeded, daemon logs error but continues running without scanner/executor. Should exit cleanly.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T23:56:12.179531912Z","created_by":"ubuntu","updated_at":"2026-02-16T00:04:15.927654850Z","closed_at":"2026-02-16T00:04:15.927640713Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["daemon"]}
{"id":"bd-170","title":"Replace hardcoded LinuxPlatform::new() with detect_platform() in CLI","description":"5 CLI functions use LinuxPlatform::new() directly instead of detect_platform(). Breaks macOS support for clean, emergency, check, status, ballast commands.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T23:56:14.069669197Z","created_by":"ubuntu","updated_at":"2026-02-16T00:04:15.928345773Z","closed_at":"2026-02-16T00:04:15.928323702Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"]}
{"id":"bd-18g","title":"Fix I3 (partial): Wire scoring config update to scanner thread on SIGHUP reload","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T21:24:56.078595139Z","created_by":"ubuntu","updated_at":"2026-02-15T21:26:56.599040029Z","closed_at":"2026-02-15T21:26:56.599021675Z","close_reason":"Fixed: handle_config_reload now sends scoring config update to scanner thread via scan_tx with try_send","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-19l","title":"cli/update clippy bind-instead-of-map micro-fix","description":"Fix clippy::bind_instead_of_map in src/cli/update.rs (sigstore_bundle_contents mapping) with minimal non-architectural change and validate via rch where possible.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T17:32:56.975218502Z","created_by":"ubuntu","updated_at":"2026-02-15T17:33:55.088582956Z","closed_at":"2026-02-15T17:33:55.088565122Z","close_reason":"Completed cli/update bind-instead-of-map micro-fix","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","quality","update"]}
{"id":"bd-1a0","title":"Fix predictive target floor + recursive open-file safety check","description":"Audit-driven fixes: enforce sensible free-space target floor in predictive preemptive cleanup path and make open-file detection cover nested descendants for deletion safety. Add regression tests and validate with rch.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T21:06:14.314791739Z","created_by":"ubuntu","updated_at":"2026-02-15T21:12:50.326987557Z","closed_at":"2026-02-15T21:12:50.326967669Z","close_reason":"Completed: predictive target floor + nested open-file detection with regression tests and rch validation","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1bw","title":"Clippy debt burn-down slice (phase 1): stress/decision-plane early lint blockers","description":"Phase-1 non-overlap cleanup for tests/stress_tests.rs and tests/decision_plane_e2e.rs: resolve early/high-signal lint blockers (similar_names, map_unwrap_or/or_fun_call, collapsible_if, key cast cleanup in upper sections, redundant_clone, early needless_collect, and uninlined format args), preserving behavior. Remaining deep-file cast/too_many_lines lint debt will be split into follow-up slices.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:35:47.832396652Z","created_by":"ubuntu","updated_at":"2026-02-15T16:41:31.045540216Z","closed_at":"2026-02-15T16:41:31.045469002Z","close_reason":"Completed: phase-1 stress/decision-plane test clippy slice resolved and validated","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"],"comments":[{"id":240,"issue_id":"bd-1bw","author":"Dicklesworthstone","text":"Completed phase-1 non-overlap lint cleanup for stress/decision-plane test files.\\n\\nFiles:\\n- tests/stress_tests.rs\\n- tests/decision_plane_e2e.rs\\n\\nWhat was fixed in this phase:\\n- Converted multiple unsafe/lossy cast patterns to checked/index-safe forms and integer math where appropriate.\\n- Replaced map+unwrap_or patterns with map_or_else variants to satisfy clippy.\\n- Collapsed nested if blocks and removed needless collects/redundant clones.\\n- Reworked deterministic RNG float generation in decision_plane_e2e to avoid cast-precision lints (bit-construction approach).\\n- Resolved similar_names/uninlined_format_args findings.\\n- Added targeted  on long scenario tests where splitting would reduce scenario trace readability.\\n\\nValidation:\\n- rch exec \"cargo clippy --test stress_tests --test decision_plane_e2e -- -D warnings\" ✅\\n- rch exec \"cargo test --test stress_tests\" ✅ (12 passed)\\n- rch exec \"cargo test --test decision_plane_e2e\" ✅ (7 passed)\\n- rch exec \"cargo check --all-targets\" ✅\\n- cargo fmt --check ✅\\n- rch exec \"cargo clippy --all-targets -- -D warnings\" ❌ (remaining repo-wide backlog outside this phase slice)","created_at":"2026-02-15T16:41:27Z"}]}
{"id":"bd-1cv","title":"Remove dead ShutdownCoordinator dummy tasks","description":"In daemon/loop_main.rs shutdown(), the ShutdownCoordinator is invoked with dummy tasks that always return true. The real thread joining happens independently after. Remove the dead coordinator call.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-16T00:15:46.460700906Z","created_by":"ubuntu","updated_at":"2026-02-16T00:17:56.798384860Z","closed_at":"2026-02-16T00:17:56.798322032Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["P2","audit"]}
{"id":"bd-1f1","title":"Guard ballast size CLI calculation against integer overflow","status":"closed","priority":0,"issue_type":"bug","created_at":"2026-02-15T22:40:16.988979700Z","created_by":"ubuntu","updated_at":"2026-02-15T22:41:40.921708719Z","closed_at":"2026-02-15T22:41:40.921687109Z","close_reason":"Used checked_mul() for CLI ballast_size MB-to-bytes conversion with CliError::User on overflow; saturating_mul for dry-run display calculation","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1fr","title":"sbh clean command: manual cleanup with confirmation and dry-run","description":"## Deliverable\nCommand to manually trigger cleanup of build artifacts, with interactive confirmation, dry-run mode, and configurable aggressiveness.\n\n## Technical Approach\n### Usage\n```bash\nsbh clean                     # Interactive cleanup with confirmation\nsbh clean --yes               # Skip confirmation (for automation)\nsbh clean --dry-run            # Show what would be deleted\nsbh clean --min-score 0.8     # Only delete high-confidence candidates\nsbh clean --max-items 10      # Delete at most 10 items\nsbh clean --max-size 50G      # Free at most 50 GB\nsbh clean --target-free 20    # Clean until 20% free space achieved\nsbh clean /tmp                # Clean only specific path\nsbh clean --json              # Machine-readable output\n```\n\n### Interactive Confirmation\n```\nThe following items will be deleted:\n\n  1. /tmp/cargo-target-quietwillow-mvcc (4.2 GB, score 0.94, 6h old)\n  2. /data/projects/pi/.target_opus_main (8.1 GB, score 0.91, 4h old)\n  3. /data/tmp/cargo-target (12.4 GB, score 0.89, 3h old)\n\nTotal: 3 items, 24.7 GB\n\nProceed with deletion? [y/N/a(ll)/s(kip)/q(uit)]\n  y - delete this item and continue\n  n - skip this item and continue\n  a - delete all remaining items without asking\n  s - skip all remaining items\n  q - quit without deleting anything\n```\n\n### Automation Mode (--yes)\nFor use by agents and scripts: skip confirmation, delete everything above threshold.\n\n### Dry-Run Mode\nComplete pipeline except actual deletion. Produces full report of what would be done.\n\n### Stop Conditions\nCleanup stops when ANY of these are met:\n- All candidates exhausted\n- --max-items reached\n- --max-size of bytes freed\n- --target-free percentage achieved\n- User quits interactive mode\n\n## Acceptance Criteria\n- Interactive mode correctly handles all responses (y/n/a/s/q)\n- --yes mode works without TTY (for automation)\n- --dry-run produces same report as real run\n- Stop conditions correctly enforced\n- All deletions logged to activity database\n- Post-cleanup summary shows actual bytes freed\n- Error handling: failed deletion doesn't stop the process\n- Unit tests for interaction logic\n- Integration test: create test artifacts → clean → verify deleted","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T16:53:19.894435037Z","created_by":"ubuntu","updated_at":"2026-02-14T21:50:56.174426632Z","closed_at":"2026-02-14T21:50:56.174359386Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"],"dependencies":[{"issue_id":"bd-1fr","depends_on_id":"bd-1hh","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-1fr","depends_on_id":"bd-1w9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-1fr","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":241,"issue_id":"bd-1fr","author":"Dicklesworthstone","text":"MINOR: sbh clean should respect the protection system (bd-3qm). When displaying candidates, protected directories should appear with [PROTECTED] label and be excluded from deletion. The clean command shares the walker (bd-1w9) which already integrates protection, so this happens automatically — but the clean command's output should explicitly mention 'N directories protected (use sbh protect --list to see)' when protected dirs are encountered.","created_at":"2026-02-14T18:55:05Z"}]}
{"id":"bd-1gm","title":"Dual-write coordinator: atomic SQLite + JSONL logging","description":"## Deliverable\nCoordinator that writes every event to BOTH SQLite and JSONL, with graceful degradation if either backend fails.\n\n## Technical Approach\n### ActivityLogger\n```rust\npub struct ActivityLogger {\n    sqlite: Option<SqliteLogger>,    // None if SQLite unavailable\n    jsonl: JsonlWriter,              // always available (fallback to stderr)\n    event_count: AtomicU64,\n    bytes_logged: AtomicU64,\n}\n\nimpl ActivityLogger {\n    pub fn log_event(&self, event: ActivityEvent) -> Result<(), SbhError>;\n    pub fn log_deletion(&self, deletion: &DeletionReport) -> Result<(), SbhError>;\n    pub fn log_pressure_change(&self, from: PressureLevel, to: PressureLevel, reading: &PressureReading) -> Result<(), SbhError>;\n    pub fn log_ballast_action(&self, action: &BallastAction) -> Result<(), SbhError>;\n}\n```\n\n### Atomic Write Strategy\n1. Write to JSONL first (always succeeds unless disk is truly full)\n2. Write to SQLite second\n3. If SQLite fails: log warning, continue JSONL-only, attempt SQLite reconnect periodically\n4. If JSONL fails: log to stderr, attempt JSONL reopen\n5. If BOTH fail: log to stderr only (last resort)\n\n### Event Types\n```rust\npub enum ActivityEvent {\n    DaemonStarted { version: String, config_hash: String },\n    DaemonStopped { reason: String, uptime: Duration },\n    PressureChanged { from: PressureLevel, to: PressureLevel, reading: PressureReading },\n    BallastReleased { files: Vec<PathBuf>, bytes_freed: u64 },\n    BallastReplenished { files: Vec<PathBuf>, bytes_used: u64 },\n    ArtifactDeleted { path: PathBuf, size: u64, score: f64, factors: ScoreFactors },\n    ArtifactDeletionFailed { path: PathBuf, error: String },\n    ScanCompleted { paths_scanned: usize, candidates_found: usize, duration: Duration },\n    SpecialLocationAlert { path: PathBuf, free_pct: f64, threshold: f64 },\n    ConfigReloaded { changes: Vec<String> },\n    Error { code: String, message: String, context: String },\n}\n```\n\n### Thread Safety\nThe logger must be safely shareable across the monitoring loop, scanner, and deletion executor threads. Use Arc<ActivityLogger> with internal synchronization (Mutex for SQLite, atomic file append for JSONL).\n\n## Acceptance Criteria\n- Every event written to both backends (when both available)\n- SQLite failure doesn't stop JSONL logging\n- JSONL failure doesn't stop SQLite logging\n- Both fail → stderr fallback\n- Thread-safe concurrent logging from multiple components\n- Event serialization is consistent between SQLite and JSONL\n- Unit tests for all degradation modes\n- Integration test: simulate SQLite failure → verify JSONL continues","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:49:49.429565237Z","created_by":"ubuntu","updated_at":"2026-02-14T19:54:05.614287017Z","closed_at":"2026-02-14T19:54:05.614265587Z","close_reason":"Dual-write coordinator implemented in src/logger/dual.rs: ActivityLoggerHandle with bounded crossbeam channel (try_send non-blocking), dedicated logger thread owning SQLite+JSONL, ActivityEvent enum with all event types, event-to-LogEntry/ActivityRow/PressureRow conversions, graceful degradation (3 SQLite failures→disable), dropped-events counter, graceful shutdown, 5 passing tests.","source_repo":".","compaction_level":0,"original_size":0,"labels":["logger"],"dependencies":[{"issue_id":"bd-1gm","depends_on_id":"bd-2f8","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-1gm","depends_on_id":"bd-394","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":242,"issue_id":"bd-1gm","author":"Dicklesworthstone","text":"REVIEW: The logger's thread-safety design is critical. Key decisions:\n\n1. NEVER block the monitoring loop for logging. Use try_send() on the logger channel, not send(). If the channel is full (1024 events buffered), DROP the event and increment a dropped_events counter. Log a warning about dropped events at the next successful write.\n\n2. SQLite access must be serialized (single writer). Use a dedicated logger thread that owns the Connection. All other threads send ActivityEvent through the channel. The logger thread is the ONLY thread that touches SQLite.\n\n3. JSONL writes use Mutex<BufWriter<File>> — but since all writes go through the logger thread, this is mostly for the flush() call which might happen from the shutdown sequence on a different thread.\n\n4. The ActivityLogger exposed to other threads is an Arc<ActivityLoggerHandle> that contains just the crossbeam Sender. It's Clone and Send, so any thread can log events.","created_at":"2026-02-14T17:15:16Z"},{"id":243,"issue_id":"bd-1gm","author":"Dicklesworthstone","text":"REVIEW-2: API clarification — the public API is ActivityLoggerHandle with a single method: send(event: ActivityEvent). Internally it calls try_send() on a crossbeam bounded channel. The ActivityLogger struct (with SQLite connection + BufWriter) is PRIVATE to the logger thread. The description's log_event/log_deletion/log_pressure_change are convenience constructors for ActivityEvent variants, NOT methods on the logger itself. E.g.: fn log_deletion(handle: &ActivityLoggerHandle, report: &DeletionReport) { handle.send(ActivityEvent::ArtifactDeleted { ... }); }","created_at":"2026-02-14T19:03:37Z"}]}
{"id":"bd-1hh","title":"Ranked deletion executor with safety checks and dry-run mode","description":"## Deliverable\nThe component that takes ranked deletion candidates from the scoring engine and actually deletes them, with comprehensive safety checks, dry-run mode, and detailed logging.\n\n## Technical Approach\n### Deletion Pipeline\n```\nScored candidates → Sort by score desc → Apply threshold → Safety pre-flight\n→ Delete batch → Log results → Re-measure pressure → Decide continue/stop\n```\n\n### DeletionExecutor\n```rust\npub struct DeletionExecutor {\n    config: ScannerConfig,\n    logger: Arc<ActivityLogger>,\n    dry_run: bool,\n}\n\npub struct DeletionPlan {\n    pub candidates: Vec<CandidacyScore>,\n    pub total_reclaimable_bytes: u64,\n    pub estimated_items: usize,\n    pub pressure_before: PressureReading,\n}\n\npub struct DeletionReport {\n    pub items_deleted: usize,\n    pub items_failed: usize,\n    pub items_skipped: usize,\n    pub bytes_freed: u64,\n    pub duration: Duration,\n    pub errors: Vec<DeletionError>,\n    pub pressure_after: PressureReading,\n}\n\npub struct DeletionError {\n    pub path: PathBuf,\n    pub error: SbhError,\n    pub recoverable: bool,\n}\n```\n\n### Safety Pre-Flight Checks (before each deletion)\n1. Re-verify the path still exists (might have been cleaned by another process)\n2. Re-check that the path is not currently open by any process (Linux: check /proc/*/fd)\n3. Re-verify age hasn't changed (file might have been touched/rebuilt since scanning)\n4. Verify we have write permission to the parent directory\n5. If directory, check it doesn't contain .git/ (final safety net)\n\n### Batch Deletion Strategy\nDon't delete everything at once:\n- Delete in batches of max_delete_batch (from PressureResponse, typically 5-20)\n- After each batch, re-measure free space\n- If pressure has dropped below threshold, STOP deleting\n- This prevents over-deletion when the first few deletions free enough space\n\n### Dry-Run Mode\nWhen dry_run=true:\n- Run entire pipeline including scoring and ranking\n- Log what WOULD be deleted with full details\n- Don't actually delete anything\n- Useful for testing and tuning scoring weights\n\n### Deletion Method\nFor directories (most common): rm_dir_all equivalent\nFor files: std::fs::remove_file\nBoth with error handling that continues on failure (log and move to next candidate)\n\n### Circuit Breaker (Alien Graveyard: resilience pattern)\nIf more than 3 consecutive deletions fail:\n- Pause deletion for 30 seconds\n- Log circuit breaker activation\n- After cooldown, retry with just 1 item\n- If that also fails, escalate to error reporting and stop\n\nThis prevents thrashing when, e.g., a filesystem goes read-only.\n\n### Post-Deletion Verification\nAfter deleting a batch:\n- Verify the paths actually disappeared (paranoia check)\n- Re-measure free space to confirm we gained what we expected\n- Log discrepancy if freed bytes don't match expectations (CoW filesystem?)\n\n## Acceptance Criteria\n- Candidates deleted in score-descending order (most obvious artifacts first)\n- Pre-flight checks prevent deletion of in-use or critical files\n- Batch strategy prevents over-deletion\n- Dry-run mode produces identical scoring without deleting\n- Circuit breaker activates on consecutive failures\n- All deletions logged with full context (path, size, score, reason)\n- Post-deletion verification confirms space was freed\n- Error recovery: single failed deletion doesn't stop the process\n- Unit tests with temp directory trees\n- Integration test: create artifacts → score → delete → verify space freed","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:48:46.218524146Z","created_by":"ubuntu","updated_at":"2026-02-14T20:03:33.648777443Z","closed_at":"2026-02-14T20:03:33.648754049Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["scanner"],"dependencies":[{"issue_id":"bd-1hh","depends_on_id":"bd-1gm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-1hh","depends_on_id":"bd-x9z","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":244,"issue_id":"bd-1hh","author":"Dicklesworthstone","text":"REVIEW: The open-file check (checking if a file/directory is in use by a process) is one of the most important safety mechanisms. Implementation detail:\n\nLinux: Read /proc/*/fd symlinks. For each process, readlink() each fd. If any fd points to a path under the candidate directory, the candidate is \"open\" and gets a hard veto.\n\nPERFORMANCE CONCERN: Scanning /proc/*/fd for every deletion candidate is O(processes × fd_per_process). On a machine with 100+ agent processes, each with 100+ open fds, this is 10K+ readlink() calls per candidate. Mitigations:\n1. Cache the open-file set: collect ALL open paths once per scan cycle, store in a HashSet, then do O(1) lookups\n2. Use /proc/<pid>/maps as a secondary check (maps shows memory-mapped files)\n3. Rate-limit: only refresh the open-file cache every N seconds (default 5s)\n4. Under extreme pressure (Critical), SKIP the open-file check for non-.git, non-system paths (the daemon itself can't afford to scan /proc when the disk is about to fill up)\n\nThe is_open flag is computed by the CALLER (main loop or CLI clean command) and passed to the scoring engine as part of ScoringInput. The scoring engine itself never touches /proc.","created_at":"2026-02-14T17:14:24Z"},{"id":245,"issue_id":"bd-1hh","author":"Dicklesworthstone","text":"REVIEW: Clarification on /proc/*/fd open-file check vs scorer is_open flag: The scorer (bd-x9z) takes is_open: bool as input. The WALKER (bd-1w9) is responsible for checking /proc/*/fd during traversal and setting this flag on ScoringInput. The deletion executor (bd-1hh) does a SECOND /proc check as a pre-flight safety re-verification — this is NOT redundant because time may have passed between scoring and deletion (the candidate might have been opened since scoring). The re-check is a last-moment safety net. Keep it.","created_at":"2026-02-14T18:54:26Z"}]}
{"id":"bd-1hz","title":"Clippy micro-slice: cli_app straightforward lint cleanup","description":"Clear straightforward clippy lints in src/cli_app.rs without architectural refactors: redundant_clone sites, match_same_arms in parse_window_duration, and simple option mapping cleanup. Validate with rch.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T17:01:13.537259028Z","created_by":"ubuntu","updated_at":"2026-02-15T19:25:13.994005383Z","closed_at":"2026-02-15T19:25:13.993981097Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"]}
{"id":"bd-1k0","title":"Offline bundle preflight bypasses sigstore verification","description":"run_bundle_preflight and update verification pass SigstorePolicy::Disabled even when sigstore bundle metadata exists, leaving checksum-in-bundle as sole trust root.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T16:39:57.229617848Z","created_by":"ubuntu","updated_at":"2026-02-15T16:53:59.481527035Z","closed_at":"2026-02-15T16:53:59.481508841Z","close_reason":"Completed: enforce sigstore for offline bundle preflight/update when sigstore bundle metadata exists; added regression tests and validation.","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli","security","supply-chain"]}
{"id":"bd-1kn","title":"Project scaffolding: Cargo.toml, workspace structure, rust-toolchain.toml","description":"Set up the complete Rust project structure for storage_ballast_helper (sbh).\n\n## Technical Approach\n- Create Cargo.toml with edition = \"2024\", binary name = \"sbh\"\n- Create rust-toolchain.toml targeting STABLE (edition 2024 is stable since Rust 1.85, Jan 2025)\n- Set up directory structure: src/{main.rs, lib.rs, cli/, core/, monitor/, ballast/, scanner/, logger/, daemon/, platform/}\n- Configure release profile for size optimization: opt-level=\"z\", lto=true, codegen-units=1, panic=\"abort\", strip=true\n- Add #![forbid(unsafe_code)] to lib.rs\n- Enable pedantic + nursery clippy lints\n\n## Key Dependencies (initial)\n- clap (derive) for CLI\n- serde + serde_json for serialization\n- rusqlite (bundled) for SQLite logging\n- toml for configuration parsing\n- thiserror for error derives\n- colored for terminal output\n- chrono for timestamps\n- nix (Linux) / core-foundation (macOS) for platform-specific ops\n- parking_lot for efficient locks\n- crossbeam-channel for thread communication\n- memchr for fast byte scanning\n- regex for artifact pattern matching (bd-1sw)\n- signal-hook for safe signal handling (bd-2s9)\n- rand for ballast file random data generation (bd-25g)\n\n## Design Rationale\nFollowing asupersync's pattern: NO tokio dependency. Use std threads + crossbeam channels for the daemon monitoring loop. This keeps the binary small, startup fast, and avoids async runtime complexity for what is fundamentally a polling-based system daemon.\n\n## Acceptance Criteria\n- `cargo check` passes with zero warnings\n- `cargo clippy --all-targets -- -D warnings` passes\n- Binary compiles to < 5MB release size\n- Project structure mirrors the modular architecture described in the design","acceptance_criteria":"1. Cargo workspace and module layout compile cleanly with Rust 2024 toolchain and strict lint gates. 2. Baseline test harness is scaffolded: unit-test module structure plus e2e script entrypoint with verbose logging hooks. 3. Build profiles and forbid-unsafe policy are enforced in root configuration. 4. Core dependency set supports scanner/daemon/CLI architecture without placeholder shims. 5. Foundation docs describe how new modules register tests and structured logs.","notes":"Progress update: implemented crate-level unsafe forbids, baseline integration harness (tests/common + tests/integration_tests), executable scripts/e2e_test.sh with verbose case logs, and docs/testing-and-logging.md. Verified: cargo fmt --check, cargo check --all-targets, cargo test --test integration_tests, ./scripts/e2e_test.sh. Status remains in_progress until repository-wide clippy -D warnings debt (pre-existing across multiple modules) is resolved.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:43:36.253025401Z","created_by":"ubuntu","updated_at":"2026-02-14T19:46:06.022861156Z","closed_at":"2026-02-14T19:46:06.022841960Z","close_reason":"Complete","source_repo":".","compaction_level":0,"original_size":0,"labels":["foundation"],"comments":[{"id":246,"issue_id":"bd-1kn","author":"Dicklesworthstone","text":"REVIEW: Fixed two issues: (1) Added missing dependencies: regex (for bd-1sw pattern matching), signal-hook (for bd-2s9 signal handling), rand (for bd-25g ballast random data). These were referenced by downstream beads but not listed in the scaffolding bead's dep list. (2) Changed 'targeting nightly' to 'targeting STABLE' — edition 2024 has been stable since Rust 1.85 (Jan 2025). No reason to use nightly.","created_at":"2026-02-14T17:12:35Z"},{"id":247,"issue_id":"bd-1kn","author":"Dicklesworthstone","text":"=== BEAD REVIEW SESSION COMPLETE (2026-02-14) ===\n\nSummary of all revisions made across the 36-bead graph:\n\nSTRUCTURAL FIX:\n- Removed bd-x9z → bd-2pj dependency (scoring engine is pure computation, shouldn't depend on fs stats collector)\n\nBEAD ENHANCEMENTS (via comments with implementation guidance):\n- bd-1kn: Added missing deps (regex, signal-hook, rand). Fixed edition 2024 → stable channel\n- bd-x9z: Full description rewrite. Established pure-computation contract (zero I/O). Added ScoringInput struct with explicit now timestamp and is_open flag for determinism\n- bd-1w9: Walker must collect structural_markers during traversal for scoring engine\n- bd-25g: Added fallocate() optimization for ext4/xfs (instant vs 25-50s). Added file locking for concurrent daemon/CLI access\n- bd-48o: Added bounded channel sizing, backpressure strategy, thread panic recovery (3 strikes in 5 min → stop respawning)\n- bd-7ls: Clarified role: cross-cutting test infrastructure + coverage verification + gap-filling (not duplicate of per-module tests)\n- bd-1sw: Added error handling for invalid custom regex patterns from config\n- bd-394: Strengthened 4-level fallback chain (file → fallback_path → stderr → discard). write_all() for atomic lines\n- bd-2q9: Added 8 more E2E test cases (signals, concurrency, determinism, perf)\n- bd-2s9: Noted signal-hook crate dependency in Cargo.toml\n- bd-1hh: Added /proc/*/fd open-file check performance analysis and caching strategy\n- bd-3qw: Added PID controller config section and special locations config section\n- bd-2np: Defined state.json format, atomic writes, staleness detection\n- bd-224: Added cross-mount ballast edge case (ballast must be on same FS as pressure)\n- bd-1gm: Added try_send() non-blocking logging design, dedicated logger thread owns SQLite\n- bd-26g: Fixed ReadWritePaths conflict with ProtectHome=read-only\n- bd-2f8: Added startup check that SQLite db is NOT on monitored filesystem\n\nGRAPH HEALTH (post-review):\n- 36 nodes, 64 edges, 0 cycles\n- Critical path length: 11 (unchanged)\n- 1 ready bead (bd-1kn)\n- 4 articulation points\n- bd-48o remains the key bottleneck (unavoidable — it's the integration point)","created_at":"2026-02-14T17:16:49Z"},{"id":248,"issue_id":"bd-1kn","author":"Dicklesworthstone","text":"REVIEW: Additional dependency needed for TUI dashboard (bd-3s5): crossterm crate for terminal manipulation. This is NOT needed in initial scaffolding — add crossterm as an optional dependency gated behind a 'tui' feature flag: [features] tui = ['dep:crossterm', 'dep:unicode-width']. This way the core binary stays small and the dashboard is opt-in at compile time.","created_at":"2026-02-14T18:53:56Z"},{"id":249,"issue_id":"bd-1kn","author":"Dicklesworthstone","text":"MINOR: Time handling convention — use std::time::SystemTime and std::time::Duration throughout the codebase. chrono is in the dependency list but should ONLY be used for user-facing formatting (display, log timestamps, JSON serialization). All internal calculations, comparisons, and storage should use SystemTime/Duration. This avoids chrono's heavier API surface for simple elapsed-time checks.","created_at":"2026-02-14T18:54:41Z"},{"id":250,"issue_id":"bd-1kn","author":"Dicklesworthstone","text":"REVIEW-2: Additional dependency: toml_edit crate for config file modification preserving formatting/comments. Required by bd-7vl (sbh tune --apply). Add as optional dependency behind a feature flag if desired.","created_at":"2026-02-14T19:03:22Z"}]}
{"id":"bd-1l7","title":"Replace unreliable permissions().readonly() with access(W_OK)","description":"In deletion.rs preflight_check uses permissions().readonly() which only checks if ANY write bit is set, not if current process can write. Use nix::unistd::access with W_OK.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-16T00:08:40.768983647Z","created_by":"ubuntu","updated_at":"2026-02-16T00:12:45.721256198Z","closed_at":"2026-02-16T00:12:45.721191357Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["P1","audit"]}
{"id":"bd-1q3","title":"Alien decision uplift: uncertainty-aware expected-loss gating in scoring","description":"Use entropy+calibration uncertainty to improve Delete/Review/Keep action quality while preserving deterministic behavior and explainability. Scope limited to src/scanner/scoring.rs with unit tests and rch validation.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T04:29:06.297135152Z","created_by":"ubuntu","updated_at":"2026-02-15T06:50:26.223913921Z","closed_at":"2026-02-15T06:42:28.044955217Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0,"labels":["decision-engine","math","scanner"],"comments":[{"id":251,"issue_id":"bd-1q3","author":"Dicklesworthstone","text":"Completed scoped decision-engine uplift in src/scanner/scoring.rs: uncertainty-aware expected-loss action gating (entropy + calibration), pressure multiplier added to evidence ledger terms, richer ledger summary with loss margin + uncertainty, and focused boundary/uncertainty unit tests. Validation: rch exec \"cargo test --lib scoring\" PASS; rch exec \"cargo check --all-targets\" PASS; cargo fmt --check PASS. rch exec \"cargo clippy --all-targets -- -D warnings\" still fails with broad pre-existing lint debt outside this slice.","created_at":"2026-02-15T06:42:25Z"},{"id":252,"issue_id":"bd-1q3","author":"WildBeacon","text":"Follow-up refinement in src/scanner/scoring.rs: added uncertainty_adjusted_losses(), routed decision expected losses through uncertainty-aware adjustment, widened review band and posterior thresholding under uncertainty, expanded evidence ledger with base-vs-adjusted losses + calibration/uncertainty terms, and added unit test uncertainty_adjustment_penalizes_delete_loss_more_than_keep_loss. Validation: cargo fmt --check PASS; rch exec 'cargo test --lib scoring' PASS (12); rch exec 'cargo check --all-targets' PASS; rch exec 'cargo clippy --lib -- -D warnings' blocked by pre-existing unrelated lint in src/monitor/fs_stats.rs.","created_at":"2026-02-15T06:50:26Z"}]}
{"id":"bd-1sr","title":"Fix C1: Launchd plist updater replaces all string elements globally","status":"closed","priority":0,"issue_type":"bug","created_at":"2026-02-15T21:20:33.772338621Z","created_by":"ubuntu","updated_at":"2026-02-15T21:21:56.259522555Z","closed_at":"2026-02-15T21:21:56.259504511Z","close_reason":"Already fixed: apply_update_service_path now tracks in_program_args state, only replaces <string> elements within ProgramArguments array (lines 1087-1114)","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1sw","title":"Build artifact pattern registry with heuristic classification rules","description":"## Deliverable\nA comprehensive, extensible registry of filename/path patterns that identify build artifacts, temporary files, and cache directories across all major build systems.\n\n## Technical Approach\n### Pattern Categories (from real-world agent swarm data)\n\n#### Rust/Cargo Patterns (highest priority - this is the primary use case)\nMatching patterns observed across real agent sessions:\n- `target/` - standard Cargo target directory\n- `.target*` - hidden target variants (.target_boldmeadow_auth3, .target-topaz, .target-opus)\n- `_target_*` - underscore-prefixed (_target_opus_main, _target_codex_deepdive)\n- `.tmp_target*` - temp targets (.tmp_target_codex_or, .tmp_target_pearlgorge)\n- `cargo-target-*` - named cargo targets (cargo-target-quietwillow-mvcc, cargo-target-pearl)\n- `cargo_*` - alternate cargo patterns (cargo_opus_prime)\n- `*-target` - suffix targets (jadefinch-target, scarletwaterfall-target)\n- `target-*` - prefix targets (target-ubuntu-am, target-maroon)\n- `.tmp_cargo_home_*` - temp cargo homes\n- `.tmp-codex-*` - codex temp dirs\n- `.tmp-pijs-*` - pi_agent temp dirs\n- `.tmp-ext-*` - extension test dirs\n- `pi_agent_*` - pi_agent variants (pi_agent_cyanrobin, pi_agent_rust_opus)\n- `pi_target_*` - pi_target variants\n- `pi_opus_*` - pi_opus variants\n- `.tmp-opt-target*` - optimization test targets\n- `br-build*` - beads_rust build dirs\n- `cass-target*` - cass build dirs\n\n**Structural indicators within directories:**\n- Contains `incremental/` → almost certainly a Rust target dir\n- Contains `deps/` + `build/` → very likely Rust target\n- Contains `.fingerprint/` → definitely Rust target\n- Contains `release/` or `debug/` with .d files → Rust target\n\n#### Node.js Patterns\n- `node_modules/`\n- `.next/` (Next.js build)\n- `dist/`\n- `.cache/` (various build tools)\n- `.parcel-cache/`\n\n#### Python Patterns\n- `__pycache__/`\n- `.venv/` / `venv/`\n- `*.egg-info/`\n- `.mypy_cache/`\n- `.pytest_cache/`\n\n#### General Build Patterns\n- `build/` (many languages)\n- `.build/`\n- `out/`\n- `.gradle/`\n- `.tox/`\n\n#### Cache Patterns\n- `~/.cache/go-build`\n- `~/.cache/pip`\n- `~/.cache/huggingface`\n- `~/.cache/actcache`\n\n### Pattern Registry Implementation\n```rust\npub struct ArtifactPattern {\n    pub name: &'static str,\n    pub description: &'static str,\n    pub name_regex: Regex,\n    pub structural_markers: Vec<&'static str>,  // subdirs that confirm classification\n    pub confidence: f64,         // 0.0-1.0 base confidence\n    pub category: ArtifactCategory,\n    pub typical_size_range: (u64, u64),  // expected size range for plausibility\n}\n\npub enum ArtifactCategory {\n    RustTarget,     // highest confidence\n    NodeModules,\n    PythonCache,\n    BuildOutput,\n    CacheDir,\n    TempDir,\n    AgentWorkspace, // agent-specific temp builds\n    Unknown,\n}\n```\n\n### Matching Algorithm\nFor each discovered directory:\n1. Check name against all patterns (regex match)\n2. If name matches, check structural markers (does it contain incremental/, deps/, etc.)\n3. Combine name confidence with structural confidence\n4. Return ArtifactClassification with overall confidence\n\n```rust\npub struct ArtifactClassification {\n    pub pattern_name: &'static str,\n    pub category: ArtifactCategory,\n    pub name_confidence: f64,\n    pub structural_confidence: f64,\n    pub combined_confidence: f64,\n}\n```\n\n### Extensibility\nUsers can add custom patterns via config:\n```toml\n[[scanner.custom_patterns]]\nname = \"my-tool-cache\"\nregex = \"^\\\\.my-tool-cache$\"\nconfidence = 0.8\ncategory = \"CacheDir\"\n```\n\n## Design Rationale\nThe pattern list is derived from REAL data collected from weeks of agent swarm operation. The naming conventions are diverse and creative (agents name targets after themselves: boldmeadow, quietwillow, etc.), so we need comprehensive regex patterns. Structural markers add a second layer of verification: even if a directory is named \"target\", we check if it LOOKS like a Rust target dir inside. This prevents false positives.\n\n## Acceptance Criteria\n- All observed agent naming patterns from the specification are covered\n- Structural markers correctly identify Rust target directories\n- No false positives on common directory names (e.g., a user's \"target\" document folder)\n- Custom patterns loadable from config\n- Confidence scores reflect actual classification quality\n- Unit tests for every pattern category\n- Unit test: directory named \"target\" but containing only documents → low confidence\n- Unit test: directory named \".target_opus_main\" with incremental/ inside → high confidence","acceptance_criteria":"1. Deterministic pattern classification for identical inputs across all built-in and custom rules. 2. Unit tests cover positive/negative fixtures, precedence, and confidence calibration boundaries. 3. Integration tests validate handoff into walker/scorer without false category drift. 4. E2E scenarios exercise real artifact trees and verify expected matched categories. 5. Detailed match-trace logging includes pattern id, confidence, and suppression/veto reasons.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:47:37.220914613Z","created_by":"ubuntu","updated_at":"2026-02-14T19:46:14.652852740Z","closed_at":"2026-02-14T19:46:14.652831130Z","close_reason":"Implemented in scanner/patterns.rs","source_repo":".","compaction_level":0,"original_size":0,"labels":["scanner"],"dependencies":[{"issue_id":"bd-1sw","depends_on_id":"bd-1kn","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-1sw","depends_on_id":"bd-3uk","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":253,"issue_id":"bd-1sw","author":"Dicklesworthstone","text":"REVIEW: Missing error handling for user-supplied custom regex patterns:\n\nWhen a user adds a custom pattern in config:\n  [[scanner.custom_patterns]]\n  name = \"my-cache\"\n  regex = \"[invalid(regex\"  # <-- broken regex\n\nThe pattern registry must:\n1. Validate each custom regex at config load time using Regex::new()\n2. If invalid: emit SBH-4001 error with the regex string, position of syntax error, and suggestion\n3. NEVER crash — skip the invalid pattern and log a warning\n4. In strict mode (sbh config validate): report all invalid patterns as errors\n5. In normal operation: silently skip invalid patterns but log them to JSONL\n\nThis follows the \"don't let user config mistakes crash the daemon\" principle. A typo in one custom pattern should not prevent sbh from monitoring with all its built-in patterns.","created_at":"2026-02-14T17:13:31Z"}]}
{"id":"bd-1td","title":"Special location registry for RAM-backed and critical filesystems","description":"## Deliverable\nA registry of special filesystem locations (tmpfs, /dev/shm, RAM-backed mounts) that require more aggressive monitoring and lower free-space thresholds.\n\n## Technical Approach\n### SpecialLocationRegistry\n```rust\npub struct SpecialLocationRegistry {\n    locations: Vec<SpecialLocation>,\n}\n\npub struct SpecialLocation {\n    pub path: PathBuf,\n    pub kind: SpecialKind,\n    pub buffer_pct: f64,          // minimum free % to maintain (default 15%)\n    pub scan_interval: Duration,   // how often to check (default 5s)\n    pub priority: u8,              // higher = more important to keep free\n}\n\npub enum SpecialKind {\n    Tmpfs,          // /tmp on most Linux systems\n    DevShm,         // /dev/shm - POSIX shared memory\n    RunShm,         // /run/shm - some distros\n    Ramfs,          // true RAM filesystem (no swap)\n    UserTmp,        // /data/tmp or similar user-managed temp\n    Custom(String), // user-configured special locations\n}\n```\n\n### Auto-Discovery\nOn startup, scan mount points (via PAL) to find:\n- All tmpfs mounts\n- /dev/shm (always special on Linux)\n- Any mount with fs_type == \"ramfs\"\n- User-configured locations from config\n\n### Why Special Locations Matter\nRAM-backed filesystems are bounded by physical memory. When /tmp (tmpfs) fills up:\n- Build processes fail with \"No space left on device\"\n- System services that use /tmp start failing\n- The machine becomes progressively more unstable\n- Unlike disk, there's no extra buffer - it's literally eating RAM\n\nThis is WORSE than disk filling because RAM pressure causes OOM kills and swap thrashing, which is exactly the scenario sbh exists to prevent.\n\n### Monitoring Strategy\nSpecial locations get:\n- 3-6x higher scan frequency than disk-backed locations\n- Lower buffer thresholds (15% free minimum vs 5% for disk)\n- Priority ballast release when they fill up\n- Immediate logging when buffer threshold is breached\n- RAM-backed locations report both their own free% AND system memory impact\n\n## Acceptance Criteria\n- Auto-discovers all tmpfs, devshm, ramfs mounts on Linux\n- Correctly classifies each special location\n- Configurable buffer_pct per location\n- Scan intervals are shorter for special locations\n- Reports special location pressure separately from disk pressure\n- Unit tests with mock mount point data","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:45:04.924331671Z","created_by":"ubuntu","updated_at":"2026-02-14T19:45:22.289462864Z","closed_at":"2026-02-14T19:45:22.289430143Z","close_reason":"Special location registry implemented in monitor/special_locations.rs (210 lines): SpecialLocationRegistry with auto-discovery from mount_points(), SpecialKind enum (Tmpfs/DevShm/Ramfs/UserTmp/Custom), per-location buffer_pct/scan_interval/priority, /tmp fallback, unit tests.","source_repo":".","compaction_level":0,"original_size":0,"labels":["monitoring"],"dependencies":[{"issue_id":"bd-1td","depends_on_id":"bd-2pj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-1td","depends_on_id":"bd-sth","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-1u9","title":"Align CLI state staleness thresholds with daemon write cadence","description":"run_status/run_check/read_daemon_prediction use thresholds (2*poll or 30s) that are tighter than self_monitor's 30s write interval, causing false 'daemon not running' and dropped predictions. Use a shared floor (>=60s) or shared constant.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T22:31:04.206737765Z","created_by":"ubuntu","updated_at":"2026-02-15T22:34:42.687249825Z","closed_at":"2026-02-15T22:34:42.687227934Z","close_reason":"Fixed: all 3 CLI staleness checks now use shared DAEMON_STATE_STALE_THRESHOLD_SECS (90s) constant from self_monitor.rs instead of flawed poll-interval-based formulas","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1w9","title":"Parallel directory walker with cross-device and symlink safety","description":"## Deliverable\nA high-performance parallel directory walker that discovers candidate files/directories for cleanup, with safety guards against crossing filesystem boundaries, following symlinks, or entering protected paths.\n\n## Technical Approach\n### Walker Design\n```rust\npub struct DirectoryWalker {\n    config: WalkerConfig,\n    excluded_paths: HashSet<PathBuf>,\n    seen_inodes: HashSet<u64>,     // detect hardlink loops\n    results_tx: crossbeam::Sender<WalkEntry>,\n}\n\npub struct WalkerConfig {\n    pub root_paths: Vec<PathBuf>,\n    pub max_depth: usize,          // default 10\n    pub follow_symlinks: bool,     // default false (NEVER follow by default)\n    pub cross_devices: bool,       // default false (stay on same filesystem)\n    pub parallelism: usize,        // default num_cpus / 2\n    pub excluded_patterns: Vec<Regex>,\n}\n\npub struct WalkEntry {\n    pub path: PathBuf,\n    pub metadata: EntryMetadata,\n    pub depth: usize,\n}\n\npub struct EntryMetadata {\n    pub size_bytes: u64,           // for dirs: recursive size estimate\n    pub file_type: FileType,\n    pub modified: SystemTime,\n    pub created: Option<SystemTime>,\n    pub is_dir: bool,\n    pub inode: u64,\n    pub device_id: u64,\n    pub permissions: u32,\n}\n```\n\n### Safety Guards\n1. **No symlink following**: Symlinks could lead anywhere, including outside the scan scope. Always use lstat, never stat.\n2. **No cross-device**: Stay on the same filesystem. A target/ dir on /data shouldn't cause us to scan /boot.\n3. **Excluded paths**: Never enter /, /boot, /etc, /usr, /bin, /sbin, /var/log, /proc, /sys, /dev (except /dev/shm)\n4. **Inode dedup**: Detect hardlink cycles via inode tracking\n5. **Permission checking**: Skip directories we can't read (log warning, don't fail)\n6. **Rate limiting**: Under extreme system load, throttle walking to avoid making things worse\n\n### Parallelism Strategy\nUse a work-stealing pattern (inspired by rayon) but with explicit control:\n- Main thread discovers top-level directories\n- Worker threads process subdirectories via crossbeam channel\n- Each worker sends results back via channel\n- Bounded channel prevents unbounded memory growth\n\n### Performance Under Load\nWhen the system is already overloaded (the exact scenario where sbh is needed), the walker must be gentle:\n- Use ionice equivalent (Linux: ioprio_set with IOPRIO_CLASS_IDLE)\n- Yield between directory reads under high load average\n- Limit parallelism based on current load average\n- Skip recursive size calculation when time is critical (use estimate)\n\n### Directory Size Estimation\nFor directories, we need size but du -s is expensive. Two modes:\n- **Estimate mode** (default under pressure): sum of direct children only, extrapolate\n- **Accurate mode** (low pressure): full recursive stat\n\n## Design Rationale\nThe walker is the \"eyes\" of the scanner. It must be thorough but safe. The biggest risk is accidentally scanning a mounted USB drive, NFS share, or critical system directory. The safety guards prevent this. Parallelism speeds up scanning on large project directories but is throttled under load to avoid contributing to the very problem we're solving.\n\n## Acceptance Criteria\n- Discovers all directories/files under root_paths within configured depth\n- Never follows symlinks by default\n- Never crosses filesystem boundaries\n- Never enters excluded paths\n- Correctly handles permission denied (skip, warn, continue)\n- Parallel scanning is faster than sequential for large trees\n- Throttles under high load (verifiable by checking iteration delay)\n- Unit tests with synthetic directory trees\n- Unit test: directory with symlink loop → correctly handled\n- Unit test: cross-device mount → not followed","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T16:47:02.781065858Z","created_by":"ubuntu","updated_at":"2026-02-14T21:40:35.463883890Z","closed_at":"2026-02-14T21:40:35.463864774Z","close_reason":"Implemented parallel directory walker with crossbeam work-stealing, protection integration, structural signal collection, open-file detection, 14 tests passing","source_repo":".","compaction_level":0,"original_size":0,"labels":["scanner"],"dependencies":[{"issue_id":"bd-1w9","depends_on_id":"bd-3qm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-1w9","depends_on_id":"bd-sth","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":254,"issue_id":"bd-1w9","author":"Dicklesworthstone","text":"REVIEW: The walker must collect structural markers during traversal. When walking a candidate directory, check for the presence of key subdirectories (incremental/, deps/, .fingerprint/, build/, .git/, node_modules/.package-lock.json, etc.) and attach them as Vec<String> to WalkEntry.structural_markers. This data is consumed by the scoring engine (bd-x9z) which is a pure computation and cannot do filesystem I/O. The walker is the only component that touches the filesystem during scanning.","created_at":"2026-02-14T17:12:14Z"},{"id":255,"issue_id":"bd-1w9","author":"Dicklesworthstone","text":"REVIEW-2: Walker must also perform open-file detection for the scorer. During each scan cycle, collect the set of all open file paths from /proc/*/fd into a HashSet<PathBuf> (refreshed every 5s, cached between refreshes). For each WalkEntry, set is_open: bool if any fd in the open-file set points to a path under the candidate. Add is_open: bool to WalkEntry struct. Under Critical pressure, skip this check entirely (too slow when disk is thrashing). On macOS, use lsof equivalent via PAL (bd-sth).","created_at":"2026-02-14T19:03:18Z"}]}
{"id":"bd-1yl","title":"Clippy micro-fix: update.rs option_map_or_none","description":"Fix clippy option_map_or_none in src/cli/update.rs by replacing map_or(None, ...) with and_then in test/setup path; preserve behavior and validate via rch.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:57:15.700899330Z","created_by":"ubuntu","updated_at":"2026-02-15T16:57:44.330106330Z","closed_at":"2026-02-15T16:57:44.330088656Z","close_reason":"Blocked by active reservation on src/cli/update.rs (held by CrimsonJay); pivoted to non-overlap slice","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"]}
{"id":"bd-1yv","title":"Remove dead code: unused label functions + unused coordinator config field","status":"closed","priority":3,"issue_type":"task","created_at":"2026-02-16T02:09:09.952789327Z","created_by":"ubuntu","updated_at":"2026-02-16T02:10:49.344611375Z","closed_at":"2026-02-16T02:10:49.344593061Z","close_reason":"Removed dead code: 2 unused label functions from cli_app.rs and unused config field from coordinator.rs","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-21p","title":"Fix M9: unescape_mount_field only handles \\040, missing other octal escapes","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-02-15T21:31:50.295109494Z","created_by":"ubuntu","updated_at":"2026-02-15T21:34:30.127607370Z","closed_at":"2026-02-15T21:34:30.127580991Z","close_reason":"Fixed: unescape_mount_field now decodes all octal \\NNN sequences, not just \\040. Added test covering space, tab, backslash, newline, and edge cases.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-21u","title":"Cap ballast file_count at u32::MAX in config validation","description":"BallastManager casts file index i (usize) to u32 at lines 168, 257, 303, 355. Config validation has no upper bound so file_count over u32::MAX silently truncates causing duplicate filenames.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-16T00:08:38.089039310Z","created_by":"ubuntu","updated_at":"2026-02-16T00:12:45.530004951Z","closed_at":"2026-02-16T00:12:45.529941722Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["P1","audit"]}
{"id":"bd-21z","title":"Integration test suite: full-pipeline tests with realistic scenarios","description":"## Deliverable\nIntegration tests that exercise the full sbh pipeline from pressure detection through scanning, scoring, cleanup, fallback, and recovery.\n\n## Scope Expansion (Plan-Space Revision)\nThis integration bead now explicitly validates all major feature clusters, including:\n- predictive actions and early-warning pipeline\n- emergency zero-write mode\n- multi-volume ballast coordination\n- project protection markers\n- process attribution and explainability paths\n- decision-plane adaptive/fallback behavior\n\n## Technical Approach\n### Scenario Set\n1. Normal operation with green pressure and no deletion\n2. Gradual pressure buildup with controller escalation\n3. Critical pressure with ballast-first recovery\n4. Special location pressure handling (/tmp/devshm style)\n5. Dry-run pipeline parity (no side effects)\n6. Recovery and ballast replenishment\n7. Concurrent scanner/deletion/logger interactions\n8. Error recovery with circuit-breaker behavior\n9. Predictive action preemption before threshold crossing\n10. Emergency zero-write policy path and rollback to normal mode\n11. Protected project markers preventing destructive actions\n12. Multi-volume pressure balancing and action allocation\n\n### Detailed Logging Contract\nEach scenario must assert both behavior and logs:\n- pressure transitions with timestamps\n- selected actions and reasons\n- fallback activations and recovery criteria\n- reclaimed bytes, skipped candidates, and veto reasons\n- trace IDs linking to decision/evidence records\n\n## Acceptance Criteria\n- All scenarios pass deterministically\n- No temp artifacts leaked after test run\n- Tests complete within bounded runtime budget\n- Behavior assertions include log assertions for each scenario\n- Coverage includes adaptive and conservative paths\n- Integration logs are machine-readable and human-auditable","acceptance_criteria":"1. Integration suite exercises full dataflow from scan to action/logging under realistic conditions. 2. Cross-module contracts (CLI/daemon/scanner/controller/logger) are verified in end-to-end pipeline fixtures. 3. Failure-mode tests validate fallback-safe behavior and recovery transitions. 4. Detailed integration logs include trace IDs, stage timings, and decision rationale snapshots. 5. Machine-readable reports summarize pass/fail per scenario and contract.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T16:54:08.740511207Z","created_by":"ubuntu","updated_at":"2026-02-15T01:01:01.214958496Z","closed_at":"2026-02-15T01:01:01.214881933Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["testing"],"dependencies":[{"issue_id":"bd-21z","depends_on_id":"bd-112","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-1gm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-1hh","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-224","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-25g","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-2f8","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-2m9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-2np","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-2qa","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-2s9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-2up","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-394","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-395","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-3cj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-3qm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-3s5","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-48o","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-7vl","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-p2u","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-21z","depends_on_id":"bd-u92","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":256,"issue_id":"bd-21z","author":"Dicklesworthstone","text":"ADDITIONAL INTEGRATION TEST (idea-wizard):\n\n**Scenario 9: Predictive Pre-emptive Cleanup**\n- Start at 80% free (Green)\n- Simulate rapid fill at 500 MB/s using MockPlatform\n- EWMA should detect acceleration and predict exhaustion in ~20 min\n- Predictive action pipeline should trigger PreemptiveCleanup BEFORE threshold is crossed\n- Verify cleanup starts while disk is still at 75% free (well above threshold)\n- Verify cleanup is gentle (high score threshold, not aggressive)\n- Verify disk never reaches Orange pressure level\n\n**Scenario 10: Multi-Volume Ballast**\n- Set up 2 mock volumes (/data at 5% free, /var at 60% free)\n- Provision ballast pools on both\n- Trigger pressure on /data\n- Verify ballast released from /data's pool (not /var's)\n- Verify space freed on /data\n- Recovery: verify replenishment on /data when pressure subsides","created_at":"2026-02-14T18:37:00Z"}]}
{"id":"bd-224","title":"Pressure-responsive ballast release with automatic replenishment","description":"## Deliverable\nIntegration between the PID pressure controller and ballast manager: automatically release ballast files when pressure rises, and replenish when pressure subsides.\n\n## Technical Approach\n### Release Logic\nThe PID controller outputs a PressureResponse. When it includes ReleaseBallast(N):\n1. Log the decision with full context (pressure level, free%, rate estimate)\n2. Release N ballast files via BallastManager\n3. Wait 2 seconds for filesystem to update\n4. Re-measure pressure\n5. If still critical, release more (up to all ballast)\n6. Log total released and resulting free%\n\n### Replenishment Logic\nWhen pressure returns to Green and stays there for replenish_cooldown (default 30 minutes):\n1. Check how many ballast files were released\n2. Start replenishing one file at a time\n3. After each file, re-check pressure - abort if no longer Green\n4. Log replenishment progress\n\n### Rate-Limited Replenishment\nReplenishing (writing 1GB files) itself causes disk I/O. Rate-limit to:\n- One file every 5 minutes during replenishment\n- Only during Green pressure\n- Pause if any other disk activity is detected (via I/O wait)\n\n### Graduated Response\nThe PID controller determines HOW MANY ballast files to release based on urgency:\n- urgency 0.0-0.3: release 1 file (buy ~1GB breathing room)\n- urgency 0.3-0.6: release 3 files (buy ~3GB)\n- urgency 0.6-0.9: release half of remaining ballast\n- urgency 0.9-1.0: release ALL ballast (emergency)\n\n## Acceptance Criteria\n- Ballast released proportionally to pressure urgency\n- No oscillation: released ballast stays released until cooldown\n- Replenishment is gradual and pressure-aware\n- Replenishment pauses if pressure increases\n- All releases logged with full context\n- Integration test: simulate pressure → verify release → simulate recovery → verify replenish","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:46:36.789122074Z","created_by":"ubuntu","updated_at":"2026-02-14T20:13:31.590808505Z","closed_at":"2026-02-14T20:13:31.590742110Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["ballast"],"dependencies":[{"issue_id":"bd-224","depends_on_id":"bd-25g","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-224","depends_on_id":"bd-3po","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":257,"issue_id":"bd-224","author":"Dicklesworthstone","text":"REVIEW: Important edge case — ballast files must be on the SAME filesystem that's under pressure. If /data is filling up but ballast is on /var (different mount), deleting ballast doesn't help.\n\nImplementation must:\n1. During provisioning, detect which mount point the ballast_dir is on\n2. During release, verify the ballast files are on the same mount as the filesystem under pressure\n3. If they're on different mounts, skip ballast release and go straight to artifact scanning\n4. Log a warning: \"Ballast on /var/lib/sbh/ballast cannot relieve pressure on /data — consider setting ballast.location to /data/.sbh/ballast\"\n5. Config should suggest putting ballast on the primary data volume: ballast.location = \"/data/.sbh/ballast\"","created_at":"2026-02-14T17:14:58Z"},{"id":258,"issue_id":"bd-224","author":"Dicklesworthstone","text":"REVIEW: Integration with multi-volume ballast pool coordinator (bd-u92): When bd-u92 is implemented, this bead's BallastManager interface changes from single-pool to multi-pool. Key changes: (1) Release logic must select ballast pool on the SAME filesystem as the pressure source (per existing review comment). (2) BallastPoolCoordinator.release_for_mount(mount_point, count) replaces BallastManager.release(count). (3) Replenishment targets pools proportionally based on config. (4) Per-pool lock files prevent concurrent access from CLI and daemon. (5) State tracking: each pool has its own available/released count.","created_at":"2026-02-14T18:53:44Z"},{"id":259,"issue_id":"bd-224","author":"Dicklesworthstone","text":"REVIEW-2: Removed bd-u92 hard dependency. Initial implementation uses single-pool BallastManager from bd-25g directly. When bd-u92 (multi-volume coordinator) is available later, the interface upgrades to BallastPoolCoordinator.release_for_mount(). The same-filesystem check from comment 14 still applies. Multi-volume is layered on top, not load-bearing for v1.","created_at":"2026-02-14T19:02:59Z"}]}
{"id":"bd-232","title":"decision_plane_tests clippy follow-up micro-slice","description":"Resolve remaining strict clippy errors in src/decision_plane_tests.rs from rch run (cast_precision_loss/cast_possible_truncation, float_cmp, suboptimal_flops, collapsible_if, field_reassign_with_default, struct_field_names, cast_lossless, too_many_lines) with scoped, non-architectural changes.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T17:28:38.752431910Z","created_by":"ubuntu","updated_at":"2026-02-15T17:32:14.329005072Z","closed_at":"2026-02-15T17:32:14.328978542Z","close_reason":"Completed decision_plane_tests lint micro-slice","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","quality","tests"]}
{"id":"bd-23i","title":"Set restrictive permissions on merkle checkpoint temp files","description":"Merkle checkpoint temp files use File::create with default umask, same pattern as the state.json fix (bd-z0j). Apply consistent 0o600 permissions for defense-in-depth.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-15T23:14:41.695193349Z","created_by":"ubuntu","updated_at":"2026-02-15T23:17:32.681124145Z","closed_at":"2026-02-15T23:17:32.681040939Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-23q","title":"Fix I36: recommended_free_target_pct broken for high free_pct","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T21:07:57.064150183Z","created_by":"ubuntu","updated_at":"2026-02-15T21:08:41.633357132Z","closed_at":"2026-02-15T21:08:41.633337405Z","close_reason":"Already fixed - uses policy-driven lerp(15.0, 25.0) instead of buggy .max() logic","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-24a","title":"Support JSON streaming for status --watch live mode","description":"Adjust live status loop so status --watch works with --json by emitting newline-delimited JSON snapshots each interval; keep dashboard in human-only live mode.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T22:29:35.935672150Z","created_by":"ubuntu","updated_at":"2026-02-15T22:32:25.954644720Z","closed_at":"2026-02-15T22:32:25.954626706Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-25g","title":"Ballast file manager: creation, verification, and inventory","description":"## Deliverable\nThe core ballast file management system: creating, tracking, and verifying the \"sacrificial anode\" files that can be deleted under pressure.\n\n## Technical Approach\n### Ballast File Design\nFiles named: SBH_BALLAST_FILE_00001.dat through SBH_BALLAST_FILE_NNNNN.dat\nLocated in: /var/lib/sbh/ballast/ (Linux), ~/Library/Application Support/sbh/ballast/ (macOS)\nDefault: 10 files × 1GB each = 10GB of reclaimable space\n\n### File Format\nEach ballast file contains:\n- First 4096 bytes: Header with metadata (JSON)\n  - magic: \"SBH_BALLAST_v1\"\n  - file_index: sequential number\n  - created_at: ISO 8601 timestamp\n  - file_size: total size in bytes\n  - xxhash64: checksum of data portion\n  - purpose: \"Storage ballast for emergency space recovery\"\n- Remaining bytes: random data generated by getrandom (or /dev/urandom fallback)\n\nUsing random data (not zeros) prevents filesystem-level deduplication or compression from defeating the purpose. The data must actually occupy disk blocks.\n\n### BallastManager\n```rust\npub struct BallastManager {\n    ballast_dir: PathBuf,\n    config: BallastConfig,\n    inventory: Vec<BallastFile>,\n}\n\npub struct BallastFile {\n    pub path: PathBuf,\n    pub index: u32,\n    pub size: u64,\n    pub created_at: DateTime<Utc>,\n    pub integrity_ok: bool,\n    pub released: bool,\n}\n\nimpl BallastManager {\n    /// Create all ballast files (idempotent, skips existing valid files)\n    pub fn provision(&mut self) -> Result<ProvisionReport, SbhError>;\n    \n    /// Check inventory: how many files exist, their status\n    pub fn inventory(&self) -> &[BallastFile];\n    \n    /// How many bytes can be released\n    pub fn releasable_bytes(&self) -> u64;\n    \n    /// Release N ballast files (delete highest-index first)\n    pub fn release(&mut self, count: usize) -> Result<ReleaseReport, SbhError>;\n    \n    /// Verify integrity of all ballast files (check headers, optional checksum)\n    pub fn verify(&self) -> Result<VerifyReport, SbhError>;\n    \n    /// Replenish: recreate released ballast files when pressure subsides\n    pub fn replenish(&mut self) -> Result<ProvisionReport, SbhError>;\n}\n```\n\n### Creation Strategy\nCreating 10GB of random data takes time. Strategy:\n1. Create files sequentially (not in parallel - we don't want to cause the very disk pressure we're trying to prevent)\n2. Write in 4MB chunks with fsync every 64MB\n3. Check free space before each file creation - abort if we'd go below 20% free\n4. Log progress to stderr for visibility\n\n### Release Strategy\nWhen pressure rises, delete ballast files in reverse order (highest index first):\n- Each deletion frees exactly file_size_mb (e.g., 1GB)\n- Log each release to the activity logger\n- After release, immediately re-check pressure to see if more releases needed\n\n## Design Rationale\nThe \"ballast\" concept is inspired by ships using ballast water for stability. By pre-allocating space, we create a guaranteed buffer that can be instantly reclaimed. This is critical because under extreme disk pressure, even creating a log file might fail. The ballast provides breathing room for the scanner and cleaner to do their work.\n\nRandom data prevents CoW/dedup/compress from silently reclaiming the space. The header enables verification that files haven't been tampered with.\n\n## Acceptance Criteria\n- Ballast files created with correct format and random content\n- Files are genuinely occupying disk blocks (verified via du vs stat)\n- Release correctly deletes files and reports freed space\n- Replenish recreates files when pressure subsides\n- Integrity verification catches corrupted/truncated files\n- Idempotent provision: re-running doesn't duplicate files\n- Unit tests for all operations\n- Test: provision → verify → release 3 → verify → replenish → verify","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:46:20.561757848Z","created_by":"ubuntu","updated_at":"2026-02-14T20:07:40.569064718Z","closed_at":"2026-02-14T20:07:40.569028791Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["ballast"],"dependencies":[{"issue_id":"bd-25g","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-25g","depends_on_id":"bd-3uk","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-25g","depends_on_id":"bd-sth","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":260,"issue_id":"bd-25g","author":"Dicklesworthstone","text":"REVIEW: Two important additions needed:\n\n1. FALLOCATE OPTIMIZATION: Writing 10GB of random data takes 25-50s (getrandom/urandom maxes out ~200-400 MB/s). On ext4/xfs, use posix_fallocate() or fallocate() which is INSTANT — it reserves blocks on disk without writing data. This is the correct approach for the primary target (Linux ext4). Only fall back to random data writing on CoW filesystems (btrfs, zfs) where fallocate might not prevent deduplication. Detection: check fs_type from PAL. Implementation:\n  - ext4/xfs: fallocate() → instant provisioning\n  - btrfs/zfs: write random data in 4MB chunks → 25-50s for 10GB\n  - tmpfs: NEVER put ballast on tmpfs (that defeats the purpose)\n\n2. FILE LOCKING: When the daemon is running and a user runs 'sbh ballast release 1', both could try to manipulate ballast files simultaneously. Use flock() on a lockfile (/var/lib/sbh/.ballast.lock) to serialize access. The daemon holds the lock during ballast operations, CLI commands wait for the lock with a timeout (5s).","created_at":"2026-02-14T17:12:51Z"}]}
{"id":"bd-26g","title":"systemd unit file generation and service installation (Linux)","description":"## Deliverable\nGenerate and install a systemd service unit file for the sbh daemon on Linux systems.\n\n## Technical Approach\n### Generated Unit File\n```ini\n[Unit]\nDescription=Storage Ballast Helper - Disk Space Guardian\nDocumentation=man:sbh(1)\nAfter=local-fs.target\nWants=local-fs.target\n\n[Service]\nType=notify\nExecStart=/usr/local/bin/sbh daemon\nExecReload=/bin/kill -HUP $MAINPID\nRestart=on-failure\nRestartSec=10\nWatchdogSec=60\nTimeoutStopSec=30\nNice=19\nIOSchedulingClass=idle\nIOSchedulingPriority=7\n\n# Security hardening\nNoNewPrivileges=true\nProtectSystem=strict\nReadWritePaths=/var/lib/sbh /tmp /data/tmp\nProtectHome=read-only\nPrivateTmp=false\nProtectKernelTunables=true\nProtectControlGroups=true\nRestrictSUIDSGID=true\nLimitNOFILE=4096\n\n# Resource limits\nMemoryMax=256M\nCPUQuota=10%\n\n# Logging\nStandardOutput=journal\nStandardError=journal\nSyslogIdentifier=sbh\n\n[Install]\nWantedBy=multi-user.target\n```\n\n### Key Design Choices\n- **Type=notify**: sbh will notify systemd when it's ready (sd_notify)\n- **Nice=19 + IOSchedulingClass=idle**: sbh runs at lowest priority - it must NEVER compete with the build processes it's trying to protect\n- **ProtectSystem=strict**: security hardening, only write to /var/lib/sbh\n- **ReadWritePaths**: explicitly list all paths sbh needs to write to\n- **ProtectHome=read-only**: can read home dirs (to scan) but not write\n- **MemoryMax=256M**: prevent sbh itself from consuming too much RAM\n- **CPUQuota=10%**: limit CPU usage\n- **WatchdogSec=60**: systemd restarts sbh if it stops responding\n- **Restart=on-failure**: auto-restart on crash\n\n### Installation Flow\n```bash\nsbh install --systemd\n```\n1. Generate unit file from template (with config-specific paths)\n2. Copy to /etc/systemd/system/sbh.service (or ~/.config/systemd/user/)\n3. systemctl daemon-reload\n4. systemctl enable sbh\n5. systemctl start sbh\n6. Verify service is running\n\n### User vs System Service\n- `sbh install`: system service (requires root)\n- `sbh install --user`: user service (no root needed)\n\n### sd_notify Integration\nThe daemon calls sd_notify at key points:\n- READY=1 after startup is complete\n- WATCHDOG=1 every 30 seconds during normal operation\n- STATUS=Monitoring N paths, M GB free on /data\n\n## Acceptance Criteria\n- Generated unit file is valid (systemd-analyze verify)\n- Service starts, stops, and restarts correctly\n- Watchdog keeps service alive\n- Resource limits enforced (memory, CPU)\n- Security sandboxing works (can't write to system dirs)\n- User-mode service works without root\n- sd_notify integration functional\n- Unit tests for unit file generation\n- Integration test: install → start → verify running → stop → uninstall","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T16:51:07.334963803Z","created_by":"ubuntu","updated_at":"2026-02-14T23:08:37.935328755Z","closed_at":"2026-02-14T23:08:37.935309319Z","close_reason":"Implemented systemd unit file generation and service installation. 15 unit tests passing. Wired up CLI install/uninstall handlers.","source_repo":".","compaction_level":0,"original_size":0,"labels":["daemon","platform"],"dependencies":[{"issue_id":"bd-26g","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-26g","depends_on_id":"bd-2j5.3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-26g","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":261,"issue_id":"bd-26g","author":"Dicklesworthstone","text":"REVIEW: ReadWritePaths conflict with artifact deletion in home directories:\n\nThe unit file specifies ProtectHome=read-only, but if scanner.watched_paths includes /home/*/projects/*, sbh CANNOT delete artifacts there because it only has read access. This creates a silent failure.\n\nFix: When generating the unit file, dynamically set ReadWritePaths to include all paths from scanner.watched_paths that are under /home:\n  ReadWritePaths=/var/lib/sbh /tmp /data/tmp /home\n  ProtectHome=false  (or use read-only + explicit ReadWritePaths)\n\nAlternative: Separate the systemd sandboxing for system-mode vs user-mode:\n- System mode (root): ProtectHome=read-only, ReadWritePaths includes /home\n- User mode (no root): no ProtectHome needed (already running as the user)\n\nThe template must be generated from config, not hardcoded.","created_at":"2026-02-14T17:16:01Z"}]}
{"id":"bd-284","title":"Open-file detection boundary false positives in scanner deletion","description":"Root cause: Linux open-file check compared /proc fd symlink targets using raw string prefix, so sibling paths like /tmp/foo-2 matched /tmp/foo and '(deleted)' suffixes were not normalized. Fix: canonical path-component matching with deleted-suffix normalization and regression tests.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T16:21:10.188311318Z","created_by":"ubuntu","updated_at":"2026-02-15T16:21:15.113532100Z","closed_at":"2026-02-15T16:21:15.113510009Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0,"labels":["linux","reliability","scanner"],"comments":[{"id":262,"issue_id":"bd-284","author":"WildBeacon","text":"Fixed in src/scanner/deletion.rs + src/monitor/fs_stats.rs (+ src/cli/assets.rs compile unblock). Added regression tests: fd_link_matching_requires_component_boundary and fd_link_matching_accepts_deleted_suffix. Validation: cargo fmt --check PASS; rch exec 'cargo check --all-targets' PASS; rch exec 'cargo test --lib deletion' PASS; rch exec 'cargo test --lib fs_stats' PASS; rch exec 'cargo test --test integration_tests' PASS; rch exec 'cargo clippy --lib -- -D warnings' PASS.","created_at":"2026-02-15T16:21:15Z"}]}
{"id":"bd-28h","title":"Fix I25: tune --apply auto-executes without confirmation in non-TTY","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T21:22:54.611572700Z","created_by":"ubuntu","updated_at":"2026-02-15T21:25:09.078513604Z","closed_at":"2026-02-15T21:25:09.078491814Z","close_reason":"Fixed: --yes now required in all output modes, not just Human","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-28s","title":"Daemon should not panic when worker thread spawn fails","description":"Replace expect-based scanner/executor thread spawns with fallible handling so daemon logs and exits cleanly instead of panicking under resource pressure.","status":"closed","priority":1,"issue_type":"bug","assignee":"RedWren","created_at":"2026-02-15T22:51:20.827461531Z","created_by":"RedWren","updated_at":"2026-02-15T22:58:09.846167686Z","closed_at":"2026-02-15T22:58:09.846150053Z","close_reason":"Completed: daemon worker thread spawn is now fallible and logged; no panic on spawn failure","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2ax","title":"dir_size_estimate only sums immediate children, vastly underestimating","description":"In daemon/loop_main.rs, dir_size_estimate uses read_dir to sum only immediate children metadata. On Unix, directories report ~4096 bytes, missing all nested content. A 5GB target/ dir might estimate as 50MB.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-16T00:15:44.665724729Z","created_by":"ubuntu","updated_at":"2026-02-16T00:17:56.704162719Z","closed_at":"2026-02-16T00:17:56.703517681Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["P1","audit"]}
{"id":"bd-2e2","title":"Clippy debt burn-down slice: cli_app setup helper lint cluster","description":"Fix a narrow cluster of clippy -D warnings in src/cli_app.rs setup helper region (collapsible_if, option_if_let_else/map_or_else, manual_let_else, match_same_arms, map_unwrap_or, related small cleanups) while preserving behavior and validating via rch.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:37:46.875433214Z","created_by":"ubuntu","updated_at":"2026-02-15T16:41:39.145507366Z","closed_at":"2026-02-15T16:41:39.145489302Z","close_reason":"Completed targeted cli_app setup-helper clippy cluster; broader cli_app/test lint backlog remains for follow-up slices.","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"],"comments":[{"id":263,"issue_id":"bd-2e2","author":"Dicklesworthstone","text":"Completed narrow setup-helper clippy cluster cleanup in src/cli_app.rs. Changes: collapsed nested ifs in resolve_bin_dir/setup_path/setup_completions; converted profile/ZDOTDIR selection to map_or_else; converted completion dir match to let-else; removed redundant match arm in completion_file selection; cleaned literal separators in generate_recommendations time-window constants. Validation: cargo fmt --check PASS; rch exec \"cargo check --all-targets\" PASS; rch exec \"cargo test --bin sbh -- setup\" PASS (setup_command_parses_with_flags). Global rch clippy still fails due broad repo backlog (including many other cli_app regions), but targeted clippy grep confirms no remaining hits at the addressed lines (1735/4405/4425/4478/4575/4590/4625/4626/4753).","created_at":"2026-02-15T16:41:35Z"}]}
{"id":"bd-2e5","title":"Clippy debt burn-down slice: core errors/config lint blockers","description":"Fix immediate clippy -D warnings blockers in src/core/errors.rs and src/core/config.rs (io_other_error, redundant_closure_for_method_calls, redundant_clone in tests) while preserving behavior with focused rch validation.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:33:25.966594071Z","created_by":"ubuntu","updated_at":"2026-02-15T16:35:15.449576738Z","closed_at":"2026-02-15T16:35:15.449558123Z","close_reason":"Completed: core errors/config clippy blockers resolved and validated","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"],"comments":[{"id":264,"issue_id":"bd-2e5","author":"Dicklesworthstone","text":"Completed non-overlap clippy slice for core errors/config tests.\\n\\nChanges:\\n- src/core/errors.rs: replaced std::io::Error::new(ErrorKind::Other, ..) with std::io::Error::other(..) in tests; replaced closure map(|e| e.code()) with method reference map(SbhError::code).\\n- src/core/config.rs: removed redundant clone in stable_hash_changes_when_config_changes test by constructing a fresh Config::default() for the modified config.\\n\\nValidation:\\n- rch exec \"cargo test --lib errors\" ✅\\n- rch exec \"cargo test --lib config\" ✅\\n- rch exec \"cargo check --all-targets\" ✅\\n- cargo fmt --check ✅\\n- rch exec \"cargo clippy --all-targets -- -D warnings\" ❌ (remaining repo-wide backlog outside this slice; e.g., tests/stress_tests.rs, src/decision_plane_tests.rs, src/cli_app.rs, etc.)","created_at":"2026-02-15T16:35:11Z"}]}
{"id":"bd-2e9","title":"Fix I34: u64 as i64 overflow in SQLite logger","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-02-15T21:22:54.802236907Z","created_by":"ubuntu","updated_at":"2026-02-15T21:23:37.397346788Z","closed_at":"2026-02-15T21:23:37.397322022Z","close_reason":"Already fixed - uses i64::try_from().unwrap_or(i64::MAX) instead of as cast","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2f8","title":"SQLite activity database with WAL mode and schema","description":"## Deliverable\nSQLite database for persistent activity logging, using WAL mode for concurrent read/write and optimized for append-heavy workloads.\n\n## Technical Approach\n### Schema\n```sql\n-- Core activity log\nCREATE TABLE IF NOT EXISTS activity_log (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    timestamp TEXT NOT NULL,             -- ISO 8601\n    event_type TEXT NOT NULL,            -- 'ballast_release', 'artifact_delete', 'pressure_change', etc.\n    severity TEXT NOT NULL,              -- 'info', 'warning', 'critical'\n    path TEXT,                           -- affected path (nullable for non-path events)\n    size_bytes INTEGER,                  -- size of deleted item\n    score REAL,                          -- candidacy score at time of action\n    score_factors TEXT,                  -- JSON blob of individual factor values\n    pressure_level TEXT,                 -- pressure level at time of action\n    free_pct REAL,                       -- free% at time of action\n    duration_ms INTEGER,                 -- how long the action took\n    success INTEGER NOT NULL DEFAULT 1,  -- 1=success, 0=failure\n    error_code TEXT,                     -- SBH-XXXX error code if failed\n    error_message TEXT,                  -- human-readable error\n    details TEXT                         -- JSON blob for additional context\n);\n\n-- Pressure history (for trend analysis)\nCREATE TABLE IF NOT EXISTS pressure_history (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    timestamp TEXT NOT NULL,\n    mount_point TEXT NOT NULL,\n    total_bytes INTEGER NOT NULL,\n    free_bytes INTEGER NOT NULL,\n    free_pct REAL NOT NULL,\n    rate_bytes_per_sec REAL,\n    pressure_level TEXT NOT NULL,\n    ewma_rate REAL,\n    pid_output REAL\n);\n\n-- Ballast inventory\nCREATE TABLE IF NOT EXISTS ballast_inventory (\n    file_index INTEGER PRIMARY KEY,\n    path TEXT NOT NULL,\n    size_bytes INTEGER NOT NULL,\n    created_at TEXT NOT NULL,\n    released_at TEXT,\n    replenished_at TEXT,\n    integrity_hash TEXT\n);\n\n-- Indexes for common queries\nCREATE INDEX IF NOT EXISTS idx_activity_timestamp ON activity_log(timestamp);\nCREATE INDEX IF NOT EXISTS idx_activity_event_type ON activity_log(event_type);\nCREATE INDEX IF NOT EXISTS idx_pressure_timestamp ON pressure_history(timestamp);\nCREATE INDEX IF NOT EXISTS idx_pressure_mount ON pressure_history(mount_point);\n```\n\n### Connection Management\n```rust\npub struct SqliteLogger {\n    conn: rusqlite::Connection,\n    insert_activity: rusqlite::Statement,    // prepared statement\n    insert_pressure: rusqlite::Statement,\n}\n```\n\n### PRAGMAs\n```sql\nPRAGMA journal_mode = WAL;           -- concurrent reads during writes\nPRAGMA synchronous = NORMAL;         -- good durability, better perf than FULL\nPRAGMA cache_size = -8000;           -- 8MB page cache\nPRAGMA mmap_size = 67108864;         -- 64MB mmap for reads\nPRAGMA temp_store = MEMORY;          -- temp tables in memory\nPRAGMA busy_timeout = 5000;          -- 5s retry on lock contention\n```\n\n### Graceful Degradation\nIf SQLite operations fail (disk full!), sbh must NOT stop working:\n- Log error to stderr\n- Continue operating using JSONL-only mode\n- Attempt to reopen SQLite periodically\n\n## Design Rationale\nSQLite with WAL mode provides excellent concurrent read performance (agents can query stats while daemon writes). Prepared statements minimize parse overhead for high-frequency inserts. The schema captures enough detail for comprehensive post-incident analysis while keeping writes fast.\n\nThe graceful degradation is critical: if the disk is so full that even SQLite can't write, sbh must still function (using JSONL on a different filesystem, or just stderr).\n\n## Acceptance Criteria\n- Database created with correct schema and PRAGMAs\n- Prepared statements for all common operations\n- WAL mode confirmed active\n- Insert latency < 1ms for typical log entries\n- Concurrent read/write without lock contention\n- Graceful handling of disk-full during write\n- Automatic schema migration for version upgrades\n- Unit tests for all CRUD operations\n- Test: 10,000 rapid inserts → no data loss\n- Test: concurrent reader + writer → no errors","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:49:11.278026287Z","created_by":"ubuntu","updated_at":"2026-02-14T19:51:08.972653915Z","closed_at":"2026-02-14T19:51:08.972633296Z","close_reason":"SQLite logger implemented in src/logger/sqlite.rs: WAL mode, NORMAL sync, 8MB cache, schema with activity_log/pressure_history/ballast_inventory tables, indexes, CRUD operations, aggregate queries (count_events_since/bytes_freed_since), upsert ballast, 7 passing tests.","source_repo":".","compaction_level":0,"original_size":0,"labels":["logger"],"dependencies":[{"issue_id":"bd-2f8","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2f8","depends_on_id":"bd-3uk","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":265,"issue_id":"bd-2f8","author":"Dicklesworthstone","text":"REVIEW: Database filesystem location consideration:\n\nThe SQLite database MUST NOT be on the same filesystem that's under pressure. If /data is filling up and the database is on /data, SQLite writes will fail precisely when logging is most critical.\n\nDefault location should be /var/lib/sbh/sbh.db (typically on / root partition, separate from /data). The config default already handles this: sqlite_path = /var/lib/sbh/sbh.db.\n\nHowever, the bead should explicitly validate during startup that the SQLite database path is NOT on a monitored filesystem (or at least warn if it is). Add a startup check:\n1. Resolve the mount point for sqlite_path\n2. Compare against scanner.watched_paths mount points\n3. If same mount: log WARNING \"[SBH-5001] Activity database is on monitored filesystem /data — database writes may fail under extreme pressure. Consider moving to a separate partition.\"","created_at":"2026-02-14T17:16:07Z"}]}
{"id":"bd-2fy","title":"Fix I20: config glob patterns don't protect subtrees","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-02-15T21:07:57.985753131Z","created_by":"ubuntu","updated_at":"2026-02-15T21:08:56.917237540Z","closed_at":"2026-02-15T21:08:56.917204048Z","close_reason":"Already fixed - matches_config_pattern walks ancestors so subtrees are protected","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2g6","title":"Replace remaining unchecked ballast pool size multiplications with safe helper","description":"RedWren fixed one site in status --json (bd-3q8) but 5 more identical unchecked file_count * file_size_bytes multiplications remain in cli_app.rs (lines ~1777, 1791, 2426, 2481, 2868). All should use ballast_total_pool_bytes() helper.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T23:13:05.378223597Z","created_by":"ubuntu","updated_at":"2026-02-15T23:14:17.148301011Z","closed_at":"2026-02-15T23:14:17.148215310Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2g8","title":"Clippy debt burn-down slice: daemon self-monitor literals/closures","description":"Address top blocking clippy -D warnings findings in src/daemon/self_monitor.rs with minimal behavioral change, validate with rch targeted checks, and report remaining blockers.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:15:24.681176080Z","created_by":"ubuntu","updated_at":"2026-02-15T16:16:53.809551932Z","closed_at":"2026-02-15T16:16:53.809528378Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"],"comments":[{"id":266,"issue_id":"bd-2g8","author":"Dicklesworthstone","text":"Completed narrow clippy debt slice in src/daemon/self_monitor.rs: fixed unreadable literal (-12_400_000.0) and replaced redundant closure with method reference (iter().all(ThreadStatus::is_healthy)). Validation: rch exec \"cargo test --lib self_monitor\" PASS; rch exec \"cargo check --all-targets\" PASS; cargo fmt --check PASS; rch exec \"cargo clippy --all-targets -- -D warnings\" still fails due broad pre-existing lint backlog, now at 79 errors.","created_at":"2026-02-15T16:16:51Z"}]}
{"id":"bd-2ht","title":"Fix C4: ballast status usize underflow when inventory > configured count","status":"closed","priority":0,"issue_type":"bug","created_at":"2026-02-15T21:20:32.697995362Z","created_by":"ubuntu","updated_at":"2026-02-15T21:21:41.782244098Z","closed_at":"2026-02-15T21:21:41.782225854Z","close_reason":"Already fixed: both subtraction sites use saturating_sub (lines 2403, 2454)","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2it","title":"sbh status command: real-time system health dashboard","description":"## Deliverable\nA status command that shows current system health, pressure levels, ballast inventory, and recent activity in a clear, informative format.\n\n## Technical Approach\n### Human Output\n```\nsbh status\n\nStorage Ballast Helper v0.1.0\n  Uptime: 3 days, 14 hours, 22 minutes\n  Config: /etc/sbh/config.toml\n\nPressure Status:\n  ┌──────────────┬───────────┬───────────┬─────────┬───────────┐\n  │ Mount Point  │ Total     │ Free      │ Free %  │ Level     │\n  ├──────────────┼───────────┼───────────┼─────────┼───────────┤\n  │ /data        │   1.8 TB  │   342 GB  │  18.5%  │ 🟢 GREEN  │\n  │ /            │   100 GB  │    23 GB  │  23.0%  │ 🟢 GREEN  │\n  │ /tmp (tmpfs) │    32 GB  │   4.8 GB  │  15.0%  │ 🟡 YELLOW │\n  │ /dev/shm     │   256 GB  │   198 GB  │  77.3%  │ 🟢 GREEN  │\n  └──────────────┴───────────┴───────────┴─────────┴───────────┘\n\nRate Estimate:\n  /data:     -12.4 MB/s (recovering)  ~∞ until threshold\n  /tmp:     +245.6 MB/s (filling)     ~18 seconds to threshold!\n\nBallast:\n  Files: 8/10 available (2 released under pressure)\n  Reclaimable: 8 GB\n\nRecent Activity (last hour):\n  Deletions: 12 items, 18.7 GB freed\n  Most common: cargo-target-* (8), .target_* (3), target/ (1)\n  Failures: 0\n```\n\n### JSON Output (--json)\n```json\n{\n  \"version\": \"0.1.0\",\n  \"uptime_seconds\": 307342,\n  \"pressure\": {\n    \"mounts\": [\n      {\"path\": \"/data\", \"total\": 1800000000000, \"free\": 342000000000, \"free_pct\": 18.5, \"level\": \"green\"},\n      ...\n    ],\n    \"overall\": \"yellow\"\n  },\n  \"rate\": {\n    \"/data\": {\"bytes_per_sec\": -12400000, \"trend\": \"recovering\", \"seconds_to_threshold\": null},\n    \"/tmp\": {\"bytes_per_sec\": 245600000, \"trend\": \"filling\", \"seconds_to_threshold\": 18}\n  },\n  \"ballast\": {\"available\": 8, \"total\": 10, \"released\": 2, \"reclaimable_bytes\": 8000000000},\n  \"recent_hour\": {\"deletions\": 12, \"bytes_freed\": 18700000000, \"failures\": 0}\n}\n```\n\n### Implementation\nReads from:\n- Live filesystem stats (PAL)\n- EWMA rate estimator (if daemon running, via shared state or status file)\n- SQLite database (recent activity)\n- Ballast inventory\n\nIf daemon is not running, still shows filesystem stats and database history but notes that live monitoring is inactive.\n\n## Acceptance Criteria\n- Shows all monitored mount points with pressure levels\n- Color-coded pressure levels (green/yellow/orange/red)\n- Rate estimates with time-to-threshold\n- Ballast inventory status\n- Recent activity summary\n- Works even when daemon is not running (degraded mode)\n- JSON mode produces complete, parseable output\n- Unit tests for formatting functions","acceptance_criteria":"1. Unit tests cover status rendering, JSON schema, and degraded-mode state handling. 2. Integration tests validate daemon state file ingestion plus live monitor metrics merging. 3. E2E scenarios verify behavior when daemon is running, stopped, stale, or partially unavailable. 4. Command performance stays bounded under high activity history. 5. Detailed status logs include source freshness, missing-signal reasons, and fallback mode transitions.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T16:52:25.394142213Z","created_by":"ubuntu","updated_at":"2026-02-14T21:56:31.896019766Z","closed_at":"2026-02-14T21:56:31.895948503Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"],"dependencies":[{"issue_id":"bd-2it","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2it","depends_on_id":"bd-3cj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":267,"issue_id":"bd-2it","author":"Dicklesworthstone","text":"REVIEW-2: Removed bd-2np dependency. sbh status works in degraded mode without state.json: shows direct fs stats from statvfs() + database query for recent events. When state.json is available (daemon running), status ADDITIONALLY shows live EWMA predictions, PID state, scan activity. The state.json read is opportunistic, not required.","created_at":"2026-02-14T19:02:55Z"}]}
{"id":"bd-2j5","title":"Installer DX Parity Program (dcg-grade automation for curl|bash + update + bootstrap)","description":"## Background\nWe want `sbh`/`fsfs` install UX to be as user-friendly and automated as `/dp/destructive_command_guard` (`dcg`): one-command setup, robust verification, auto-configuration, guided defaults, and safe update+rollback.\n\n## Why this epic exists\nExisting install-related beads cover service setup and baseline CLI work, but they do not yet encode the full parity set that makes dcg's distribution path smooth for both humans and agents.\n\n## dcg parity baseline (concrete features to mirror)\n1. Unix installer with rich flags, platform detection, artifact targeting, preflight checks, checksum + optional sigstore verification, source-build fallback, PATH/completions automation, and polished summary UX.\n2. Windows PowerShell installer with equivalent integrity and path automation.\n3. Uninstall flow with safe cleanup + optional purge behavior.\n4. First-class updater with check/cache/force/rollback/version-list/system-user modes.\n5. Auto-configuration integrations for AI tooling with backup/merge semantics.\n6. Release artifact contract (target archives + `.sha256` + optional `.sigstore.json`) that installers/updaters can rely on deterministically.\n\n## Program goals\n- Batteries-included install and update flow with minimal manual steps.\n- Default-safe integrity checks and explicit remediation on failures.\n- Idempotent bootstrap and reversible rollback.\n- Self-contained bead graph (all rationale and intent in issue bodies/comments).\n\n## Success criteria\n1. Fresh machine: install -> verify -> run -> update succeeds via documented happy path.\n2. Installer automates PATH, completions, integration bootstrap, and first-run setup.\n3. Updater has backup+rollback with bounded retention and clear UX.\n4. E2E tests cover happy paths and failure injection scenarios.\n5. Docs are sufficient for future maintainers without external planning docs.","acceptance_criteria":"1. Epic scope covers Unix installer, Windows installer, uninstall parity, update/rollback, model/assets bootstrap, offline bundle support, and migration/self-healing without dropping functionality.\n2. Every feature bead in this epic links to both unit-test coverage (bd-2j5.19) and E2E verification (bd-2j5.14) directly or through dependencies.\n3. Structured observability (bd-2j5.18) is integrated so install/update failures are diagnosable from logs alone.\n4. Release artifact contract (bd-2j5.13) and docs handbook (bd-2j5.15) are complete before epic closure.\n5. Dependency graph remains acyclic and supports parallel work where safe.","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-14T21:02:47.540739742Z","created_by":"ubuntu","updated_at":"2026-02-15T04:38:52.418707349Z","closed_at":"2026-02-15T04:38:52.418681741Z","close_reason":"Epic acceptance met: all child beads are closed including unit matrix (bd-2j5.19), E2E matrix (bd-2j5.14), offline bundle mode (bd-2j5.20), update cache/notice policy (bd-2j5.9), release artifact contract (bd-2j5.13), structured observability (bd-2j5.18), and operator handbook (bd-2j5.15). Dependency graph remains acyclic with no blocked issues; key validation gates were re-run via rch during closure pass.","source_repo":".","compaction_level":0,"original_size":0,"labels":["automation","distribution","dx","installer"],"comments":[{"id":268,"issue_id":"bd-2j5","author":"Dicklesworthstone","text":"Implementation note: This epic intentionally mirrors concrete dcg behaviors that drive real-world usability: (1) deterministic artifact resolution, (2) default integrity checks, (3) idempotent auto-configuration, (4) updater rollback semantics, and (5) strong installer summaries with remediation hints. Keep parity decisions explicit: if we diverge, record why in child issue comments.","created_at":"2026-02-14T21:04:20Z"},{"id":269,"issue_id":"bd-2j5","author":"Dicklesworthstone","text":"Revision note (plan-space optimization): Added explicit Windows parity, uninstall parity, observability, unit-matrix, offline bundle, and migration/self-healing tracks. This closes major UX/completeness gaps while preserving all previously scoped functionality. Also promoted explicit acceptance criteria fields and test/logging gates across all children so completion standards are enforceable by tooling, not just narrative descriptions.","created_at":"2026-02-14T21:14:12Z"}]}
{"id":"bd-2j5.1","title":"Parity Matrix and Acceptance Spec for dcg-grade installer/update UX","description":"## Deliverable\nA parity matrix that translates dcg installer/update automation into explicit sbh/fsfs behavior requirements and CLI surface definitions.\n\n## Background and rationale\nWe want implementation to be deterministic, not vibe-driven. This issue codifies exactly what we are mirroring from dcg and what we intentionally diverge from.\n\n## Scope\n- Enumerate required installer flags (version pin, dest path, easy mode, verify/no-verify, from-source, offline/no-network, quiet/no-color, no-configure).\n- Enumerate updater controls (check, refresh cache, force, rollback, list versions).\n- Define required idempotency and rollback guarantees.\n- Define output/UX contract (human mode + machine mode).\n\n## Acceptance criteria\n1. Matrix maps each dcg automation capability to sbh behavior (implemented/planned/not-applicable + why).\n2. Gaps become linked child dependencies in this epic.\n3. Future maintainers can make scope decisions from this issue alone.","acceptance_criteria":"1. Parity matrix maps each dcg automation capability to sbh/fsfs behavior: implemented/planned/deferred with rationale.\n2. Matrix includes explicit CLI flag contract for install/update/bootstrap/uninstall flows.\n3. Matrix includes security policy for verification defaults, bypass behavior, and failure handling.\n4. Matrix references required unit/e2e/logging gates for every capability.\n5. Output is detailed enough to drive implementation without external planning docs.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:03:38.854226306Z","created_by":"ubuntu","updated_at":"2026-02-14T21:27:25.612362498Z","closed_at":"2026-02-14T21:27:25.612343672Z","close_reason":"Completed: parity matrix and acceptance spec documented in docs/installer-dx-parity-matrix.md with capability mapping, CLI contracts, security policy, and gate/bead linkage.","source_repo":".","compaction_level":0,"original_size":0,"labels":["dx","installer","planning"],"dependencies":[{"issue_id":"bd-2j5.1","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":270,"issue_id":"bd-2j5.1","author":"Dicklesworthstone","text":"Implemented parity matrix artifact at docs/installer-dx-parity-matrix.md. Includes dcg->sbh capability mapping with implemented/planned/deferred statuses, explicit CLI flag contracts (install/update/bootstrap/uninstall), security defaults/bypass policy, and required unit/e2e/observability gates mapped to beads.","created_at":"2026-02-14T21:27:22Z"}]}
{"id":"bd-2j5.10","title":"Updater backups, rollback flow, and retention pruning","description":"## Deliverable\nUpdater backup snapshots, rollback command support, and bounded retention pruning.\n\n## Background and rationale\nAutomatic updates without rollback are operationally unsafe.\n\n## Scope\n- Store pre-update binary/config snapshots before replacement.\n- Add rollback flow (latest or selected prior version).\n- Prune old backups by policy while preserving recent recovery points.\n\n## Acceptance criteria\n1. Failed update can be rolled back in one command.\n2. Backup inventory is inspectable (list timestamps/versions).\n3. Retention policy prevents unbounded disk growth.","acceptance_criteria":"1. Update process always captures restore points before replacement.\n2. Rollback supports latest and selected prior versions deterministically.\n3. Retention pruning enforces bounds without deleting required recovery points.\n4. Unit tests cover backup inventory and rollback selection logic.\n5. E2E validates failed-update recovery and rollback logging.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:03:39.734964821Z","created_by":"ubuntu","updated_at":"2026-02-15T02:33:14.002388112Z","closed_at":"2026-02-15T02:33:14.002322940Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["recovery","reliability","update"],"dependencies":[{"issue_id":"bd-2j5.10","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.10","depends_on_id":"bd-2j5.18","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.10","depends_on_id":"bd-2j5.8","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":271,"issue_id":"bd-2j5.10","author":"Dicklesworthstone","text":"Coordination note from CopperAnchor: rch validation surfaced compile blocker in src/cli/update.rs (E0433 undeclared BackupStore at line 306; downstream E0282). Reported to owning agent on Agent Mail thread bd-2j5.10.","created_at":"2026-02-15T02:25:33Z"}]}
{"id":"bd-2j5.11","title":"Guided first-run install wizard + non-interactive --auto mode","description":"## Deliverable\nGuided first-run installer wizard plus non-interactive `--auto` mode.\n\n## Background and rationale\nNew users should get smart defaults, while automation users need deterministic non-interactive behavior.\n\n## Scope\n- Interactive flow for selecting install mode, watched paths, and ballast defaults.\n- Clear summary/confirmation step before writing config and provisioning resources.\n- `--auto` path for CI/agent usage that applies documented defaults without prompts.\n\n## Acceptance criteria\n1. Interactive mode reduces manual post-install editing for first-time users.\n2. `--auto` mode is fully non-interactive and script-safe.\n3. Wizard choices map cleanly to generated config with reproducible output.","acceptance_criteria":"1. Interactive wizard provides guided defaults and explicit confirmation before mutation.\n2. `--auto` mode is fully non-interactive and deterministic for automation.\n3. Wizard and auto outputs include config decisions and safety-impacting choices.\n4. Unit tests cover wizard decision mapping and non-interactive defaults.\n5. E2E validates first-run onboarding and repeat-run idempotency with detailed logs.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T21:03:39.825228176Z","created_by":"ubuntu","updated_at":"2026-02-15T00:11:41.817560945Z","closed_at":"2026-02-15T00:11:41.817497566Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["installer","onboarding","ux"],"dependencies":[{"issue_id":"bd-2j5.11","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.11","depends_on_id":"bd-2j5.2","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.11","depends_on_id":"bd-2j5.21","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.11","depends_on_id":"bd-2j5.6","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.11","depends_on_id":"bd-2j5.7","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-2j5.12","title":"Automatic model/asset bootstrap: download, verify, cache, prefetch","description":"## Deliverable\nAutomatic model/asset bootstrap pipeline (download, verify, cache, optional prefetch) for components that require external model/data bundles.\n\n## Background and rationale\nUser request explicitly calls for automatic model download and batteries-included setup. This must be explicit, policy-driven, and safe.\n\n## Scope\n- Define artifact manifest format (name, version, checksum, source URL, size, signature info).\n- Implement resumable download + integrity verification + local cache layout.\n- Add CLI controls for prefetch, offline mode, and cache inspection/cleanup.\n- Integrate bootstrap into install/update where relevant.\n\n## Acceptance criteria\n1. Required model/assets can be fetched automatically during install/update.\n2. Corrupt or partial downloads are detected and recovered safely.\n3. Offline mode fails fast with clear instructions when required assets are missing.","acceptance_criteria":"1. Required model/assets can be auto-fetched, verified, cached, and reused safely.\n2. Partial/corrupt downloads are detected and recovered without inconsistent state.\n3. Offline behavior is explicit: missing required assets fail fast with remediation.\n4. Unit tests cover manifest parsing, checksum validation, and cache policy logic.\n5. E2E validates online and offline asset bootstrap paths with detailed logs.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:03:39.917102900Z","created_by":"ubuntu","updated_at":"2026-02-15T00:03:22.811104591Z","closed_at":"2026-02-15T00:03:22.811010685Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["assets","automation","installer"],"dependencies":[{"issue_id":"bd-2j5.12","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.12","depends_on_id":"bd-2j5.2","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.12","depends_on_id":"bd-2j5.3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.12","depends_on_id":"bd-2j5.4","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.12","depends_on_id":"bd-2j5.7","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":272,"issue_id":"bd-2j5.12","author":"Dicklesworthstone","text":"Model/bootstrap note: this issue exists because user explicitly requested automatic model download and batteries-included setup. Treat model/assets as first-class artifacts with manifest-driven integrity, resumable fetch, and offline diagnostics.","created_at":"2026-02-14T21:04:20Z"}]}
{"id":"bd-2j5.13","title":"Release artifact publishing contract for installer/update compatibility","description":"## Deliverable\nRelease pipeline alignment so installers/updaters can rely on consistent artifact naming, checksums, signatures, and metadata.\n\n## Background and rationale\nInstaller quality is inseparable from release artifact discipline.\n\n## Scope\n- Define required release outputs per platform.\n- Ensure CI produces checksums/signature bundles and publishes predictable URLs.\n- Validate artifact contract continuously in CI to catch regressions before release.\n\n## Acceptance criteria\n1. Every supported target publishes installer-consumable artifacts with metadata.\n2. CI fails when artifact naming/metadata contract is broken.\n3. Install/update logic no longer depends on ad-hoc release layout assumptions.","acceptance_criteria":"1. CI publishes deterministic installer/updater artifacts for all supported targets.\n2. Release outputs include integrity metadata required by verification policy.\n3. Contract checks fail CI on naming/metadata drift.\n4. Unit/CI tests validate artifact contract manifests.\n5. Contract supports both online and bundle-based install/update flows.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:03:40.010974145Z","created_by":"ubuntu","updated_at":"2026-02-15T02:01:19.659149518Z","closed_at":"2026-02-15T02:01:19.659067213Z","close_reason":"Release artifact publishing contract fully implemented: ReleaseArtifactContract with deterministic naming for 6 targets, validate_release_assets() for CI enforcement, supply chain verification (SHA256+sigstore), install scripts aligned with contract. 11 unit tests cover all acceptance criteria. CI validates via cargo test --lib.","source_repo":".","compaction_level":0,"original_size":0,"labels":["ci","installer","release"],"dependencies":[{"issue_id":"bd-2j5.13","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.13","depends_on_id":"bd-2j5.3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.13","depends_on_id":"bd-2j5.4","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.13","depends_on_id":"bd-5vm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-2j5.14","title":"Installer/update/integration E2E matrix with failure injection","description":"## Deliverable\nComprehensive installer/update/integration test matrix, including golden UX snapshots and failure-injection scenarios.\n\n## Background and rationale\nThese workflows are safety-critical and user-facing; regressions here have outsized impact.\n\n## Scope\n- E2E tests for fresh install, reinstall, uninstall, update, rollback, and bootstrap integrations.\n- Failure injection for network loss, checksum mismatch, unsupported targets, missing prerequisites.\n- Golden output snapshots for key user-visible installer/update screens.\n\n## Acceptance criteria\n1. Core workflows are test-covered on Linux and macOS paths, with Windows parity where feasible.\n2. Failure paths produce deterministic remediation messages.\n3. CI gate prevents shipping installer/update regressions.","acceptance_criteria":"1. E2E suite covers install, reinstall, update, rollback, uninstall, bootstrap, and bundle/offline scenarios.\n2. E2E suite includes failure injection: network loss, checksum mismatch, permission failure, unsupported target, partial install.\n3. Every E2E run captures detailed logs and structured event artifacts for diagnosis.\n4. E2E scripts are CI-runnable and deterministic across repeated runs.\n5. E2E gate blocks release when critical workflows regress.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:03:40.104061010Z","created_by":"ubuntu","updated_at":"2026-02-15T04:35:33.192316298Z","closed_at":"2026-02-15T04:33:55.367570189Z","close_reason":"Acceptance met: installer/update integration E2E matrix passes with failure injection and lifecycle coverage (rch cargo test --test installer_e2e: 43 passed), offline/update integration scenarios pass (rch cargo test --test integration_tests -- update_check_), and CI compile gate remains green (rch cargo check --all-targets). e2e shell suite script is syntactically valid (bash -n scripts/e2e_test.sh).","source_repo":".","compaction_level":0,"original_size":0,"labels":["e2e","installer","testing"],"dependencies":[{"issue_id":"bd-2j5.14","depends_on_id":"bd-26g","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.10","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.11","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.12","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.13","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.16","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.17","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.18","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.19","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.2","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.20","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.21","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.4","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.6","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.7","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.8","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2j5.9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2pi","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-2q9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-3i3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.14","depends_on_id":"bd-7ls","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":273,"issue_id":"bd-2j5.14","author":"Dicklesworthstone","text":"Testing bar: include failure injection for checksum mismatch, truncated download, permission errors, unsupported target, and rollback failure. We want deterministic reproductions rather than ad-hoc manual QA.","created_at":"2026-02-14T21:04:20Z"},{"id":274,"issue_id":"bd-2j5.14","author":"Dicklesworthstone","text":"Added blocker-clearing E2E coverage in tests/installer_e2e.rs for offline updater failure injection: (1) e2e_update_offline_bundle_bad_checksum_fails_without_network_download and (2) e2e_update_offline_bundle_missing_manifest_fails_without_network_download, plus helper create_update_bundle(). Validation: cargo fmt --check -- tests/installer_e2e.rs ✅; rch exec \"cargo test --test installer_e2e -- e2e_update_offline_bundle\" ✅ (2/2); rch exec \"cargo test --test installer_e2e -- e2e_update_\" ✅ (4/4); rch exec \"cargo check --test installer_e2e\" ✅. Note: rch exec \"cargo check --all-targets\" currently fails on unrelated examples/* API drift outside this slice.","created_at":"2026-02-15T04:25:32Z"},{"id":275,"issue_id":"bd-2j5.14","author":"LavenderOak","text":"Added installer_e2e failure-injection slice in tests/installer_e2e.rs: new tests e2e_update_offline_bundle_unsupported_target_fails_without_network_download and e2e_update_offline_bundle_blocked_install_path_fails_deterministically. Also added update_sequence_test_lock guard and applied it to full offline-update (check_only=false) tests to eliminate tempdir millisecond collision flake during parallel runs. Validation: rch exec 'cargo test --test installer_e2e -- e2e_update_offline_bundle_unsupported_target_fails_without_network_download' PASS; rch exec 'cargo test --test installer_e2e -- e2e_update_offline_bundle_blocked_install_path_fails_deterministically' PASS; rch exec 'cargo test --test installer_e2e -- e2e_update_offline_bundle' PASS (4/4); rch exec 'cargo check --test installer_e2e' PASS; cargo fmt --check PASS; rch exec 'cargo check --all-targets' PASS. rch exec 'cargo clippy --all-targets -- -D warnings' currently fails in many pre-existing files outside this slice (e.g., src/daemon/self_monitor.rs, src/logger/stats.rs, src/decision_plane_tests.rs, src/cli/bootstrap.rs).","created_at":"2026-02-15T04:35:33Z"}]}
{"id":"bd-2j5.15","title":"Installer/Updater operator handbook with troubleshooting and security model","description":"## Deliverable\nOperator-facing installer/update handbook that is self-sufficient for humans and agents.\n\n## Background and rationale\nThe easiest system to use is the one whose expected behavior is clearly documented with examples and troubleshooting.\n\n## Scope\n- Document happy path + advanced flags + rollback + recovery procedures.\n- Include security model (what is verified, what is optional, what is bypassed by `--no-verify`).\n- Provide copy-paste recipes for common deployment scenarios (desktop dev, headless server, CI agent host).\n\n## Acceptance criteria\n1. README/docs cover complete installer/update lifecycle.\n2. Troubleshooting includes concrete commands and expected outputs.\n3. Documentation remains aligned with actual CLI flags and test assertions.","acceptance_criteria":"1. Documentation covers full lifecycle: install, update, rollback, uninstall, bootstrap, offline bundle mode.\n2. Security model and bypass implications are explicit and example-driven.\n3. Troubleshooting includes concrete command sequences and expected diagnostics.\n4. Docs align with implemented flags and validated test behavior.\n5. Handbook is sufficient for both human operators and agent workflows.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T21:03:40.197974956Z","created_by":"ubuntu","updated_at":"2026-02-15T04:38:38.904245544Z","closed_at":"2026-02-15T04:38:38.904222581Z","close_reason":"Acceptance met: operator handbook coverage is present across README, docs/installer-dx-parity-matrix.md, and docs/testing-and-logging.md for install, update, rollback, uninstall, bootstrap, offline mode, security model, and troubleshooting workflows. Parity matrix command/flag contract now aligns with CLI semantics including update --version, update --list-backups, and bootstrap via install/setup integration paths.","source_repo":".","compaction_level":0,"original_size":0,"labels":["docs","installer","update"],"dependencies":[{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5.10","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5.11","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5.12","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5.13","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5.14","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5.16","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5.17","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5.18","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5.19","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5.2","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5.20","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5.21","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.15","depends_on_id":"bd-2j5.8","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":276,"issue_id":"bd-2j5.15","author":"Dicklesworthstone","text":"Support docs slice started by CopperAnchor while dependency blockers remain: added operator-runbook/security/troubleshooting content to README and docs parity/testing guides to reduce handoff risk once implementation beads close.","created_at":"2026-02-15T02:25:33Z"},{"id":277,"issue_id":"bd-2j5.15","author":"Dicklesworthstone","text":"Taking a non-overlapping docs slice: add operator-facing guidance for update metadata cache, refresh semantics, and opt-out controls in README.md + docs/testing-and-logging.md; will keep aligned with implemented CLI/config behavior and validate formatting.","created_at":"2026-02-15T04:24:26Z"},{"id":278,"issue_id":"bd-2j5.15","author":"ubuntu","text":"Reopened: Correcting close reason text after shell escaping stripped flag names.","created_at":"2026-02-15T04:38:35Z"}]}
{"id":"bd-2j5.16","title":"Windows PowerShell installer parity with deterministic verification and rollback support","description":"## Deliverable\nFull Windows installer parity (PowerShell) matching Unix installer convenience and safety guarantees.\n\n## Background and rationale\n`dcg` has a first-class Windows path. For true batteries-included UX, we cannot leave Windows as second-class. Feature parity reduces support burden and avoids fragmented docs.\n\n## Scope\n- Ship `install.ps1` equivalent with version pinning, destination selection, easy-mode PATH update, and verification controls.\n- Implement deterministic Windows artifact resolution and integrity checks.\n- Ensure non-interactive CI/agent mode and human-friendly interactive mode.\n- Produce consistent summary output and machine-readable status.\n\n## Acceptance criteria\n1. Windows install supports latest + pinned version flows with deterministic artifact selection.\n2. Integrity checks (checksum and optional signature path) behave consistently with Unix policy.\n3. PATH/profile updates are idempotent and reversible.\n4. Unit tests cover argument parsing, artifact resolution, and PATH mutation logic.\n5. E2E test validates install -> verify -> update -> rollback -> uninstall with detailed step logs.","acceptance_criteria":"1. Windows installer feature parity is achieved for version pinning, verification, easy-mode PATH updates, and diagnostics.\n2. Behavior is deterministic and script-safe in non-interactive mode.\n3. Structured logs are emitted with parity to Unix operation phases.\n4. Unit tests cover Windows-specific parser/path/integrity logic.\n5. E2E validates complete Windows lifecycle with detailed logging.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:10:54.875579461Z","created_by":"ubuntu","updated_at":"2026-02-14T23:42:28.621266873Z","closed_at":"2026-02-14T23:42:28.621240193Z","close_reason":"Created install.ps1 PowerShell installer with full parity: version pinning, SHA-256 verification, user/system modes, PATH automation, rollback support, dry-run, JSON output, structured event logging, tar/7z extraction","source_repo":".","compaction_level":0,"original_size":0,"labels":["dx","installer","windows"],"dependencies":[{"issue_id":"bd-2j5.16","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.16","depends_on_id":"bd-2j5.1","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.16","depends_on_id":"bd-2j5.18","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.16","depends_on_id":"bd-2j5.2","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.16","depends_on_id":"bd-2j5.3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.16","depends_on_id":"bd-2j5.4","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-2j5.17","title":"Uninstall parity: safe cleanup modes, dry-run plans, and reversible teardown","description":"## Deliverable\nComprehensive uninstall parity with safe cleanup controls and reversible integration teardown.\n\n## Background and rationale\nGreat installers require equally robust uninstall paths. Users need confident cleanup without accidental data loss.\n\n## Scope\n- Implement uninstall modes: conservative default, keep-data/keep-config/keep-assets, and explicit purge.\n- Remove auto-configured integrations/hooks with backup-first semantics.\n- Add dry-run/plan output showing exactly what will be removed or kept.\n- Support partial-failure recovery so uninstall can be retried safely.\n\n## Acceptance criteria\n1. Uninstall behavior is explicit, idempotent, and never silently destructive.\n2. Integration teardown restores/retains user config according to selected mode.\n3. Dry-run output is complete enough for operator review before execution.\n4. Unit tests cover cleanup decision matrix and backup/restore paths.\n5. E2E tests cover keep-* variants, purge flow, and partial-failure recovery with detailed logs.","acceptance_criteria":"1. Uninstall exposes safe default, keep-* modes, and explicit purge with clear previews.\n2. Teardown reverses installer-managed integrations safely with backup awareness.\n3. Partial-failure paths are recoverable and idempotent.\n4. Unit tests cover deletion policy matrix and teardown sequencing.\n5. E2E validates uninstall variants with detailed logs and outcome checks.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:10:54.965794615Z","created_by":"ubuntu","updated_at":"2026-02-15T00:07:02.187555Z","closed_at":"2026-02-15T00:07:02.187472856Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["installer","safety","uninstall"],"dependencies":[{"issue_id":"bd-2j5.17","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.17","depends_on_id":"bd-2j5.12","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.17","depends_on_id":"bd-2j5.18","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.17","depends_on_id":"bd-2j5.7","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-2j5.18","title":"Structured installer/update observability with trace IDs and phase-level diagnostics","description":"## Deliverable\nStructured installer/update observability with trace IDs, phase timings, and dual human+machine output.\n\n## Background and rationale\nThe user explicitly wants confidence that everything works perfectly. That requires rich logs designed for debugging and automation, not ad-hoc println output.\n\n## Scope\n- Define event schema for installer/update/bootstrap operations.\n- Emit per-phase start/end/failure events with trace IDs and duration metrics.\n- Support human-readable and JSONL outputs without loss of diagnostic detail.\n- Capture remediation hints and decision reasons in failure events.\n\n## Acceptance criteria\n1. Every major installer/update phase emits structured start/success/failure records.\n2. Trace IDs allow correlating multi-step operations end-to-end.\n3. Logs are stable enough for automated assertions in CI.\n4. Unit tests validate event schema and serialization contracts.\n5. E2E scripts archive structured logs as artifacts for failed runs.","acceptance_criteria":"1. Installer/update flows emit structured start/success/failure events with trace IDs.\n2. Event schema is stable and machine-assertable in tests.\n3. Human summaries and JSON logs are consistent in meaning.\n4. Unit tests validate schema serialization and reason-code contracts.\n5. E2E archives logs and traces for failed scenarios automatically.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:10:55.058137386Z","created_by":"ubuntu","updated_at":"2026-02-14T22:56:22.288299837Z","closed_at":"2026-02-14T22:56:22.288281944Z","close_reason":"Implemented structured installer observability in scripts/install.sh with trace IDs, phase-level start/success/failure JSONL events (--event-log), and human/json output parity; added E2E assertions for trace/event schema stability","source_repo":".","compaction_level":0,"original_size":0,"labels":["installer","logging","observability"],"dependencies":[{"issue_id":"bd-2j5.18","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-2j5.19","title":"Comprehensive unit-test matrix for installer/update/bootstrap/rollback internals","description":"## Deliverable\nComprehensive unit test matrix for installer, updater, bootstrap, and rollback internals.\n\n## Background and rationale\nReliability in install/update flows depends on deterministic behavior under edge cases. Unit tests must lock those contracts before implementation scales.\n\n## Scope\n- Table-driven tests for target resolution, checksums, signature policy, rollback selection, cache TTL, and retention pruning.\n- Tests for shell/profile mutation idempotency and path normalization.\n- Snapshot/golden tests for key machine-readable outputs.\n- Negative tests for malformed manifests, missing assets, and corrupt metadata.\n\n## Acceptance criteria\n1. Critical decision logic has deterministic unit coverage with explicit edge-case cases.\n2. Golden outputs protect CLI/JSON contract stability.\n3. Failure cases produce precise reason codes/messages validated by tests.\n4. Coverage includes both Unix and Windows-specific logic branches.\n5. Test logs are detailed enough to diagnose failures without rerunning interactively.","acceptance_criteria":"1. Unit matrix covers all core installer/update/bootstrap/rollback decision modules.\n2. Edge cases and malformed input paths have explicit tests.\n3. Golden outputs protect machine-readable contract stability.\n4. Tests include platform-specific branches (Unix and Windows logic).\n5. Unit test logs are detailed enough for non-interactive diagnosis.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:10:55.147239544Z","created_by":"ubuntu","updated_at":"2026-02-15T04:30:44.706337755Z","closed_at":"2026-02-15T04:30:44.706317336Z","close_reason":"Acceptance met: comprehensive installer/update/bootstrap/rollback unit matrix is now green across modules (full rch cargo test --lib passed 765 tests) with explicit edge-case coverage; machine-readable contracts and failure paths validated; all-target compile gate revalidated via rch cargo check --all-targets.","source_repo":".","compaction_level":0,"original_size":0,"labels":["installer","testing","unit"],"dependencies":[{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.10","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.12","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.16","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.17","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.18","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.2","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.20","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.21","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.5","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.6","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.7","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.8","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.19","depends_on_id":"bd-2j5.9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":279,"issue_id":"bd-2j5.19","author":"AmberFalcon","text":"Taking non-overlap unit-test matrix slice on src/cli/from_source.rs (exclusive reservation). Focus: deterministic branch/edge-case coverage for from-source installer logic; avoiding currently reserved integration/E2E/update surfaces.","created_at":"2026-02-15T03:27:53Z"},{"id":280,"issue_id":"bd-2j5.19","author":"AmberFalcon","text":"Completed from_source unit-test matrix slice in src/cli/from_source.rs: added deterministic probe_version edge-case tests for failing command exit and fallback-first-line behavior without semver token (unix script harness), and tightened existing tests to avoid clippy issues (Path comparison, extension assertion via Path::extension, redundant closure removal). Validation: cargo fmt --check OK; rch exec cargo test --lib from_source::tests::probe_version_returns_none_when_command_fails OK; rch exec cargo test --lib from_source::tests::probe_version_falls_back_to_first_line_without_semver OK; rch exec cargo check --lib OK. rch exec cargo check --all-targets and rch exec cargo clippy --all-targets -- -D warnings still fail on unrelated pre-existing installer_e2e and other files outside this slice.","created_at":"2026-02-15T03:32:02Z"},{"id":281,"issue_id":"bd-2j5.19","author":"Dicklesworthstone","text":"Validation note from CopperAnchor: rch exec \"cargo check --all-targets\" currently blocked by API drift in reserved tests/installer_e2e.rs against current cli::update BackupStore/UpdateOptions signatures (create args, inventory field rename, rollback signature/order, removed UpdateOptions fields).","created_at":"2026-02-15T03:32:10Z"}]}
{"id":"bd-2j5.2","title":"Unix curl|bash Installer with polished UX and idempotent behavior","description":"## Deliverable\nA polished Unix `curl|bash` installer entrypoint with explicit flags and sensible defaults for new users.\n\n## Background and rationale\ndcg's installer succeeds because it is practical: one command works, advanced users still get control, and output is readable under stress.\n\n## Scope\n- Implement shell installer command interface and argument parsing.\n- Support user/system destination modes and dry-run mode.\n- Provide consistent UX framing (headers, progress sections, summary block, clear failure remediations).\n- Keep behavior idempotent on repeated runs.\n\n## Acceptance criteria\n1. Fresh install and repeat install both succeed without destructive side effects.\n2. `--help` clearly documents all flags and examples.\n3. Installer output remains clear in both TTY and non-TTY environments.","acceptance_criteria":"1. Unix curl|bash installer supports idempotent fresh/repeat installs with clear summary output.\n2. Installer supports documented flags and deterministic non-interactive behavior for CI/agent usage.\n3. Installer emits structured observability events per major phase.\n4. Unit tests validate parser and control-flow decisions for installer modes.\n5. E2E tests validate install path with failure injection and detailed logs.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:03:38.949794051Z","created_by":"ubuntu","updated_at":"2026-02-14T22:53:53.357239668Z","closed_at":"2026-02-14T22:53:53.357220422Z","close_reason":"Implemented scripts/install.sh Unix installer with explicit flags, dry-run, user/system destination handling, idempotent re-run logic, local-fixture test coverage in scripts/e2e_test.sh, and README installer docs","source_repo":".","compaction_level":0,"original_size":0,"labels":["dx","installer","unix"],"dependencies":[{"issue_id":"bd-2j5.2","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.2","depends_on_id":"bd-2j5.1","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.2","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":282,"issue_id":"bd-2j5.2","author":"Dicklesworthstone","text":"UX contract detail: treat installer output as an operator interface. Every failure path must include: cause, what was attempted, and exact copy-paste recovery command. This mirrors dcg's practical diagnostics and is critical for agent-run sessions where logs are often the only artifact.","created_at":"2026-02-14T21:04:20Z"}]}
{"id":"bd-2j5.20","title":"Offline/airgapped bundle mode for installer/update/model assets","description":"## Deliverable\nOffline/airgapped bundle mode for installer + updater + model/assets bootstrap.\n\n## Background and rationale\nUsers in restricted environments still need full batteries-included setup. Bundle mode prevents installer UX collapse when network access is unavailable.\n\n## Scope\n- Define bundle artifact format containing binaries, checksums, signatures, and required model/assets manifests.\n- Add commands to create and consume bundles deterministically.\n- Validate bundle integrity before install/update.\n- Ensure update/rollback logic works with bundle-backed sources.\n\n## Acceptance criteria\n1. Offline install from bundle supports full bootstrap with no network dependency.\n2. Bundle verification enforces integrity exactly as online flow does.\n3. Missing/invalid bundle components fail with actionable diagnostics.\n4. Unit tests validate bundle manifest parsing and integrity checks.\n5. E2E tests simulate airgapped install/update with verbose logs and artifact capture.","acceptance_criteria":"1. Bundle mode supports fully offline install/update/bootstrap for required assets.\n2. Bundle integrity checks enforce same trust model as online flow.\n3. Bundle build/consume commands are deterministic and documented.\n4. Unit tests validate bundle manifests and error handling.\n5. E2E validates airgapped workflows with detailed logs.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T21:10:55.247556839Z","created_by":"ubuntu","updated_at":"2026-02-15T04:30:28.465541169Z","closed_at":"2026-02-15T04:30:28.465514589Z","close_reason":"Acceptance met: offline bundle install/update/bootstrap path, deterministic bundle manifest/consume, integrity checks, unit+integration+E2E coverage, and fresh rch validation (cargo test --lib; cargo test --test integration_tests -- update_check_; cargo check --all-targets).","source_repo":".","compaction_level":0,"original_size":0,"labels":["assets","installer","offline"],"dependencies":[{"issue_id":"bd-2j5.20","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.20","depends_on_id":"bd-2j5.12","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.20","depends_on_id":"bd-2j5.13","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.20","depends_on_id":"bd-2j5.4","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.20","depends_on_id":"bd-2j5.8","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":283,"issue_id":"bd-2j5.20","author":"Dicklesworthstone","text":"Implemented core offline bundle primitives: (1) added typed bundle manifest + host-target bundle resolution in src/cli/mod.rs with strict artifact-name validation and local file existence checks, and (2) added bundle-aware asset hydration/readiness in src/cli/assets.rs (FetchOptions.bundle_root, restore_from_bundle flow, offline_readiness_with_bundle). Added unit tests for success/failure paths. Full rch cargo check is currently blocked by pre-existing compile errors in src/cli/update.rs (BackupStore unresolved).","created_at":"2026-02-15T02:25:09Z"},{"id":284,"issue_id":"bd-2j5.20","author":"Dicklesworthstone","text":"Progress (JadeBass): tightened offline bundle contract in src/cli/mod.rs to allow nested paths by basename validation while rejecting parent-dir traversal (..). Added tests for nested-path success and traversal rejection. Expanded src/cli/assets.rs tests for flat bundle layout restore/readiness. Validation: cargo fmt OK; rch exec \"cargo check --lib\" OK. Full all-target check remains blocked by unrelated unsafe blocks in src/cli/update.rs test code under forbid(unsafe_code).","created_at":"2026-02-15T02:30:25Z"},{"id":285,"issue_id":"bd-2j5.20","author":"Dicklesworthstone","text":"CobaltOtter progress slice: hardened offline bundle asset restore/readiness path safety in src/cli/assets.rs by rejecting non-normal/absolute/parent components before bundle lookup (prevents ../ escape). Added unit coverage: fetch_offline_rejects_bundle_parent_dir_escape and offline_readiness_rejects_bundle_parent_dir_escape. Updated docs/installer-dx-parity-matrix.md with explicit offline bundle safety contract (nested->flat lookup, path safety, sha256 verify, fail-fast offline diagnostics). Validation: rch exec \"cargo test --lib assets\" PASS; rch exec \"cargo check --all-targets\" PASS. Global rch clippy all-targets currently fails in unrelated pre-existing files outside this slice.","created_at":"2026-02-15T03:12:23Z"},{"id":286,"issue_id":"bd-2j5.20","author":"Dicklesworthstone","text":"Progress (RedWolf): added installer-side offline bundle preflight API in src/cli/install.rs via run_install_sequence_with_bundle(opts, bundle_manifest_path), including host-aware bundle contract validation + checksum integrity verification using verify_artifact_supply_chain. Added two unit tests for success and checksum-failure paths. Hardened src/cli/mod.rs bundle parser with manifest schema-version gate (expects version=1) and added rejection test for unsupported manifest versions. Validation: cargo fmt --check OK; rch exec \"cargo test --lib install_sequence_with_bundle_preflight\" OK; rch exec \"cargo test --lib bundle_contract_rejects_unsupported_manifest_version\" OK; rch exec \"cargo check --all-targets\" OK. Repo-wide clippy -D warnings remains failing on many pre-existing files outside this slice.","created_at":"2026-02-15T03:14:40Z"},{"id":287,"issue_id":"bd-2j5.20","author":"Dicklesworthstone","text":"Follow-up (RedWolf): expanded installer bundle-preflight edge-case tests in src/cli/install.rs with (1) dry-run plan-only behavior when bundle manifest path is provided and (2) non-dry-run failure path for missing bundle manifest file. Validation: rch exec \"cargo test --lib install_sequence_with_bundle_preflight\" OK; rch exec \"cargo check --all-targets\" OK. Note: cargo fmt --check currently fails due unrelated formatting deltas in src/cli/from_source.rs and src/cli/integrations.rs owned by other agents; touched files are formatted.","created_at":"2026-02-15T03:17:11Z"},{"id":288,"issue_id":"bd-2j5.20","author":"Dicklesworthstone","text":"Landed additional offline-bundle core APIs in src/cli/assets.rs: build_offline_bundle (deterministic sorted manifest snapshot + per-asset copied/missing/corrupt status), bundle_manifest_path/load_offline_bundle_manifest helpers, and offline_bundle_readiness (bundle-only checksum/readiness checks). Added targeted tests for deterministic export ordering, missing/corrupt diagnostics, bundle-only readiness, and invalid manifest handling. Validation: rch cargo test --lib assets ✅, rch cargo check --lib ✅, rch clippy --lib with known unrelated suppressions ✅. all-targets check still blocked by unrelated tests/installer_e2e drift.","created_at":"2026-02-15T03:30:44Z"},{"id":289,"issue_id":"bd-2j5.20","author":"Dicklesworthstone","text":"Completed updater offline-bundle follow-up wiring slice in src/cli/update.rs + src/cli_app.rs. Added/preserved focused tests for check-only + pinned tag mismatch and validated with rch targeted runs (lib tests + update CLI parse bin test). Applied clippy cleanup in touched updater block (map_or_else). cargo fmt --check passes. rch cargo check --all-targets currently blocked by unrelated tests/installer_e2e.rs API drift (backup/update test signatures/fields). Releasing updater/cli_app reservations.","created_at":"2026-02-15T03:35:42Z"},{"id":290,"issue_id":"bd-2j5.20","author":"Dicklesworthstone","text":"Added integration offline-bundle coverage in tests/integration_tests.rs: update_check_with_offline_bundle_manifest_reports_target_json and update_check_with_offline_bundle_and_pinned_tag_mismatch_fails_json, plus helper create_offline_update_bundle for deterministic local manifest/archive/checksum setup. Validation: cargo fmt --check ✅, rch exec \"cargo test --test integration_tests -- update_check_with_offline_bundle\" ✅ (2/2), rch exec \"cargo check --all-targets\" ✅. Targeted clippy for integration test is blocked by unrelated pre-existing src/monitor/fs_stats.rs lint (significant_drop_tightening).","created_at":"2026-02-15T03:40:31Z"},{"id":291,"issue_id":"bd-2j5.20","author":"Dicklesworthstone","text":"CopperAnchor start: implementing E2E offline-bundle update scenarios in scripts/e2e_test.sh (deterministic local fixture + success/mismatch cases) to raise acceptance-criteria #5 coverage.","created_at":"2026-02-15T04:20:40Z"},{"id":292,"issue_id":"bd-2j5.20","author":"AmberFalcon","text":"Starting focused bd-2j5.20 updater hardening in src/cli/update.rs: add offline-bundle edge-case tests for dry-run+refresh-cache behavior, notice suppression, and same-version check-only semantics; will validate with rch check/tests and report.","created_at":"2026-02-15T04:22:50Z"},{"id":293,"issue_id":"bd-2j5.20","author":"Dicklesworthstone","text":"TealDuck progress: added E2E offline-bundle update coverage in scripts/e2e_test.sh via deterministic local fixture helper + success/mismatch JSON cases for sbh update --check --offline. Validation: bash -n scripts/e2e_test.sh PASS; rch exec \"cargo test --test integration_tests -- update_check_with_offline_bundle\" PASS (2 tests).","created_at":"2026-02-15T04:23:42Z"},{"id":294,"issue_id":"bd-2j5.20","author":"Dicklesworthstone","text":"Taking non-overlap follow-up slice: tighten bundle artifact path normalization in src/cli/mod.rs to reject non-normal components (absolute/root/prefix/dot traversal variants) and add focused unit tests; validate with rch.","created_at":"2026-02-15T04:23:52Z"},{"id":295,"issue_id":"bd-2j5.20","author":"Dicklesworthstone","text":"TealDuck validation follow-up: e2e script edits remain clean (git diff only scripts/e2e_test.sh). Gates: bash -n scripts/e2e_test.sh PASS; rch exec \"cargo test --test integration_tests -- update_check_with_offline_bundle\" PASS (2/2). Full rch exec \"cargo check --all-targets\" currently fails in pre-existing examples API drift (examples/pressure_monitor.rs + examples/scan_artifacts.rs); cargo fmt --check currently reports unrelated formatting deltas in examples/src/cli/update/tests files not touched in this slice.","created_at":"2026-02-15T04:24:29Z"},{"id":296,"issue_id":"bd-2j5.20","author":"Dicklesworthstone","text":"Contributed additional offline-path failure-injection E2E coverage via tests/installer_e2e.rs update tests: bad checksum and missing manifest now explicitly assert no network-download fallback in offline mode. See bd-2j5.14 comment for detailed validation commands/results.","created_at":"2026-02-15T04:25:32Z"}]}
{"id":"bd-2j5.21","title":"Installer bootstrap migration + self-healing for legacy/partial environments","description":"## Deliverable\nBootstrap migration and self-healing for existing configs/integrations across installer and updater runs.\n\n## Background and rationale\nReal users have drifted environments. A friendly installer must detect and repair outdated or partially-broken states automatically and safely.\n\n## Scope\n- Detect prior installer footprints and stale integration entries.\n- Apply deterministic migrations with timestamped backups.\n- Repair common broken states (partial installs, stale PATH entries, mismatched integration snippets).\n- Expose migration reports in both human summary and JSON output.\n\n## Acceptance criteria\n1. Legacy/partial states are migrated or repaired without manual editing in common cases.\n2. Every mutation is backup-first and reversible.\n3. Migration decisions are logged with clear reason codes.\n4. Unit tests cover migration matrix and rollback-on-failure behavior.\n5. E2E tests include upgrade-from-older-install scenarios with detailed logs.","acceptance_criteria":"1. Legacy and partial installations are detected and migrated/repaired safely.\n2. Every migration mutation is backup-first and reversible.\n3. Migration reason codes and actions are logged in structured output.\n4. Unit tests cover migration matrix and rollback-on-error behavior.\n5. E2E validates upgrade-from-older-environment scenarios with detailed logs.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T21:10:55.352543453Z","created_by":"ubuntu","updated_at":"2026-02-14T23:55:23.151868746Z","closed_at":"2026-02-14T23:55:23.151697846Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["automation","installer","migration"],"dependencies":[{"issue_id":"bd-2j5.21","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-2j5.3","title":"Platform/Arch Artifact Resolution Contract for installer/updater","description":"## Deliverable\nDeterministic platform/architecture detection and release artifact resolution for installer/update flows.\n\n## Background and rationale\nInstaller reliability depends on downloading the right artifact every time. dcg resolves target triples and artifact names deterministically.\n\n## Scope\n- Detect OS + arch + ABI variants and map to release targets.\n- Define canonical artifact naming contract (`tar.xz` on Unix, zip on Windows where applicable).\n- Support explicit version pin and channel selection logic.\n- Define failure strategy when target is unsupported.\n\n## Acceptance criteria\n1. All supported host triples map to exactly one artifact URL.\n2. Unsupported hosts fail with actionable guidance.\n3. Resolution behavior is shared between installer and updater (no drift).","acceptance_criteria":"1. Supported OS/arch combinations map deterministically to release artifacts with no ambiguity.\n2. Unsupported targets fail fast with actionable remediation text.\n3. Mapping contract is shared by installer and updater.\n4. Unit tests cover all supported mappings and edge/unknown targets.\n5. Mapping assumptions are reflected in release contract validation.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:03:39.062961415Z","created_by":"ubuntu","updated_at":"2026-02-14T21:34:34.372495164Z","closed_at":"2026-02-14T21:34:34.372473052Z","close_reason":"Implemented deterministic installer/updater target resolver + release artifact contract validation with unit tests","source_repo":".","compaction_level":0,"original_size":0,"labels":["installer","platform","release"],"dependencies":[{"issue_id":"bd-2j5.3","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.3","depends_on_id":"bd-2j5.1","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-2j5.4","title":"Installer Supply-Chain Verification (SHA256 + optional Sigstore)","description":"## Deliverable\nSupply-chain integrity pipeline with mandatory checksum verification and optional sigstore/cosign verification.\n\n## Background and rationale\nIntegrity validation is not optional in curl|bash workflows. It must be default-on and visible.\n\n## Scope\n- Download artifact checksum metadata and verify before extraction/install.\n- Implement optional signature verification path with graceful degradation messaging if cosign unavailable.\n- Add explicit `--no-verify` escape hatch with strong warning text.\n- Log/emit structured verification outcomes for diagnostics.\n\n## Acceptance criteria\n1. Tampered artifact is always rejected with clear reason.\n2. Missing checksum/signature metadata is handled predictably by policy.\n3. Verification status is visible in installer summary and machine-readable output.","acceptance_criteria":"1. Checksum verification is default and mandatory unless explicit bypass is requested.\n2. Optional signature verification path is implemented with clear degradation messaging.\n3. Bypass path is loud, explicit, and logged in structured output.\n4. Unit tests cover success/failure/tamper scenarios.\n5. E2E tests include integrity failure injection and remediation validation.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:03:39.154960402Z","created_by":"ubuntu","updated_at":"2026-02-14T21:38:43.595422377Z","closed_at":"2026-02-14T21:38:43.595403531Z","close_reason":"Implemented SHA256 enforcement + optional/required Sigstore policy contract with structured bypass semantics and tests","source_repo":".","compaction_level":0,"original_size":0,"labels":["installer","security","supply-chain"],"dependencies":[{"issue_id":"bd-2j5.4","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.4","depends_on_id":"bd-2j5.3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":297,"issue_id":"bd-2j5.4","author":"Dicklesworthstone","text":"Security decision note: checksum verification is baseline mandatory; signature verification is highly recommended but may be conditionally optional if cosign is absent. Any bypass () must be loud, explicit, and reflected in summary output/log metadata.","created_at":"2026-02-14T21:04:20Z"},{"id":298,"issue_id":"bd-2j5.4","author":"Dicklesworthstone","text":"Clarification: bypass flag name is --no-verify; using it must emit a high-visibility warning and appear in machine-readable result metadata.","created_at":"2026-02-14T21:04:28Z"}]}
{"id":"bd-2j5.5","title":"From-Source Fallback Install Mode with prerequisite checks","description":"## Deliverable\nFrom-source fallback install mode with prerequisite checks and deterministic build behavior.\n\n## Background and rationale\nWhen release assets are unavailable (airgapped, unsupported target, CI lag), users still need a path to success.\n\n## Scope\n- Implement `--from-source` path with toolchain checks and explicit prompts/remediations.\n- Support offline/limited-network behavior where feasible.\n- Ensure source-build mode respects destination, verification, and summary UX conventions.\n\n## Acceptance criteria\n1. Source mode can install from repository tag/commit with reproducible command flow.\n2. Missing prerequisites are reported with direct fix commands.\n3. Source mode is covered by installer tests.","acceptance_criteria":"1. From-source mode works deterministically with clear prerequisite validation.\n2. Source mode preserves destination, verification, and summary behavior parity.\n3. Missing prerequisites produce exact fix commands.\n4. Unit tests cover source-mode decision logic and prerequisite checks.\n5. E2E includes source-install scenario with detailed logs.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T21:03:39.263367275Z","created_by":"ubuntu","updated_at":"2026-02-15T00:05:57.610371400Z","closed_at":"2026-02-15T00:05:57.610306519Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["build","installer"],"dependencies":[{"issue_id":"bd-2j5.5","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.5","depends_on_id":"bd-2j5.3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.5","depends_on_id":"bd-2j5.4","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-2j5.6","title":"Post-install automation: PATH, completions, and verification","description":"## Deliverable\nPost-install automation for PATH setup, shell completions, and immediate binary verification.\n\n## Background and rationale\nThe install is not complete until the command actually works in the user's shell with minimal manual edits.\n\n## Scope\n- Optional easy-mode PATH mutation for common shells with safe backups/idempotency.\n- Install completion scripts (bash/zsh/fish) automatically when requested.\n- Run post-install sanity command (`sbh --version`, optional health check) and report status.\n\n## Acceptance criteria\n1. New users can run `sbh` in a new shell without manual PATH surgery when easy mode is enabled.\n2. Completion install does not clobber unrelated shell config.\n3. Verification failures provide exact next-step commands.","acceptance_criteria":"1. PATH/completion automation is idempotent and backup-safe across supported shells.\n2. Post-install verification confirms binary usability and reports actionable remediation on failure.\n3. Automation outcomes are visible in both human summary and structured logs.\n4. Unit tests cover shell profile mutation edge cases.\n5. E2E validates end-to-end behavior in clean shell environments.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:03:39.364973615Z","created_by":"ubuntu","updated_at":"2026-02-14T23:49:31.015590483Z","closed_at":"2026-02-14T23:49:31.015511595Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["installer","shell","ux"],"dependencies":[{"issue_id":"bd-2j5.6","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.6","depends_on_id":"bd-2j5.2","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-2j5.7","title":"Automatic AI tool integration bootstrap with backup-first safety","description":"## Deliverable\nAutomatic integration bootstrap for AI coding toolchains (Claude Code, Codex, Gemini, and related hook-capable CLIs) with backup-first semantics.\n\n## Background and rationale\ndcg succeeds partly because it wires itself into user workflows immediately. We need similar convenience while preserving safety and reversibility.\n\n## Scope\n- Detect known tool config files and hook registries.\n- Inject/update sbh integration entries idempotently.\n- Create timestamped backups before mutation and print restore guidance.\n- Support `--no-configure` mode for manual-only users.\n\n## Acceptance criteria\n1. Re-running bootstrap does not duplicate hooks or corrupt config files.\n2. Backups are always created and discoverable.\n3. Installer summary reports per-tool status (configured/skipped/failed + reason).","acceptance_criteria":"1. Integration bootstrap updates known tool configs idempotently with backup-first behavior.\n2. Re-runs never duplicate entries or corrupt configuration files.\n3. Per-tool status is surfaced in summary and JSON diagnostics.\n4. Unit tests cover merge/update and rollback-on-failure logic.\n5. E2E validates multi-tool bootstrap with detailed logs and artifacted backups.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:03:39.460926551Z","created_by":"ubuntu","updated_at":"2026-02-14T23:59:08.919914083Z","closed_at":"2026-02-14T23:59:08.919841177Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["automation","installer","integrations"],"dependencies":[{"issue_id":"bd-2j5.7","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.7","depends_on_id":"bd-2j5.2","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.7","depends_on_id":"bd-2j5.21","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.7","depends_on_id":"bd-2j5.6","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-2j5.8","title":"sbh update command orchestration (check/apply/pin/system-user)","description":"## Deliverable\nA first-class `sbh update` command that orchestrates install/update flows with explicit policy controls.\n\n## Background and rationale\nUsers need an in-product update command, not just docs telling them to re-run installer scripts.\n\n## Scope\n- Implement `sbh update` command surface: check-only, install target version, force refresh, system/user destination controls.\n- Reuse installer logic for download/verify/install to avoid split behavior.\n- Support dry-run and machine-readable output.\n\n## Acceptance criteria\n1. `sbh update --check` is fast and safe for cron/agent usage.\n2. Updating to latest and pinned versions works across supported platforms.\n3. Update output clearly states old/new version and any required follow-up actions.","acceptance_criteria":"1. `sbh update` supports check/apply/pin/system-user controls with deterministic behavior.\n2. Update flow reuses installer integrity and artifact resolution logic (no drift).\n3. Update outcomes include old/new version and required follow-up actions.\n4. Unit tests cover command options, policy decisions, and error mapping.\n5. E2E covers update success/failure and rollback handoff with detailed logs.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T21:03:39.553479917Z","created_by":"ubuntu","updated_at":"2026-02-15T02:19:22.876874004Z","closed_at":"2026-02-15T02:19:22.876774046Z","close_reason":"Implemented sbh update command: UpdateArgs with --check/--version/--force/--system/--user/--no-verify/--dry-run, module-based orchestration in cli/update.rs with 11 unit tests (version resolution, report formatting, step tracking), 3 bin tests (CLI parsing, defaults, conflict validation). Shares artifact resolution and verification with installer via resolve_updater_artifact_contract/verify_artifact_supply_chain. Full pipeline: detect platform → resolve contract → check version → download via curl → SHA-256 verify → extract tar.xz → backup+install with rollback. Human and JSON output modes.","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli","installer","update"],"dependencies":[{"issue_id":"bd-2j5.8","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.8","depends_on_id":"bd-2j5.13","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.8","depends_on_id":"bd-2j5.16","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.8","depends_on_id":"bd-2j5.2","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.8","depends_on_id":"bd-2j5.21","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.8","depends_on_id":"bd-2j5.3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.8","depends_on_id":"bd-2j5.4","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.8","depends_on_id":"bd-2j5.5","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.8","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":299,"issue_id":"bd-2j5.8","author":"Dicklesworthstone","text":"Update orchestration note: updater must not fork behavior from installer. Shared code paths are required so install/update verification and artifact resolution semantics cannot drift over time.","created_at":"2026-02-14T21:04:20Z"}]}
{"id":"bd-2j5.9","title":"Update cache + background notice policy + opt-out controls","description":"## Deliverable\nUpdater version-intelligence cache and background notification policy with clear opt-out controls.\n\n## Background and rationale\nFast startup matters; repeated network calls for every command do not scale. dcg uses cached checks plus optional background refresh.\n\n## Scope\n- Add local cache for update metadata with TTL.\n- Implement lightweight background refresh policy where appropriate.\n- Support config/env opt-out for update checks and notices.\n\n## Acceptance criteria\n1. Update check latency stays low with warm cache.\n2. Cache expiry/refresh semantics are deterministic and test-covered.\n3. Users/agents can disable notices globally in config or env.","acceptance_criteria":"1. Update metadata caching reduces check latency while preserving correctness.\n2. TTL and refresh behavior are deterministic and configurable.\n3. Opt-out controls work via config/env without side effects.\n4. Unit tests cover cache lifecycle and opt-out logic.\n5. E2E includes stale-cache and offline-check scenarios with detailed logs.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T21:03:39.644217741Z","created_by":"ubuntu","updated_at":"2026-02-15T04:30:31.519562857Z","closed_at":"2026-02-15T04:30:31.519545735Z","close_reason":"Acceptance met: update metadata cache/TTL + refresh policy + opt-out controls are wired and test-covered (unit + integration stale-cache/offline); revalidated with rch cargo test --lib, rch cargo test --test integration_tests -- update_check_, and rch cargo check --all-targets.","source_repo":".","compaction_level":0,"original_size":0,"labels":["observability","update"],"dependencies":[{"issue_id":"bd-2j5.9","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2j5.9","depends_on_id":"bd-2j5.8","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":300,"issue_id":"bd-2j5.9","author":"Dicklesworthstone","text":"Progress (JadeBass): added update policy config + deterministic env override tests in src/core/config.rs and added file-backed cache module with expanded lifecycle tests in src/core/update_cache.rs. Validation: cargo fmt OK, rch exec \"cargo check --lib\" OK. Remaining blocker: src/cli/update.rs reserved by DustyDove and currently failing clippy/check-all-targets due unclosed delimiters + unsafe std::env::set_var in tests; awaiting fix/release to wire cache+notice behavior into updater command path.","created_at":"2026-02-15T02:27:45Z"},{"id":301,"issue_id":"bd-2j5.9","author":"Dicklesworthstone","text":"Update: retrying reservation for src/cli/update.rs + src/cli_app.rs still conflicts with DustyDove (reservation 386/387 expiring ~03:02Z). all-target rch checks currently fail in update.rs test code due unsafe std::env::set_var blocks under crate forbid(unsafe_code). Ready to wire cache/notices into updater command path immediately once reservation clears.","created_at":"2026-02-15T02:31:01Z"},{"id":302,"issue_id":"bd-2j5.9","author":"AmberFalcon","text":"Taking unblock slice: reserved src/cli/update.rs + src/cli_app.rs, fixing compile/lint blockers and wiring update-cache/notice behavior into updater path; will report rch check/clippy results.","created_at":"2026-02-15T03:04:48Z"},{"id":303,"issue_id":"bd-2j5.9","author":"AmberFalcon","text":"Completed updater cache/notice wiring slice: added --refresh-cache in cli_app UpdateArgs; mapped config.update.metadata_cache_file/ttl/notices_enabled into UpdateOptions via build_update_options(); wired cache-aware target metadata resolution in src/cli/update.rs (cache hit vs network refresh path), and gated notice follow-ups/Run","created_at":"2026-02-15T03:22:49Z"},{"id":304,"issue_id":"bd-2j5.9","author":"AmberFalcon","text":"Validation details for updater slice: cargo fmt --check OK; rch exec cargo check --all-targets OK; rch exec cargo test --lib update::tests::target_metadata_uses_cache_when_refresh_disabled OK; rch exec cargo test --lib update::tests::target_metadata_refresh_bypasses_cache_and_writes_new_entry OK; rch exec cargo test --lib update::tests::format_check_only_update_available_notice_suppressed OK; rch exec cargo test --bin sbh -- update_options_include_cache_and_notice_config OK. Full rch exec cargo clippy --all-targets -- -D warnings still fails on unrelated existing files outside src/cli/update.rs and src/cli_app.rs.","created_at":"2026-02-15T03:22:54Z"},{"id":305,"issue_id":"bd-2j5.9","author":"Dicklesworthstone","text":"CopperAnchor progress: added integration stale-cache/offline-check scenarios in tests/integration_tests.rs and env-aware CLI helper in tests/common/mod.rs. Validation currently blocked by compile issues in reserved files: src/cli/update.rs non-exhaustive TargetMetadataSource match (missing OfflineBundle arm) and src/cli/assets.rs missing test helper seed_cache_entry references.","created_at":"2026-02-15T03:28:41Z"},{"id":306,"issue_id":"bd-2j5.9","author":"Dicklesworthstone","text":"CopperAnchor update: added integration coverage for stale-cache/offline-check and isolated backup inventory paths in tests/integration_tests.rs (4 new tests) plus env-aware helper in tests/common/mod.rs. Validation: rch exec \"cargo test --test integration_tests -- update_\" PASS (8 update_* tests).","created_at":"2026-02-15T03:32:10Z"},{"id":307,"issue_id":"bd-2j5.9","author":"Dicklesworthstone","text":"Taking a non-overlapping bd-2j5.9 slice now: runtime enforcement of update.enabled + background_refresh behavior in src/cli_app.rs and src/cli/update.rs, with focused tests and rch validation. Avoiding reserved integration/e2e surfaces.","created_at":"2026-02-15T04:23:42Z"}]}
{"id":"bd-2j8","title":"Fix M10: parse_meminfo should respect unit suffix instead of assuming kB","status":"closed","priority":3,"issue_type":"bug","created_at":"2026-02-15T21:37:40.456335250Z","created_by":"ubuntu","updated_at":"2026-02-15T21:39:22.852036621Z","closed_at":"2026-02-15T21:39:22.852018797Z","close_reason":"Fixed: parse_meminfo now reads actual unit suffix (kB/mB/gB) instead of blindly assuming kB","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2ld","title":"Clippy debt burn-down slice: deletion/release lint blockers","description":"Reduce immediate clippy -D warnings blockers in unreserved files: remove unused self in src/scanner/deletion.rs and replace unchecked Instant subtraction patterns in src/ballast/release.rs with checked_sub-based setup in tests. Preserve behavior; validate with rch.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:23:11.582405963Z","created_by":"ubuntu","updated_at":"2026-02-15T16:26:29.274282766Z","closed_at":"2026-02-15T16:26:29.274264402Z","close_reason":"Completed targeted non-overlap clippy burn-down in deletion/release files with rch validation; touched lints resolved while global clippy remains blocked by unrelated files.","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"],"comments":[{"id":308,"issue_id":"bd-2ld","author":"LavenderOak","text":"Completed non-overlap clippy slice in reserved files. Changes: (1) src/scanner/deletion.rs removed unused self on dry-run logger helper by making log_dry_run associated and updating call site; (2) src/ballast/release.rs replaced unchecked Instant subtraction in tests with checked_sub helper one_hour_ago(). Validation: cargo fmt --check PASS; rch exec 'cargo test --lib release' PASS; rch exec 'cargo check --all-targets' PASS; rch exec 'cargo clippy --all-targets -- -D warnings' still FAIL due many unrelated pre-existing files (tests/stress_tests.rs, examples/*, src/decision_plane_tests.rs, etc.), with no remaining mentions of src/scanner/deletion.rs or src/ballast/release.rs in clippy error stream.","created_at":"2026-02-15T16:26:26Z"}]}
{"id":"bd-2m1","title":"Harden config path normalization to avoid unwrap panic surfaces","description":"Replace unwrap-based trailing-slash normalization in core config with total safe logic and add coverage for root path + trailing slash cases.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T22:34:02.353862969Z","created_by":"ubuntu","updated_at":"2026-02-15T22:35:13.801279579Z","closed_at":"2026-02-15T22:35:13.801257298Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2m9","title":"sbh config and sbh ballast subcommands","description":"## Deliverable\nConfig management and ballast management subcommands.\n\n## Technical Approach\n### sbh config\n```bash\nsbh config show              # Show current effective config (merged layers)\nsbh config path              # Show config file path\nsbh config validate          # Validate config file\nsbh config set <key> <value> # Set a config value\nsbh config reset             # Reset to defaults\nsbh config diff              # Show diff between file and defaults\n```\n\n### sbh ballast\n```bash\nsbh ballast status           # Show ballast inventory\nsbh ballast provision        # Create ballast files (idempotent)\nsbh ballast release N        # Manually release N files\nsbh ballast replenish        # Manually replenish released files\nsbh ballast verify           # Check integrity of all files\n```\n\n### Implementation\nThese commands are relatively straightforward wrappers around the config system and ballast manager. The key value is providing CLI access to internals for debugging and manual intervention.\n\n## Acceptance Criteria\n- All config subcommands work correctly\n- Config validation produces helpful errors\n- Ballast status shows accurate inventory\n- Ballast verify checks file integrity\n- Manual release/replenish work correctly\n- JSON output available for all subcommands","acceptance_criteria":"1. Unit tests cover config key parsing, validation error messaging, and ballast command argument handling. 2. Integration tests validate effective-config layering and ballast manager command effects. 3. E2E scripts cover config show/set/validate/reset/diff and ballast status/provision/release/replenish/verify flows. 4. JSON and human outputs remain consistent and parseable under success and failure paths. 5. Detailed command logs include config source precedence, ballast inventory deltas, and safety guard decisions.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T16:53:28.335870700Z","created_by":"ubuntu","updated_at":"2026-02-15T00:22:16.453122972Z","closed_at":"2026-02-15T00:22:16.453057750Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"],"dependencies":[{"issue_id":"bd-2m9","depends_on_id":"bd-25g","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2m9","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2m9","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-2nb","title":"Clippy micro-slice: assets + loop_main test lint cleanup","description":"Fix narrow clippy -D warnings hotspots in src/cli/assets.rs and src/daemon/loop_main.rs (redundant_clone and float_cmp assertions in tests) while preserving behavior; validate with rch.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:43:18.593081449Z","created_by":"ubuntu","updated_at":"2026-02-15T16:51:45.146605839Z","closed_at":"2026-02-15T16:51:45.146587755Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"]}
{"id":"bd-2np","title":"Daemon self-monitoring and health reporting","description":"## Deliverable\nThe daemon monitors its own health: memory usage, thread status, scan latency, and reports this via sd_notify STATUS and the status command.\n\n## Technical Approach\n### Self-Monitoring Metrics\n```rust\npub struct DaemonHealth {\n    pub uptime: Duration,\n    pub memory_rss_bytes: u64,      // /proc/self/status on Linux\n    pub scan_count: u64,\n    pub avg_scan_duration: Duration,\n    pub last_scan_at: Instant,\n    pub deletions_total: u64,\n    pub bytes_freed_total: u64,\n    pub errors_total: u64,\n    pub thread_status: Vec<ThreadStatus>,\n    pub last_pressure_level: PressureLevel,\n}\n\npub enum ThreadStatus {\n    Running { name: String, last_heartbeat: Instant },\n    Stalled { name: String, stalled_since: Instant },\n    Dead { name: String, died_at: Instant, error: String },\n}\n```\n\n### Thread Heartbeats\nEach worker thread periodically writes to an AtomicU64 timestamp. The self-monitor checks these:\n- If heartbeat is > 60s stale → thread is stalled\n- Log warning and attempt restart\n\n### Health Report for sd_notify\n```\nSTATUS=Monitoring 4 mounts | GREEN 23.4% free on /data | 312 deletions (467 GB freed) | RSS 42 MB\n```\n\n### Stale State File\nWrite a JSON state file (/var/lib/sbh/state.json) periodically:\n- Allows `sbh status` to read daemon state even when not connecting directly\n- Includes last scan time, current pressure, recent activity summary\n- Written every 30 seconds\n\n## Acceptance Criteria\n- Memory usage tracked and bounded (< 256MB, alert if exceeded)\n- Thread stalls detected within 60 seconds\n- sd_notify STATUS updated every 30 seconds\n- State file written for status command\n- Self-monitoring overhead < 1% CPU","acceptance_criteria":"1. Unit tests cover heartbeat staleness detection, memory parsing, and state serialization correctness. 2. Integration tests validate self-monitor interaction with daemon threads and sd_notify updates. 3. E2E scenarios validate stalled-thread detection, alert emission, and recovery/restart handling. 4. Health state persists accurately across daemon restarts and degraded operation. 5. Detailed health logs include per-thread heartbeat age, memory trends, status payloads, and alert reason codes.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T16:55:20.178762071Z","created_by":"ubuntu","updated_at":"2026-02-15T00:29:26.706762811Z","closed_at":"2026-02-15T00:29:26.706696376Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["daemon"],"dependencies":[{"issue_id":"bd-2np","depends_on_id":"bd-48o","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":309,"issue_id":"bd-2np","author":"Dicklesworthstone","text":"REVIEW: The state file (/var/lib/sbh/state.json) is the PRIMARY mechanism for CLI-to-daemon communication. Its format must be well-defined:\n\n```json\n{\n  \"version\": \"0.1.0\",\n  \"pid\": 12345,\n  \"started_at\": \"2026-02-14T10:00:00Z\",\n  \"uptime_seconds\": 307342,\n  \"last_updated\": \"2026-02-14T15:30:00Z\",\n  \"pressure\": {\n    \"overall\": \"green\",\n    \"mounts\": [\n      {\"path\": \"/data\", \"free_pct\": 23.4, \"level\": \"green\", \"rate_bps\": -12400000}\n    ]\n  },\n  \"ballast\": {\"available\": 8, \"total\": 10, \"released\": 2},\n  \"last_scan\": {\"at\": \"2026-02-14T15:29:55Z\", \"candidates\": 3, \"deleted\": 0},\n  \"counters\": {\"scans\": 1542, \"deletions\": 312, \"bytes_freed\": 467800000000, \"errors\": 2}\n}\n```\n\nATOMICITY: Write to state.json.tmp first, then rename() (atomic on POSIX). This prevents sbh status from reading a half-written file.\nSTALENESS: sbh status must check last_updated and warn if > 60s old (daemon might be stalled).\nPERMISSIONS: state.json readable by the user running sbh commands (0644).","created_at":"2026-02-14T17:14:49Z"}]}
{"id":"bd-2pi","title":"sbh install / sbh uninstall commands","description":"## Deliverable\nCommands to install and uninstall sbh as a system service, including ballast provisioning.\n\n## Technical Approach\n### sbh install\n```bash\nsbh install [OPTIONS]\n\nOptions:\n  --systemd          Install as systemd service (Linux, default on Linux)\n  --launchd          Install as launchd agent (macOS, default on macOS)\n  --user             Install as user-level service (no root required)\n  --ballast-count N  Number of ballast files to create (default: 10)\n  --ballast-size N   Size of each ballast file in MB (default: 1024)\n  --ballast-path P   Location for ballast files\n  --dry-run          Show what would be done without doing it\n```\n\n### Installation Steps\n1. Detect platform (Linux → systemd, macOS → launchd)\n2. Create data directory (/var/lib/sbh/ or equivalent)\n3. Write default config file\n4. Provision ballast files (with progress bar)\n5. Create SQLite database\n6. Generate and install service file\n7. Enable and start service\n8. Verify service is running\n9. Print summary\n\n### sbh uninstall\n```bash\nsbh uninstall [OPTIONS]\n\nOptions:\n  --keep-data        Keep data directory and logs\n  --keep-ballast     Keep ballast files (don't reclaim space)\n  --force            Don't ask for confirmation\n```\n\n### Uninstall Steps\n1. Stop service\n2. Disable service\n3. Remove service file\n4. Optionally remove data directory (with confirmation)\n5. Optionally remove ballast files (with confirmation)\n6. Print summary\n\n### Progress Reporting\nBallast provisioning (writing 10GB) takes time. Show progress:\n```\nInstalling sbh v0.1.0...\n  Creating data directory... done\n  Writing default config... done\n  Provisioning ballast files:\n    [████████████████░░░░] 8/10 (8.0 GB) - SBH_BALLAST_FILE_00008.dat\n  Creating activity database... done\n  Installing systemd service... done\n  Starting service... done\n\n✓ sbh installed successfully\n  Service: sbh.service (running)\n  Config:  /etc/sbh/config.toml\n  Data:    /var/lib/sbh/\n  Ballast: 10 files × 1 GB = 10 GB reclaimable\n```\n\n## Acceptance Criteria\n- Install works on Linux (systemd) and macOS (launchd)\n- Idempotent: running install twice doesn't break anything\n- Uninstall cleanly removes all components\n- Progress bar during ballast provisioning\n- --dry-run shows plan without executing\n- --user mode works without root\n- Verification step confirms service is actually running\n- Integration test: install → verify → uninstall → verify clean","acceptance_criteria":"1. `sbh install` and `sbh uninstall` remain idempotent and deterministic across Linux/macOS paths.\n2. Install command integrates wizard/auto flow, post-install automation, integration bootstrap, and structured diagnostics.\n3. Uninstall command integrates safe cleanup modes and reversible teardown behavior.\n4. Unit tests validate install/uninstall option handling and safety decisions.\n5. E2E validates install -> verify -> update -> rollback -> uninstall with detailed logs.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T16:52:04.488580920Z","created_by":"ubuntu","updated_at":"2026-02-15T00:20:36.178919253Z","closed_at":"2026-02-15T00:20:36.178840786Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"],"dependencies":[{"issue_id":"bd-2pi","depends_on_id":"bd-25g","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2pi","depends_on_id":"bd-26g","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2pi","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2pi","depends_on_id":"bd-2j5.11","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2pi","depends_on_id":"bd-2j5.16","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2pi","depends_on_id":"bd-2j5.17","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2pi","depends_on_id":"bd-2j5.18","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2pi","depends_on_id":"bd-2j5.6","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2pi","depends_on_id":"bd-2j5.7","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2pi","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":310,"issue_id":"bd-2pi","author":"Dicklesworthstone","text":"ENHANCEMENT (idea-wizard): Add interactive first-run wizard mode to sbh install. When run without flags, it should:\n  1. Detect all mounted filesystems and show them in a table\n  2. Auto-suggest scan paths based on discovered project directories\n  3. Show estimated reclaimable space (quick scan with built-in patterns)\n  4. Let user adjust scan paths, exclusions, and ballast sizing\n  5. Show config summary and ask for confirmation\n  6. Create config, provision ballast, install service\n  7. Run first scan and show results\nThis replaces the current 'install with defaults' approach with a guided experience. For headless: sbh install --auto uses all defaults without prompting.","created_at":"2026-02-14T18:35:03Z"},{"id":311,"issue_id":"bd-2pi","author":"Dicklesworthstone","text":"REVIEW-2: Removed bd-3i3 (launchd) dependency. macOS launchd support is optional at compile time. Install command detects platform: Linux -> systemd (bd-26g, required dep), macOS -> launchd (bd-3i3, wired in when available). If bd-3i3 is not yet implemented, 'sbh install' on macOS returns: 'macOS service installation not yet available. Run sbh daemon in foreground instead.'","created_at":"2026-02-14T19:03:09Z"}]}
{"id":"bd-2pj","title":"Cross-platform filesystem stats collector","description":"## Deliverable\nEfficient filesystem statistics collection that works across all target platforms, with caching and rate limiting.\n\n## Technical Approach\n### FsStatsCollector\nWraps the PAL's fs_stats() with intelligent caching and batching:\n\n```rust\npub struct FsStatsCollector {\n    platform: Arc<dyn Platform>,\n    cache: HashMap<PathBuf, CachedStats>,\n    cache_ttl: Duration,  // default: 1 second\n}\n\nstruct CachedStats {\n    stats: FsStats,\n    collected_at: Instant,\n}\n```\n\n### Batch Collection\nWhen monitoring multiple paths, group by mount point to avoid redundant statvfs calls:\n- /data/projects/foo and /data/projects/bar → single statvfs for /data mount\n- /tmp/build1 and /tmp/build2 → single statvfs for /tmp mount\n\n### Rate Limiting\nstatvfs is a syscall; avoid calling it too frequently:\n- Cache results for configurable TTL (default 1s)\n- Under high pressure, reduce TTL to 100ms\n- During normal operation, 5s TTL is fine\n\n### Zero-Allocation Hot Path\nThe stats check in the monitoring loop should not allocate:\n- Pre-allocate the stats buffer\n- Reuse PathBuf instances\n- Use stack-allocated arrays for mount point looking\n\n## Design Rationale\nstatvfs is fast (~1μs on Linux) but calling it hundreds of times per second across many mount points adds up. Caching by mount point deduplicates the work. The cache TTL adapts to pressure level: more frequent checks when storage is under pressure.\n\n## Acceptance Criteria\n- Correctly reports free/total/available for all filesystems\n- Caching prevents redundant syscalls (verifiable by counting calls)\n- Mount point deduplication works (paths on same mount = single call)\n- Thread-safe for concurrent access\n- Unit tests with MockPlatform","acceptance_criteria":"1. Unit tests validate cache TTL behavior, mount deduplication, and concurrency safety. 2. Integration tests verify PAL-backed stats correctness across multiple mount configurations. 3. E2E scenarios exercise mixed-path monitoring and confirm no redundant stats collection regressions. 4. Performance bounds are met under high-frequency polling workloads. 5. Detailed collector logs include mount key, cache hit/miss, syscall timing, and normalization decisions.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:44:47.357260610Z","created_by":"ubuntu","updated_at":"2026-02-14T19:45:22.025631582Z","closed_at":"2026-02-14T19:45:22.025610593Z","close_reason":"Filesystem stats collector implemented in monitor/fs_stats.rs (274 lines): FsStatsCollector with cache-aware collection, per-mount caching with TTL, mount point deduplication via collect_many(), cache expiry pruning, unit tests for dedup and cache hits.","source_repo":".","compaction_level":0,"original_size":0,"labels":["monitoring"],"dependencies":[{"issue_id":"bd-2pj","depends_on_id":"bd-sth","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-2q9","title":"E2E test script with detailed logging","description":"## Deliverable\nShell-based end-to-end test script suite that exercises CLI, daemon, policy modes, and recovery paths with detailed structured logs.\n\n## Scope Expansion (Plan-Space Revision)\nE2E scripts must cover:\n- core CLI commands and JSON output validation\n- scan/clean/ballast lifecycles\n- predictive pipeline + fallback-safe transitions\n- emergency zero-write mode\n- project protection markers\n- process attribution output paths\n- status/dashboard/stats visibility checks\n- decision-plane shadow/canary trace assertions\n\n## Logging Requirements\nEach test case logs:\n- command executed\n- expected vs actual exit status\n- expected vs actual output constraints\n- timing and environment metadata\n- trace IDs and fallback reason codes when present\n\nOutput artifacts:\n- machine-readable JSON summary\n- per-test logs\n- compact human summary for CI console\n\n## Acceptance Criteria\n- comprehensive command and policy-mode coverage\n- deterministic pass/fail behavior\n- explicit cleanup on success/failure paths\n- integrated into CI e2e stage\n- runtime budget and flaky-test guardrails documented","acceptance_criteria":"1. E2E script suite covers normal, degraded, and emergency user workflows without feature gaps. 2. Scenarios validate CLI UX plus daemon behavior and decision-plane transitions where applicable. 3. Every scenario emits verbose structured logs with timestamps, trace IDs, and assertion context. 4. Scripts produce deterministic exit codes and machine-readable summary artifacts for CI. 5. Flake diagnostics are captured with retry metadata and first-failure preservation.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T16:54:25.464012324Z","created_by":"ubuntu","updated_at":"2026-02-15T01:40:35.299786122Z","closed_at":"2026-02-15T01:40:35.299714828Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["testing"],"dependencies":[{"issue_id":"bd-2q9","depends_on_id":"bd-112","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-1fr","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-21z","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-224","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-25g","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-26g","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-2it","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-2m9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-2np","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-2pi","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-2qa","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-2s9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-395","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-3i3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-3qm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-3s5","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-7ls","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-g0c","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-nhm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2q9","depends_on_id":"bd-p2u","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":312,"issue_id":"bd-2q9","author":"Dicklesworthstone","text":"REVIEW: Additional E2E test cases needed:\n\n23. **Signal handling SIGHUP**: Start daemon → send SIGHUP → verify config reload logged → verify daemon still running\n24. **Signal handling SIGUSR1**: Start daemon → send SIGUSR1 → verify immediate scan triggered\n25. **Concurrent CLI access**: Start daemon → run 'sbh status' while daemon is running → verify no deadlock or corruption\n26. **Ballast concurrent access**: Start daemon → run 'sbh ballast release 1' while daemon monitors → verify file locking works (no race condition)\n27. **Scoring determinism**: Run 'sbh scan --json' twice on identical directory → verify JSON output is byte-identical\n28. **JSONL tailing**: Start daemon → tail -f JSONL file → trigger scan → verify events appear in real-time with complete JSON lines (no partial writes)\n29. **Large directory tree**: Create 10,000+ files in nested dirs → 'sbh scan' completes in < 10s\n30. **Exit codes**: Verify all documented exit codes (0, 1, 2, 3, 4) match their descriptions\n\nAlso: Each test should capture TIMING information (start/end timestamps) and log it, so we can detect performance regressions across runs.","created_at":"2026-02-14T17:14:00Z"},{"id":313,"issue_id":"bd-2q9","author":"Dicklesworthstone","text":"ADDITIONAL E2E TESTS for new features (idea-wizard beads):\n31. **Emergency mode**: sbh emergency --dry-run /tmp/test_dir -> finds test artifacts, scores them, no deletions\n32. **Emergency mode auto**: Create test artifacts -> sbh emergency --yes --target-free 20 -> verify artifacts deleted, space freed\n33. **Emergency mode zero-write**: Run sbh emergency --dry-run under strace -> verify ZERO write syscalls\n34. **Project protection**: touch /tmp/test_dir/.sbh-protect -> sbh scan -> verify test_dir NOT in candidates\n35. **Protection CLI**: sbh protect /tmp/test -> verify file created -> sbh unprotect /tmp/test -> verify removed\n36. **Pre-build check**: Fill test partition to 95% -> sbh check -> verify exit code 2 (CRITICAL)\n37. **Pre-build check OK**: Fresh test partition at 50% -> sbh check -> verify exit code 0\n38. **Blame command**: Create test artifacts with known process CWDs -> sbh blame --json -> verify attribution","created_at":"2026-02-14T18:37:00Z"}]}
{"id":"bd-2qa","title":"Emergency zero-write recovery mode (sbh emergency)","description":"## Deliverable\nA zero-write emergency mode that works when the disk is already critically full — the exact moment users need sbh most.\n\n## The Problem\nUsers install sbh PRECISELY when their disk is full. But the normal startup sequence requires creating directories, writing config, creating SQLite database, provisioning ballast files. ALL of these fail on a full disk. sbh can't help in the exact scenario it exists for.\n\n## The Solution: sbh emergency [paths...]\n\nA completely self-contained mode that:\n- Performs ZERO disk writes (no database, no JSONL, no config file)\n- Scans specified paths immediately using built-in patterns\n- Scores and ranks all candidates using default scoring weights\n- Shows interactive deletion list (like sbh clean but stateless)\n- All output to stdout/stderr only\n- Works with zero configuration — pure binary execution\n- Supports automation: sbh emergency --yes --target-free 10 /data\n\n### CLI Interface\n  sbh emergency                        # Scan common paths (/data, /tmp, /home)\n  sbh emergency /data/projects         # Scan specific path\n  sbh emergency --yes --target-free 10 # Auto-delete until 10% free\n  sbh emergency --top 20               # Show top 20 candidates only\n  sbh emergency --min-score 0.7        # Only high-confidence candidates\n  sbh emergency --dry-run              # Just show what would be deleted\n\n### Implementation\nEmergency mode creates no objects requiring persistence:\n- ScoringEngine with default weights (hardcoded, no config file read)\n- DirectoryWalker configured for the specified paths\n- PatternRegistry with built-in patterns only (no custom patterns from config)\n- No ActivityLogger — all output goes to stderr for logging, stdout for JSON\n- No BallastManager, No EWMA, No PID controller — crisis mode, delete by score alone\n- No /proc/*/fd open-file checks in emergency (too slow when disk is thrashing)\n\n### Output Format\n  sbh emergency — ZERO-WRITE RECOVERY MODE\n  Warning: /data is 99.2% used (8.1 GB free / 1.8 TB total)\n  Scanning /data/projects... found 47 candidates (182.3 GB reclaimable)\n  [interactive deletion list with scores, sizes, ages]\n  Delete items? [y/N/a(ll)/s(kip)/q(uit)]\n\n### Post-Recovery Guidance\nAfter freeing space, print: \"Emergency cleanup complete: freed 87.3 GB. Next: run sbh install for ongoing protection.\"\n\n### Safety\n- Hard vetoes still enforced: .git directories, system paths, files < 30 min old\n- Requires user confirmation unless --yes flag\n- Clear EMERGENCY MODE banner\n\n## Design Rationale\nThis is the single most impactful UX improvement. Every user's first interaction with sbh will likely be \"my disk is full, help!\" The implementation reuses scoring engine + walker + pattern registry WITHOUT the persistence layer. It is the pure-computation core of sbh exposed directly.\n\n## Acceptance Criteria\n- Works on a 99%+ full disk (zero disk writes verified via strace)\n- Correctly finds and scores build artifacts using built-in patterns\n- Interactive confirmation before deletion\n- --yes flag enables automated operation\n- --target-free stops cleanup when target free% is reached\n- --dry-run shows candidates without deleting\n- Post-recovery message suggests sbh install\n- All hard vetoes still enforced\n- Works with zero configuration (no config file needed)\n- Exit codes: 0=success, 1=no candidates, 2=user cancelled\n- Unit test: scoring without persistence layer\n- Integration test: create artifacts -> emergency scan -> delete -> verify\n- E2E test: verify zero disk writes","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T18:30:40.968645441Z","created_by":"ubuntu","updated_at":"2026-02-14T21:53:05.778243349Z","closed_at":"2026-02-14T21:53:05.778176153Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli","scanner"],"dependencies":[{"issue_id":"bd-2qa","depends_on_id":"bd-1hh","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2qa","depends_on_id":"bd-1sw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2qa","depends_on_id":"bd-1w9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2qa","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2qa","depends_on_id":"bd-x9z","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":314,"issue_id":"bd-2qa","author":"Dicklesworthstone","text":"REVIEW: Emergency mode interaction with protection system (bd-3qm): Emergency mode depends on walker (bd-1w9) which depends on protection (bd-3qm). But emergency mode has NO config file. The protection system handles this via marker-only mode (see bd-3qm comment). Emergency mode WILL honor .sbh-protect marker files (they are on-disk, zero-config). Emergency mode WILL NOT honor config-level glob patterns (scanner.protected_paths). This is documented and acceptable — marker files are the user's explicit intent, while config patterns may be stale or from a different context. Emergency mode output should note: 'Config-level protections are not active in emergency mode. Only .sbh-protect marker files are honored.'","created_at":"2026-02-14T18:53:26Z"},{"id":315,"issue_id":"bd-2qa","author":"Dicklesworthstone","text":"REVIEW: Emergency mode needs deletion capability. Added bd-1hh (deletion executor) as dependency. Emergency mode creates a DeletionExecutor with dry_run=false (unless --dry-run flag) but skips the circuit breaker (emergency = delete everything above score threshold). The executor's pre-flight safety checks (re-verify exists, check .git, verify permissions) still apply. Emergency mode uses a simplified deletion flow: score -> rank -> present to user -> delete confirmed items. No batch-then-remeasure loop needed since there is no PID target — just delete what the user confirms.","created_at":"2026-02-14T18:53:39Z"}]}
{"id":"bd-2rq","title":"CLI framework with clap derive and subcommands","description":"## Deliverable\nThe main CLI argument parser using clap derive, defining all subcommands and their options.\n\n## Technical Approach\n### CLI Structure\n```\nsbh [OPTIONS] <COMMAND>\n\nCommands:\n  daemon     Run the monitoring daemon (foreground or background)\n  install    Install sbh as a system service\n  uninstall  Remove sbh system service\n  status     Show current system status and pressure levels\n  stats      Show activity statistics and metrics\n  scan       Run a manual scan for build artifacts\n  clean      Manually clean build artifacts (with confirmation)\n  ballast    Manage ballast files\n  config     View/edit configuration\n  version    Show version and build info\n  help       Show help\n\nOptions:\n  --config <PATH>   Override config file path\n  --json            Output as JSON (for agent consumption)\n  --no-color        Disable colored output\n  --verbose         Increase log verbosity\n  --quiet           Quiet mode (errors only)\n```\n\n### Clap Derive Setup\n```rust\n#[derive(Parser)]\n#[command(name = \"sbh\", about = \"Storage Ballast Helper - Disk Space Guardian\")]\n#[command(version, long_about = None)]\npub struct Cli {\n    #[command(subcommand)]\n    pub command: Command,\n    \n    #[arg(long, global = true)]\n    pub config: Option<PathBuf>,\n    \n    #[arg(long, global = true)]\n    pub json: bool,\n    \n    #[arg(long, global = true)]\n    pub no_color: bool,\n    \n    #[arg(short, long, global = true)]\n    pub verbose: bool,\n    \n    #[arg(short, long, global = true)]\n    pub quiet: bool,\n}\n\n#[derive(Subcommand)]\npub enum Command {\n    Daemon(DaemonArgs),\n    Install(InstallArgs),\n    Uninstall(UninstallArgs),\n    Status(StatusArgs),\n    Stats(StatsArgs),\n    Scan(ScanArgs),\n    Clean(CleanArgs),\n    Ballast(BallastArgs),\n    Config(ConfigArgs),\n}\n```\n\n### Dual Output Mode\nFollowing dcg's pattern:\n- Human mode: colored terminal output with tables and progress indicators\n- JSON mode: structured JSON to stdout for agent consumption\n- Auto-detect based on TTY + --json flag + SBH_OUTPUT_FORMAT env var\n\n### Exit Codes\n```\n0 → Success\n1 → User error (bad arguments, invalid config)\n2 → Runtime error (permission denied, disk error)\n3 → Internal error (bug)\n4 → Partial success (some items cleaned, some failed)\n```\n\n## Acceptance Criteria\n- All subcommands parse correctly\n- --help produces clear, helpful output\n- --version shows version + build metadata\n- --json flag works globally\n- --no-color respected\n- Exit codes match specification\n- Shell completions generatable (bash, zsh, fish)\n- Unit tests for argument parsing edge cases","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T16:51:48.582281754Z","created_by":"ubuntu","updated_at":"2026-02-14T21:25:35.045331351Z","closed_at":"2026-02-14T21:25:35.045310492Z","close_reason":"Completed: clap-derive CLI framework with global flags, expanded subcommands, JSON/human output mode, completions generation, parser tests, and updated integration/e2e scaffolding.","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"],"dependencies":[{"issue_id":"bd-2rq","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":316,"issue_id":"bd-2rq","author":"Dicklesworthstone","text":"REVIEW: New subcommands that must be wired into the CLI framework: (1) sbh emergency [paths...] (bd-2qa) — zero-write recovery mode. (2) sbh protect <path> / sbh unprotect <path> / sbh protect --list (bd-3qm) — project protection. (3) sbh tune / sbh tune --apply (bd-7vl) — auto-tuning recommendations. (4) sbh check [path] (bd-g0c) — pre-build disk check. (5) sbh blame (bd-395) — agent/process attribution. (6) sbh dashboard (bd-3s5) — live TUI dashboard. All are gated behind their respective beads as dependencies, but bd-2rq must define the clap subcommand enum variants for all of them upfront so the CLI structure is complete.","created_at":"2026-02-14T18:54:09Z"}]}
{"id":"bd-2s9","title":"Signal handling, graceful shutdown, and watchdog heartbeat","description":"## Deliverable\nRobust signal handling for the daemon: SIGTERM/SIGINT for graceful shutdown, SIGHUP for config reload, plus watchdog heartbeat for systemd integration.\n\n## Technical Approach\n### Signal Handler\n```rust\npub struct SignalHandler {\n    shutdown_flag: Arc<AtomicBool>,\n    reload_flag: Arc<AtomicBool>,\n}\n```\n\nUsing signal-hook crate for safe signal handling:\n- SIGTERM/SIGINT → set shutdown_flag, wake monitoring loop\n- SIGHUP → set reload_flag (config reload)\n- SIGUSR1 → trigger immediate scan and report\n\n### Graceful Shutdown Sequence\n1. Set shutdown_flag (all threads check this)\n2. Stop accepting new scan requests\n3. Wait up to 30 seconds for in-progress operations to complete\n4. Flush all logger buffers\n5. Close database connections\n6. Log shutdown event with stats summary\n7. Exit 0\n\n### Config Reload (SIGHUP)\n1. Re-read config file\n2. Validate new config\n3. If valid: apply changes, log what changed\n4. If invalid: log error, keep running with old config\n\n### Watchdog Heartbeat (systemd)\nEvery 30 seconds (half of WatchdogSec=60), notify systemd:\n- sd_notify(WATCHDOG=1)\n- Include STATUS=... with current state\n\nIf the monitoring loop is stuck (deadlock, infinite loop), the watchdog timeout fires and systemd restarts sbh.\n\n### Platform Considerations\n- Linux: signal-hook + sd_notify\n- macOS: signal-hook only (no sd_notify equivalent)\n- Windows: SetConsoleCtrlHandler for Ctrl-C\n\n## Acceptance Criteria\n- SIGTERM/SIGINT triggers graceful shutdown within 30s\n- SIGHUP reloads config without restart\n- SIGUSR1 triggers immediate scan\n- Watchdog heartbeat keeps systemd happy\n- Invalid config on reload doesn't crash the daemon\n- All pending operations complete before shutdown\n- Unit tests for signal flag handling\n- Integration test: send signals → verify correct behavior","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:51:31.888092520Z","created_by":"ubuntu","updated_at":"2026-02-14T20:09:03.058863186Z","closed_at":"2026-02-14T20:09:03.058840854Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["daemon"],"dependencies":[{"issue_id":"bd-2s9","depends_on_id":"bd-sth","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":317,"issue_id":"bd-2s9","author":"Dicklesworthstone","text":"REVIEW: This bead requires the signal-hook crate (already added to bd-1kn's dependency list during review). The nix crate's signal module may also be useful for POSIX signal manipulation (sigprocmask, etc.), which is already a dependency. signal-hook provides safe, higher-level abstractions over raw signal handling that prevent common footguns (e.g., calling non-signal-safe functions in signal handlers).","created_at":"2026-02-14T17:14:09Z"},{"id":318,"issue_id":"bd-2s9","author":"Dicklesworthstone","text":"MINOR: SIGHUP reload clarification — on SIGHUP, the daemon should: (1) Re-read config file from disk. (2) Update in-memory config (pressure thresholds, PID gains, scan intervals, scoring weights). (3) Re-discover special locations. (4) Log 'Configuration reloaded' event. It should NOT: restart threads, re-initialize SQLite, re-provision ballast (those require full restart). Implementation: signal_hook::iterator::Signals in the main loop checks for SIGHUP each cycle.","created_at":"2026-02-14T18:54:57Z"}]}
{"id":"bd-2t7","title":"Fix I15: release tier docs don't match implementation","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-02-15T21:22:54.898252033Z","created_by":"ubuntu","updated_at":"2026-02-15T21:23:59.953444773Z","closed_at":"2026-02-15T21:23:59.953425847Z","close_reason":"Already fixed - docs and implementation now match (0.3/0.6/0.9 tiers: 0/1/3/all)","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2ug","title":"Circuit breaker should break instead of cooldown-and-retry","description":"In deletion.rs when circuit breaker trips it sleeps 30s then resets and continues cycling indefinitely. Should break out of loop and let daemon next scan cycle retry.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-16T00:08:39.294678400Z","created_by":"ubuntu","updated_at":"2026-02-16T00:12:45.625639787Z","closed_at":"2026-02-16T00:12:45.625561801Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["P1","audit"]}
{"id":"bd-2up","title":"Predictive action pipeline with early warning alerts","description":"## Deliverable\nTransform sbh from reactive (acts after thresholds are crossed) to predictive (acts before thresholds are crossed based on EWMA forecasts). Includes early warning alerts.\n\n## The Problem\nThe EWMA estimator (bd-x1k) already computes time_to_exhaustion and acceleration. The PID controller (bd-3po) already determines pressure levels. But the main loop (bd-48o) only acts on CURRENT pressure levels — it waits for thresholds to actually be crossed before doing anything.\n\nThis means: if 10 agents simultaneously start cargo builds and disk consumption jumps from 0 MB/s to 500 MB/s, sbh won't start cleaning until the disk actually hits the threshold (say 15% free). By then, with 500 MB/s consumption, the disk may be at 5% within 3 minutes. The reactive approach leaves very little time for cleanup.\n\n## The Solution: Predictive Pre-emptive Action\n\n### Predictive Action Policy\nNew module that maps EWMA predictions to pre-emptive actions:\n\n```rust\npub struct PredictiveActionPolicy {\n    config: PredictiveConfig,\n}\n\npub struct PredictiveConfig {\n    pub enabled: bool,                    // default: true\n    pub action_horizon_minutes: f64,      // default: 30.0\n    pub warning_horizon_minutes: f64,     // default: 60.0  \n    pub min_confidence: f64,              // default: 0.7\n    pub min_samples: u64,                 // default: 5\n}\n\npub enum PredictiveAction {\n    /// No predicted issue within horizon\n    Clear,\n    /// Disk will be full within warning horizon — log and increase monitoring\n    EarlyWarning {\n        mount: PathBuf,\n        minutes_remaining: f64,\n        confidence: f64,\n    },\n    /// Disk will be full within action horizon — start pre-emptive cleanup\n    PreemptiveCleanup {\n        mount: PathBuf,\n        minutes_remaining: f64,\n        confidence: f64,\n        recommended_free_target_pct: f64,\n    },\n    /// Imminent disk full (< 5 min) — emergency measures\n    ImminentDanger {\n        mount: PathBuf,\n        minutes_remaining: f64,\n    },\n}\n\nimpl PredictiveActionPolicy {\n    pub fn evaluate(&self, estimate: &RateEstimate, current_free_pct: f64) -> PredictiveAction;\n}\n```\n\n### Timeline-Based Response\n```\ntime_to_exhaustion  │  Action\n> 60 min            │  Clear — no action\n30-60 min           │  EarlyWarning — log WARNING, increase scan frequency to 10s\n10-30 min           │  PreemptiveCleanup — start scanning and deleting high-score artifacts\n5-10 min            │  PreemptiveCleanup (aggressive) — lower score threshold, delete more\n< 5 min             │  ImminentDanger — release ballast + aggressive cleanup\n< 2 min             │  ImminentDanger (critical) — release ALL ballast + emergency cleanup\n```\n\n### Key Innovation: Acting BEFORE Thresholds\nThe current system: \"disk is 92% full -> pressure is Orange -> start cleanup\"\nThe predictive system: \"disk is 78% full but filling at 500 MB/s -> predicted 95% in 28 min -> start gentle cleanup NOW while disk is still healthy\"\n\nThis means:\n1. Cleanup has MORE time (starting 30 min early vs 3 min before critical)\n2. Cleanup can be GENTLER (lower urgency, higher score threshold)\n3. Less chance of user-impacting aggressive deletion\n4. Disk never actually enters critical state\n\n### Early Warning Alerts\nWhen predictions cross thresholds, emit structured events:\n\n```json\n{\"ts\":\"2026-02-14T16:30:00Z\",\"event\":\"predictive_warning\",\"mount\":\"/data\",\"minutes_remaining\":42.3,\"confidence\":0.85,\"rate_mbps\":487.2,\"trend\":\"accelerating\",\"message\":\"At current rate, /data will be full in ~42 minutes\"}\n```\n\nThese events go to:\n1. Activity log (SQLite + JSONL)\n2. systemd journal (sd_notify STATUS update)\n3. Optional: notification channel (if notification system bead is implemented)\n\n### Confidence Gating\nPre-emptive action is ONLY taken when:\n- EWMA has >= min_samples (default 5) — need enough data\n- Prediction confidence >= min_confidence (default 0.7) — high-variance predictions are unreliable\n- Trend is Accelerating or Stable (not Recovering or Decelerating)\n- Current free% is actually declining (not just noisy measurement)\n\nThis prevents false alarms from brief spikes (e.g., one large file creation that immediately finishes).\n\n### Configuration\n```toml\n[pressure.prediction]\nenabled = true\naction_horizon_minutes = 30\nwarning_horizon_minutes = 60\nmin_confidence = 0.7\nmin_samples = 5\n```\n\n## Design Rationale\nThis transforms sbh from reactive to proactive. The EWMA data already exists — this connects it to the action pipeline earlier. A 30-minute prediction window means sbh starts gentle cleanup well before an emergency. Users never see a critical alert because the situation was handled proactively. This is THE key differentiator from a dumb cron job running find -delete.\n\n## Acceptance Criteria\n- Pre-emptive cleanup starts when predicted exhaustion < action_horizon\n- Cleanup intensity proportional to time remaining (not just current pressure)\n- Confidence gating prevents false positives\n- Early warning events logged with structured data\n- Does NOT act on low-confidence predictions\n- Does NOT act when trend is Recovering/Decelerating\n- Integrates cleanly with PID controller (advisory, not replacement)\n- Configuration allows tuning horizons and confidence thresholds\n- Unit tests: prediction to action mapping with synthetic scenarios\n- Test: 500 MB/s consumption rate at 80% full -> pre-emptive cleanup starts\n- Test: brief spike (1 min) -> no pre-emptive action (insufficient samples)\n- Test: steady recovery after cleanup -> pre-emptive actions stop\n- Integration test: full pipeline with predictive + reactive working together","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T18:32:51.922586640Z","created_by":"ubuntu","updated_at":"2026-02-14T22:55:27.840003403Z","closed_at":"2026-02-14T22:55:27.839980961Z","close_reason":"Fully implemented by another agent: PredictiveActionPolicy, PredictiveConfig, PredictiveAction enum, 22+ tests in src/monitor/predictive.rs. Config integrated into PressureConfig.","source_repo":".","compaction_level":0,"original_size":0,"labels":["daemon","monitoring"],"dependencies":[{"issue_id":"bd-2up","depends_on_id":"bd-3po","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2up","depends_on_id":"bd-x1k","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":319,"issue_id":"bd-2up","author":"Dicklesworthstone","text":"MINOR: Notification wiring clarification — when predictive action triggers an EarlyWarning or PreemptiveCleanup, it should emit a structured event that the notification system (bd-112) can pick up IF notifications are configured. The predictive module itself does NOT depend on the notification system. Instead, it emits events to the same ActivityEvent channel that all threads use. The notification system subscribes to that channel and filters by event type and min_level.","created_at":"2026-02-14T18:55:09Z"}]}
{"id":"bd-2xk","title":"Clippy debt burn-down slice: walker + decision_record test lint blockers","description":"Fix clippy -D warnings blockers in src/scanner/walker.rs and src/scanner/decision_record.rs (needless_collect/significant_drop_tightening and float_cmp in tests) while preserving behavior, with focused rch validation.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:29:12.804265531Z","created_by":"ubuntu","updated_at":"2026-02-15T16:33:24.734756936Z","closed_at":"2026-02-15T16:33:24.734731558Z","close_reason":"Completed non-overlap walker+decision_record clippy slice with rch check/test validation; global clippy remains blocked by unrelated files.","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"],"comments":[{"id":320,"issue_id":"bd-2xk","author":"Dicklesworthstone","text":"Implemented non-overlap clippy cleanup in src/scanner/walker.rs + src/scanner/decision_record.rs. Changes: replaced needless collect+contains pattern with iterator any in handles_empty_directory test; tightened lock guard lifetime in protection_registry_updated_during_walk via explicit drop(prot); replaced float assert_eq comparisons with to_bits equality for deterministic float comparisons in decision_record tests. Validation: rch exec \"cargo check --all-targets\" PASS; rch exec \"cargo test --lib walker\" PASS (14 tests); rch exec \"cargo test --lib decision_record\" PASS (27 tests); rch exec \"cargo clippy --all-targets -- -D warnings\" still fails globally on unrelated files, but filtered stderr scan shows no hits for src/scanner/walker.rs or src/scanner/decision_record.rs. cargo fmt --check currently fails due unrelated staged ordering changes in tests/common/mod.rs (held by another agent).","created_at":"2026-02-15T16:33:22Z"}]}
{"id":"bd-2y6","title":"Clippy debt burn-down slice (phase 1): stress_harness/proof_harness","description":"Phase-1 non-overlap cleanup focused on low-risk, high-signal lint fixes in tests/stress_harness.rs and tests/proof_harness.rs: deterministic RNG float generation (cast-precision removal), map_or simplifications, collapsible if/readability improvements, selected redundant clone/closure fixes, and targeted too_many_lines allow annotations for scenario driver functions. Deep numeric conversion backlog remains for follow-up slices.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:42:23.134299324Z","created_by":"ubuntu","updated_at":"2026-02-15T16:55:39.785929718Z","closed_at":"2026-02-15T16:55:39.785911163Z","close_reason":"Completed phase-1 stress_harness/proof_harness clippy cleanup with targeted rch validation","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"]}
{"id":"bd-2yw","title":"Walker correctness: honor follow_symlinks and normalize open-file path checks","description":"Fix two walker correctness issues in src/scanner/walker.rs: (1) follow_symlinks config is effectively inert because traversal metadata handling always uses symlink_metadata-style behavior, and (2) open-file detection may miss when candidate paths are relative while /proc fd targets are absolute. Implement behavior-preserving normalization and add/adjust tests.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T16:33:51.666438881Z","created_by":"ubuntu","updated_at":"2026-02-15T16:36:58.678973351Z","closed_at":"2026-02-15T16:36:58.678955097Z","close_reason":"Completed walker follow_symlinks + relative open-file path normalization fixes with focused test/check validation.","source_repo":".","compaction_level":0,"original_size":0,"labels":["safety","scanner","walker"],"comments":[{"id":321,"issue_id":"bd-2yw","author":"Dicklesworthstone","text":"Implemented walker correctness fixes in src/scanner/walker.rs: (1) traversal now honors WalkerConfig.follow_symlinks via metadata_for_path helper used for root seeding, child metadata, and emitted directory metadata; (2) is_path_open now normalizes candidate paths (absolute/current_dir+canonicalize fallback) so relative paths can match absolute /proc fd targets. Added tests: follows_symlinks_when_enabled (unix) and is_path_open_handles_relative_candidate_paths. Validation: cargo fmt --check PASS; rch exec \"cargo test --lib walker\" PASS (16 tests); rch exec \"cargo check --all-targets\" PASS; rch exec \"cargo clippy --all-targets -- -D warnings\" still fails globally on unrelated files, and filtered clippy stderr contains no src/scanner/walker.rs hits.","created_at":"2026-02-15T16:36:56Z"}]}
{"id":"bd-2ze","title":"Clippy debt burn-down slice: update + merkle lint blockers","description":"Fix immediate clippy -D warnings blockers in src/cli/bootstrap.rs and src/cli/uninstall.rs (needless_collect and unnecessary_mut_passed style test-lint issues) with behavior preserved and rch validation; created after conflicts on update/merkle reservations.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:34:23.437276505Z","created_by":"ubuntu","updated_at":"2026-02-15T16:42:45.292955986Z","closed_at":"2026-02-15T16:42:45.292938002Z","close_reason":"Completed bootstrap/uninstall clippy slice plus regression follow-up; uninstall tests and all-target check now pass, with remaining clippy failures outside this slice.","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"],"comments":[{"id":322,"issue_id":"bd-2ze","author":"Dicklesworthstone","text":"Completed scoped clippy cleanup in reserved files. Changes: src/cli/bootstrap.rs removed needless collect+len, unnecessary mutable-reference passing to apply_init_state_file/apply_fix_permissions, redundant clone in backup footprint, and single-char pattern string; src/cli/uninstall.rs replaced needless collect patterns with iterator any/next checks and tightened KeepData assertions. Validation: cargo fmt --check initially showed only local formatting adjustments; cargo fmt --check on touched files PASS. rch exec 'cargo check --lib' PASS. rch exec 'cargo test --lib bootstrap' and rch exec 'cargo test --lib uninstall' BLOCKED by unrelated compile error in src/cli/assets.rs (borrow of moved entry) under another agent reservation. rch exec 'cargo check --all-targets' likewise blocked by same unrelated assets error. rch exec 'cargo clippy --all-targets -- -D warnings' fails on global backlog; targeted grep shows no remaining clippy mentions for src/cli/bootstrap.rs or src/cli/uninstall.rs.","created_at":"2026-02-15T16:38:06Z"},{"id":323,"issue_id":"bd-2ze","author":"ubuntu","text":"Reopened: Follow-up fix: keep_data_mode test assertion regression introduced during clippy cleanup","created_at":"2026-02-15T16:39:12Z"},{"id":324,"issue_id":"bd-2ze","author":"Dicklesworthstone","text":"Follow-up regression fix complete: adjusted keep_data_mode_keeps_logs_and_db to avoid over-constraining kept categories, and replaced filter+next with find to satisfy clippy::filter_next. Re-validation now passes: cargo fmt --check -- src/cli/uninstall.rs PASS; rch exec 'cargo test --lib uninstall' PASS; rch exec 'cargo check --all-targets' PASS. rch exec 'cargo clippy --lib -- -D warnings' filtered for src/cli/uninstall.rs produced no hits. Full clippy --all-targets still fails due unrelated backlog.","created_at":"2026-02-15T16:42:40Z"}]}
{"id":"bd-30r","title":"Fix PID controller config reload: propagate all pressure thresholds","description":"On SIGHUP reload, only set_target_free_pct() is called but PID stores separate green/yellow/orange/red thresholds used in classify_with_hysteresis(). Need setter for all four.","status":"closed","priority":0,"issue_type":"bug","created_at":"2026-02-15T23:56:09.574138722Z","created_by":"ubuntu","updated_at":"2026-02-16T00:04:15.926098015Z","closed_at":"2026-02-16T00:04:15.926073129Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["daemon"]}
{"id":"bd-329","title":"Clippy debt burn-down slice: example binaries lint blockers","description":"Fix clippy -D warnings blockers in examples/pressure_monitor.rs and examples/scan_artifacts.rs (map_or_else usage, clone_on_copy, numeric cast cleanup) with behavior preserved and rch validation.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:24:55.372080802Z","created_by":"ubuntu","updated_at":"2026-02-15T16:28:20.265569751Z","closed_at":"2026-02-15T16:28:20.265548401Z","close_reason":"Completed: example binaries clippy blockers resolved and validated","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"],"comments":[{"id":325,"issue_id":"bd-329","author":"Dicklesworthstone","text":"Completed non-overlap clippy slice for example binaries.\\n\\nChanges:\\n- examples/pressure_monitor.rs: replaced Option map+unwrap_or_else with map_or_else; removed clone/cast lint path in threshold bytes calc using bounded basis-points integer math.\\n- examples/scan_artifacts.rs: replaced Option map+unwrap_or_else with map_or_else; removed clone_on_copy on structural_signals.\\n\\nValidation:\\n- rch exec \"cargo clippy --examples -- -D warnings\" ✅\\n- rch exec \"cargo check --all-targets\" ✅\\n- cargo fmt --check ✅\\n- rch exec \"cargo clippy --all-targets -- -D warnings\" ❌ (pre-existing lint backlog outside this slice)","created_at":"2026-02-15T16:28:17Z"}]}
{"id":"bd-32s","title":"Wire sbh daemon command to MonitoringDaemon runtime","description":"Replace cli_app daemon stub with real runtime invocation: convert CLI args to daemon::loop_main::DaemonArgs, load config via load_config, initialize MonitoringDaemon, run loop, and map failures to CliError with JSON/human parity.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T22:21:04.959420837Z","created_by":"ubuntu","updated_at":"2026-02-15T22:23:41.034869685Z","closed_at":"2026-02-15T22:23:41.034851821Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-355","title":"Clippy blocker cleanup: installer_e2e + uninstall iterator lints","description":"Clear currently-reported clippy blockers in tests/installer_e2e.rs (redundant_clone, filter_map_next) and src/cli/uninstall.rs (search_is_some) without behavior changes; validate with rch.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:52:30.494546387Z","created_by":"ubuntu","updated_at":"2026-02-15T16:56:34.970640921Z","closed_at":"2026-02-15T16:56:34.970617246Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"]}
{"id":"bd-394","title":"JSONL append-only structured logger","description":"## Deliverable\nAppend-only JSONL (JSON Lines) writer that provides a second, independent log of all sbh activity, optimized for agent consumption and grep-ability.\n\n## Technical Approach\n### JSONL Format\nEach line is a self-contained JSON object:\n```json\n{\"ts\":\"2026-02-14T16:30:00Z\",\"event\":\"artifact_delete\",\"path\":\"/data/projects/foo/.target_opus\",\"size\":3456789012,\"score\":0.87,\"factors\":{\"location\":0.85,\"name\":0.90,\"age\":0.95,\"size\":0.80,\"structure\":0.85},\"pressure\":\"orange\",\"free_pct\":8.3,\"duration_ms\":145,\"ok\":true}\n{\"ts\":\"2026-02-14T16:30:01Z\",\"event\":\"ballast_release\",\"path\":\"/var/lib/sbh/ballast/SBH_BALLAST_FILE_00010.dat\",\"size\":1073741824,\"pressure\":\"red\",\"free_pct\":4.2,\"ok\":true}\n{\"ts\":\"2026-02-14T16:30:02Z\",\"event\":\"pressure_change\",\"level\":\"red->orange\",\"free_pct\":12.1,\"rate_bps\":-50000000}\n```\n\n### Writer Implementation\n```rust\npub struct JsonlWriter {\n    file: BufWriter<File>,\n    path: PathBuf,\n    bytes_written: u64,\n    max_size: u64,           // rotation threshold\n    rotation_count: u32,\n}\n```\n\n### Write Strategy\n- Buffer writes in memory (BufWriter with 64KB buffer)\n- Flush after every logical event (not every line - batch related events)\n- fsync every 10 seconds or on pressure change (not every write - too expensive)\n- Each line is atomic: write the full line then newline in one write() call\n\n### Rotation\nWhen file exceeds max_size_mb:\n- Rename current file to sbh.jsonl.1 (shift existing rotations)\n- Open new sbh.jsonl\n- Keep up to 5 rotated files (configurable)\n\n### Agent-Friendly Design\nAgents can:\n- `tail -f /var/lib/sbh/sbh.jsonl` for live monitoring\n- `grep \"artifact_delete\" sbh.jsonl | jq .` for filtering\n- `jq -s '[.[] | select(.event == \"artifact_delete\")] | length' sbh.jsonl` for counts\n- Parse each line independently (no multi-line records)\n\n### Why Both SQLite AND JSONL?\n1. SQLite: efficient queries, aggregation, statistics, joins\n2. JSONL: portable, grep-able, agent-friendly, survives SQLite corruption\n3. JSONL works even when disk is critically full (can be on a different filesystem)\n4. JSONL is the \"black box recorder\" - if everything else fails, this survives\n\n## Acceptance Criteria\n- Each line is valid JSON\n- Lines are atomic (no partial writes visible to readers)\n- Rotation works correctly without data loss\n- Agent can tail -f and get real-time events\n- All event types have consistent field names\n- Timestamps in ISO 8601 UTC\n- File rotation handles edge cases (rename failures, etc.)\n- Unit tests for writing, rotation, and parsing","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:49:33.020087320Z","created_by":"ubuntu","updated_at":"2026-02-14T19:51:08.884116886Z","closed_at":"2026-02-14T19:51:08.884093723Z","close_reason":"JSONL logger implemented in src/logger/jsonl.rs: LogEntry/EventType/Severity types, JsonlWriter with BufWriter (64KB), atomic write_all lines, file rotation with configurable max_size/rotated_files, 4-level fallback chain (file→fallback→stderr→discard), fsync batching, try_recover, 6 passing tests.","source_repo":".","compaction_level":0,"original_size":0,"labels":["logger"],"dependencies":[{"issue_id":"bd-394","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-394","depends_on_id":"bd-3uk","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":326,"issue_id":"bd-394","author":"Dicklesworthstone","text":"REVIEW: Strengthened fallback chain specification:\n\nThe JSONL writer must implement this explicit degradation ladder:\n\n1. NORMAL: BufWriter → file (64KB buffer, fsync every 10s)\n2. DEGRADED-1: If file write fails (disk full), try reopening file on a DIFFERENT filesystem. Config should allow jsonl_fallback_path (e.g., /dev/shm/sbh.jsonl for RAM-backed fallback)\n3. DEGRADED-2: If fallback path also fails, write to stderr with [SBH-JSONL] prefix so journald/syslog captures events\n4. DEGRADED-3: If stderr write fails (shouldn't happen but defensive), discard events silently — the daemon MUST NOT crash for logging failures\n\nEach degradation level transition must be logged at the NEXT available level.\n\nAlso add: Write JSONL lines using write_all() for a complete buffer (line + newline assembled first), NOT separate write() calls for line and newline. This prevents interleaved partial lines when the file is being tailed by another process.","created_at":"2026-02-14T17:13:46Z"}]}
{"id":"bd-395","title":"Agent/process disk usage attribution (sbh blame)","description":"## Deliverable\nTrack and display which running processes or agents are consuming the most disk space in build artifacts. sbh status --blame and sbh blame commands.\n\n## Usage\n  sbh blame                    # Show disk usage by agent/process\n  sbh blame --json             # Machine-readable output\n\n## Output\n```\nDisk Usage by Agent/Process:\n\n  Agent/Process          │ Build Dirs │ Total Size │ Oldest   │ Newest\n  claude-code (PID 1234) │    23      │   45.2 GB  │ 12h ago  │ 15m ago\n  codex-cli (PID 5678)   │     8      │   12.1 GB  │  4h ago  │ 30m ago\n  pi-agent (PID 9012)    │    14      │   28.7 GB  │  8h ago  │  1h ago\n  (orphaned)             │    31      │   67.4 GB  │  3d ago  │  6h ago\n\n  Total: 76 build dirs, 153.4 GB\n  Orphaned dirs (no running process) are the safest to clean.\n```\n\n## Implementation\n1. Scan /proc/*/cwd to find which processes have CWD in project directories\n2. Correlate discovered artifacts with the project directory of running processes\n3. \"Orphaned\" artifacts belong to projects where no process currently has CWD\n4. Use process binary name (from /proc/*/comm) as agent identifier\n5. Cache /proc scan results (refreshed every 30s or on demand)\n\n## Design Rationale\nHelps users understand which agents are the worst disk offenders. \"Orphaned\" artifacts (no running process) are the safest to clean and can be prioritized. This is a diagnostic tool that makes sbh's decisions more transparent.\n\n## Acceptance Criteria\n- Correctly attributes artifacts to running processes\n- Orphaned artifacts identified and highlighted\n- Works when many agents run simultaneously\n- Performance: <2s even with 100+ processes and 10K+ artifacts\n- JSON output for agent consumption\n- Handles /proc access gracefully (permission denied on some PIDs)","acceptance_criteria":"1. Unit tests cover PID-to-path attribution, orphan detection, and aggregation correctness. 2. Integration tests validate /proc scanning behavior with permission denials and stale process state. 3. E2E scenarios validate blame output across concurrent agent workloads and orphan cleanup opportunities. 4. JSON output schema remains stable for agent consumption. 5. Detailed attribution logs include process identity, matched directories, bytes totals, and unresolved-candidate reasons.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T18:34:05.574878016Z","created_by":"ubuntu","updated_at":"2026-02-14T23:22:55.232016968Z","closed_at":"2026-02-14T23:22:55.231952347Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli","scanner"],"dependencies":[{"issue_id":"bd-395","depends_on_id":"bd-1w9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-395","depends_on_id":"bd-2pj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-395","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-395","depends_on_id":"bd-sth","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":327,"issue_id":"bd-395","author":"Dicklesworthstone","text":"REVIEW: sbh blame is Linux-specific (/proc/*/cwd, /proc/*/comm). Added bd-sth (PAL) as dependency. Implementation: On Linux, use /proc scanning. On macOS, use lsof -c or similar. On other platforms, return an error 'blame command requires Linux or macOS' with exit code 3. The PAL layer provides platform_supports_process_attribution() -> bool and get_process_cwd(pid) -> Option<PathBuf>.","created_at":"2026-02-14T18:53:52Z"}]}
{"id":"bd-39b","title":"Rewrite AGENTS.md for storage_ballast_helper project","description":"## Deliverable\nReplace the current dcg-focused AGENTS.md with one tailored for the storage_ballast_helper (sbh) project.\n\n## Technical Approach\n### Structure (following dcg's excellent pattern)\n1. Rule 0: Fundamental override prerogative\n2. Rule 1: No file deletion without permission\n3. Git branch conventions\n4. Toolchain section (Rust, Cargo, edition, dependencies)\n5. Code editing discipline\n6. Compiler checks (cargo check, clippy, fmt)\n7. Testing section (unit tests, integration, E2E, stress)\n8. CI/CD pipeline overview\n9. Release process\n10. Architecture overview:\n    - Module diagram\n    - Key files table\n    - Data flow description\n11. Configuration reference\n12. CLI quick reference\n13. Scoring engine documentation\n14. Beads/bv workflow integration (keep existing sections)\n15. Session completion protocol\n\n### Key Differences from dcg's AGENTS.md\n- Architecture section describes sbh's monitoring/scanning/cleanup pipeline\n- No \"hook protocol\" section (sbh is a standalone daemon, not a hook)\n- Add scoring engine documentation\n- Add ballast system documentation\n- Add pressure levels and PID controller overview\n- Add build artifact pattern reference\n\n## Acceptance Criteria\n- Comprehensive and self-contained (agent can work from AGENTS.md alone)\n- All key files documented\n- CLI commands documented\n- Architecture clearly explained\n- Testing instructions complete\n- No references to dcg left","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T16:55:04.827031477Z","created_by":"ubuntu","updated_at":"2026-02-15T00:18:49.279774512Z","closed_at":"2026-02-15T00:18:49.279705413Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["docs"],"dependencies":[{"issue_id":"bd-39b","depends_on_id":"bd-1kn","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":328,"issue_id":"bd-39b","author":"Dicklesworthstone","text":"MINOR: AGENTS.md rewrite depends only on bd-2rq (CLI framework) to know the final command structure. It does NOT need to wait for every bead to be implemented — AGENTS.md documents intended behavior, not implemented behavior. Current dep (bd-2rq) is sufficient.","created_at":"2026-02-14T18:54:47Z"}]}
{"id":"bd-3cj","title":"Statistics and metrics query engine with time-window aggregation","description":"## Deliverable\nQuery engine that provides statistics about sbh's recent behavior across multiple time windows, enabling agents and users to understand what sbh has been doing.\n\n## Technical Approach\n### Time Windows\nReport statistics for: 10 minutes, 30 minutes, 1 hour, 6 hours, 24 hours, 3 days, 7 days\n\n### Statistics Available\n```rust\npub struct WindowStats {\n    pub window: Duration,\n    pub deletions: DeletionStats,\n    pub ballast: BallastStats,\n    pub pressure: PressureStats,\n}\n\npub struct DeletionStats {\n    pub count: u64,                      // number of items deleted\n    pub total_bytes_freed: u64,          // total bytes freed\n    pub avg_size: u64,                   // average size of deleted items\n    pub median_size: u64,\n    pub largest_deletion: Option<PathInfo>,\n    pub most_common_category: String,    // e.g., \"RustTarget\"\n    pub most_common_pattern: String,     // e.g., \"cargo-target-*\"\n    pub avg_score: f64,                  // average candidacy score\n    pub avg_age_hours: f64,              // average age at time of deletion\n    pub failures: u64,                   // failed deletions\n}\n\npub struct BallastStats {\n    pub files_released: u64,\n    pub files_replenished: u64,\n    pub current_inventory: u64,\n    pub bytes_available: u64,\n}\n\npub struct PressureStats {\n    pub time_in_green_pct: f64,\n    pub time_in_yellow_pct: f64,\n    pub time_in_orange_pct: f64,\n    pub time_in_red_pct: f64,\n    pub time_in_critical_pct: f64,\n    pub transitions: u64,                // number of pressure level changes\n    pub worst_level_reached: PressureLevel,\n    pub current_level: PressureLevel,\n    pub current_free_pct: f64,\n}\n```\n\n### Query Implementation\n```rust\npub struct StatsEngine {\n    sqlite: Arc<SqliteLogger>,\n}\n\nimpl StatsEngine {\n    /// Get stats for all standard windows\n    pub fn summary(&self) -> Result<Vec<WindowStats>, SbhError>;\n    \n    /// Get stats for a specific window\n    pub fn window_stats(&self, window: Duration) -> Result<WindowStats, SbhError>;\n    \n    /// Get top-N most deleted patterns\n    pub fn top_patterns(&self, n: usize, window: Duration) -> Result<Vec<PatternStat>, SbhError>;\n    \n    /// Get top-N largest deletions\n    pub fn top_deletions(&self, n: usize, window: Duration) -> Result<Vec<DeletionDetail>, SbhError>;\n    \n    /// Export stats as JSON (for agent consumption)\n    pub fn export_json(&self) -> Result<serde_json::Value, SbhError>;\n}\n```\n\n### SQL Queries\nEfficient aggregation using SQLite's date functions:\n```sql\nSELECT \n    COUNT(*) as count,\n    SUM(size_bytes) as total_bytes,\n    AVG(size_bytes) as avg_size,\n    AVG(score) as avg_score\nFROM activity_log\nWHERE event_type = 'artifact_delete'\n  AND timestamp > datetime('now', '-1 hour')\n  AND success = 1;\n```\n\n### Output Format\nBoth human-readable (colored table for terminal) and JSON (for agents):\n```\nsbh stats\n┌─────────┬────────┬──────────────┬──────────────┬────────────┐\n│ Window  │ Deleted│ Space Freed  │ Avg Size     │ Avg Score  │\n├─────────┼────────┼──────────────┼──────────────┼────────────┤\n│ 10 min  │     3  │       4.2 GB │       1.4 GB │      0.87  │\n│ 30 min  │    12  │      18.7 GB │       1.6 GB │      0.82  │\n│  1 hour │    28  │      42.1 GB │       1.5 GB │      0.79  │\n│  6 hours│    85  │     124.3 GB │       1.5 GB │      0.76  │\n│ 24 hours│   312  │     467.8 GB │       1.5 GB │      0.74  │\n│  3 days │   891  │    1284.2 GB │       1.4 GB │      0.73  │\n│  7 days │  2104  │    3012.7 GB │       1.4 GB │      0.72  │\n└─────────┴────────┴──────────────┴──────────────┴────────────┘\n\nMost deleted patterns: cargo-target-* (42%), .target_* (28%), target/ (18%)\nCurrent pressure: GREEN (23.4% free)\nBallast: 8/10 files available (8 GB reclaimable)\n```\n\n## Acceptance Criteria\n- All time windows produce correct statistics\n- Statistics match actual activity log data (verified by cross-checking)\n- JSON output is well-formed and complete\n- Human-readable output is clear and informative\n- Queries are efficient (< 100ms even with 100K+ log entries)\n- Most common patterns correctly computed\n- Handles empty database gracefully\n- Unit tests with pre-populated test data","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T16:50:15.096388928Z","created_by":"ubuntu","updated_at":"2026-02-14T19:59:45.809126758Z","closed_at":"2026-02-14T19:59:45.809098235Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["logger"],"dependencies":[{"issue_id":"bd-3cj","depends_on_id":"bd-1gm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":329,"issue_id":"bd-3cj","author":"Dicklesworthstone","text":"MINOR: Stats engine schema coupling with SQLite logger (bd-2f8): The stats engine queries the SQLite database directly. The schema is defined in bd-2f8 and the stats engine reads it. This is intentional tight coupling — they share the same database. Any schema changes in bd-2f8 must be reflected in bd-3cj queries. Document the schema contract in both beads.","created_at":"2026-02-14T18:54:53Z"}]}
{"id":"bd-3fh","title":"Fix I26: run_status reports stale daemon as running","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T21:07:56.273533662Z","created_by":"ubuntu","updated_at":"2026-02-15T21:19:47.384634360Z","closed_at":"2026-02-15T21:19:47.384613430Z","close_reason":"Implementation verified: run_status checks state file mtime against 2x poll_interval threshold, compilation and clippy pass","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3ge","title":"Fix state.json staleness: use DAEMON_STATE_STALE_THRESHOLD_SECS constant","description":"self_monitor.rs:417 hardcodes 60s staleness check but constant is 90s. Causes spurious daemon stalled warnings.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T23:56:10.985950085Z","created_by":"ubuntu","updated_at":"2026-02-16T00:04:15.927023768Z","closed_at":"2026-02-16T00:04:15.927009341Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["daemon"]}
{"id":"bd-3i3","title":"launchd plist generation and service installation (macOS)","description":"## Deliverable\nGenerate and install a launchd plist for the sbh daemon on macOS.\n\n## Technical Approach\n### Generated Plist\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n    <key>Label</key>\n    <string>com.sbh.daemon</string>\n    <key>ProgramArguments</key>\n    <array>\n        <string>/usr/local/bin/sbh</string>\n        <string>daemon</string>\n    </array>\n    <key>RunAtLoad</key>\n    <true/>\n    <key>KeepAlive</key>\n    <dict>\n        <key>SuccessfulExit</key>\n        <false/>\n    </dict>\n    <key>ThrottleInterval</key>\n    <integer>10</integer>\n    <key>Nice</key>\n    <integer>19</integer>\n    <key>LowPriorityIO</key>\n    <true/>\n    <key>StandardOutPath</key>\n    <string>/usr/local/var/log/sbh/sbh.log</string>\n    <key>StandardErrorPath</key>\n    <string>/usr/local/var/log/sbh/sbh.err</string>\n</dict>\n</plist>\n```\n\n### Installation Flow\n```bash\nsbh install --launchd\n```\n1. Generate plist from template\n2. Copy to ~/Library/LaunchAgents/com.sbh.daemon.plist (user) or /Library/LaunchDaemons/ (system)\n3. launchctl load plist_path\n4. Verify service is running\n\n### macOS-specific Considerations\n- No sd_notify equivalent; use different health check\n- macOS paths differ (~/Library/Application Support/sbh/)\n- Need to handle SIP restrictions (System Integrity Protection)\n- macOS doesn't have /dev/shm or tmpfs in the same way\n\n## Acceptance Criteria\n- Generated plist is valid XML\n- Service loads and starts via launchctl\n- Auto-restart on crash (KeepAlive)\n- Low priority scheduling (Nice=19, LowPriorityIO)\n- Works as user agent (no root required)\n- Integration test on macOS: install → start → verify → stop → uninstall","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T16:51:18.776325044Z","created_by":"ubuntu","updated_at":"2026-02-14T23:12:18.513244001Z","closed_at":"2026-02-14T23:12:18.513213604Z","close_reason":"Implemented launchd plist generation and service installation for macOS. 11 launchd unit tests plus 15 systemd tests (26 total) all passing. CLI handlers wired up for install/uninstall --launchd.","source_repo":".","compaction_level":0,"original_size":0,"labels":["daemon","platform"],"dependencies":[{"issue_id":"bd-3i3","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3i3","depends_on_id":"bd-2j5.3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3i3","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-3il","title":"Deep audit hardening: merkle/protection/update/jsonl/self-monitor/assets","description":"Root-cause fixes from deep audit across reserved non-overlap files","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T16:38:00.095920032Z","created_by":"ubuntu","updated_at":"2026-02-15T16:38:14.035495393Z","closed_at":"2026-02-15T16:38:14.035474063Z","close_reason":"Completed and validated","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli","reliability","scanner","security"],"comments":[{"id":330,"issue_id":"bd-3il","author":"Dicklesworthstone","text":"Implemented and validated fixes: (1) Merkle budget now defers only changed/new paths after exhaustion and rehashes ancestors on remove_paths; (2) protection glob/path matching normalizes Windows separators; (3) self_monitor reconstructs last_scan_at Instant from RFC3339 timestamp; (4) assets cleanup uses same sanitized path components as cache layout; (5) update tempdir uses random per-invocation unique dirs; (6) JSONL writer performs throttled automatic recovery attempts while degraded. Validation: rch exec 'cargo test --lib', rch exec 'cargo check --all-targets', rch exec 'cargo clippy --lib -- -D warnings', rch exec 'cargo test --test integration_tests'.","created_at":"2026-02-15T16:38:10Z"}]}
{"id":"bd-3lg","title":"Fix I5+I33+I2: Stats engine gaps — SQLite recovery, missing event writes, Unknown level ordering","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T21:20:36.770696081Z","created_by":"ubuntu","updated_at":"2026-02-15T21:23:17.042424199Z","closed_at":"2026-02-15T21:23:17.042406045Z","close_reason":"All 3 issues already fixed: I5 (SQLite recovery loop every 50 cycles), I33 (all 3 event types write to SQLite via event_to_activity_row), I2 (PressureLevel uses explicit repr(u8) discriminants)","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3lv","title":"Fix C2+C3+I17: Ballast fallocate durability — missing sync_all, wrong length, underflow","status":"closed","priority":0,"issue_type":"bug","created_at":"2026-02-15T21:20:31.373863488Z","created_by":"ubuntu","updated_at":"2026-02-15T21:21:15.626242674Z","closed_at":"2026-02-15T21:21:15.626217717Z","close_reason":"Already fixed in current codebase: sync_all added to fallocate path, correct offset/length used, underflow guard in place","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3n0","title":"Fix replenish check tautology in BallastReleaseController","description":"available_count() >= inventory().len() is always true since both return self.inventory.len(). Should compare against config.file_count instead.","status":"closed","priority":0,"issue_type":"bug","created_at":"2026-02-15T23:56:08.057446001Z","created_by":"ubuntu","updated_at":"2026-02-16T00:03:51.901480979Z","closed_at":"2026-02-16T00:03:51.901463276Z","close_reason":"Fixed: compare available_count() against config().file_count instead of tautological inventory().len(). Added regression test.","source_repo":".","compaction_level":0,"original_size":0,"labels":["ballast"]}
{"id":"bd-3ok","title":"Canonicalize paths in sbh protect/unprotect to prevent symlink traversal","status":"closed","priority":1,"issue_type":"bug","assignee":"RedWren","created_at":"2026-02-15T22:40:17.873128143Z","created_by":"ubuntu","updated_at":"2026-02-15T22:58:06.749748451Z","closed_at":"2026-02-15T22:58:06.749726250Z","close_reason":"Completed: canonicalized protect/unprotect paths and added protection-registry canonical alias handling with tests","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3po","title":"PID-based storage pressure controller","description":"## Deliverable\nA PID (Proportional-Integral-Derivative) controller that determines how aggressively sbh should respond to storage pressure, replacing simplistic threshold-based reactions with smooth, oscillation-free behavior.\n\n## Technical Approach\n### Theory (Alien Graveyard: PID control from control theory)\nInstead of simple \"if free < 5% then panic\", use a feedback controller:\n\n- **P (Proportional)**: Response proportional to how far we are from target free%\n  - Large deviation → aggressive cleanup\n  - Small deviation → gentle cleanup\n  \n- **I (Integral)**: Accumulated error over time\n  - Persistent pressure (free% stayed low for minutes) → escalate response\n  - Prevents the system from being \"stuck\" at a slightly-too-low level\n  - Anti-windup clamp prevents integral term from growing unboundedly\n  \n- **D (Derivative)**: Rate of change (from EWMA estimator)\n  - Rapid disk consumption → preemptive aggressive response\n  - Rapid recovery → dampen response to prevent over-correction\n\n### Implementation\n```rust\npub struct PressureController {\n    // PID gains (configurable)\n    kp: f64,  // proportional gain (default 1.0)\n    ki: f64,  // integral gain (default 0.1)\n    kd: f64,  // derivative gain (default 0.5)\n    \n    // State\n    setpoint: f64,           // target free% (default 15.0)\n    integral: f64,           // accumulated error\n    integral_clamp: f64,     // anti-windup limit\n    previous_error: f64,     // for derivative calculation\n    last_update: Instant,\n    \n    // Hysteresis (Alien Graveyard: prevent oscillation)\n    hysteresis_band: f64,    // ±2% band around setpoint\n    last_action: PressureAction,\n}\n\npub struct PressureReading {\n    pub free_pct: f64,\n    pub rate_estimate: RateEstimate,\n    pub timestamp: Instant,\n}\n\npub enum PressureLevel {\n    Green,     // > setpoint + hysteresis → no action needed\n    Yellow,    // within hysteresis band → maintain current action\n    Orange,    // below setpoint → moderate cleanup\n    Red,       // significantly below setpoint → aggressive cleanup\n    Critical,  // near 0% → emergency: delete ballast + all safe artifacts\n}\n\npub struct PressureResponse {\n    pub level: PressureLevel,\n    pub urgency: f64,              // 0.0-1.0 (PID output, clamped)\n    pub recommended_actions: Vec<PressureAction>,\n    pub scan_interval: Duration,   // adaptive scan interval\n    pub max_delete_batch: usize,   // how many items to delete per cycle\n}\n\npub enum PressureAction {\n    NoAction,\n    IncreaseScanFrequency,\n    ReleaseBallast(usize),  // release N ballast files\n    DeleteArtifacts { min_score: f64 },\n    EmergencyCleanup,\n}\n```\n\n### Hysteresis (Alien Graveyard: prevent oscillation)\nWithout hysteresis, the controller would oscillate:\n1. Free drops to 14% → start cleaning\n2. Free rises to 16% → stop cleaning\n3. Free drops to 14% → start cleaning again\n4. (repeat forever)\n\nWith a 2% hysteresis band around the 15% setpoint:\n- Start cleaning when free < 13%\n- Stop cleaning when free > 17%\n- This creates stable behavior\n\n### Adaptive Scan Intervals\nThe PID output also controls scan frequency:\n- Green: scan every 60s\n- Yellow: scan every 30s\n- Orange: scan every 10s\n- Red: scan every 5s\n- Critical: scan every 1s\n\n## Design Rationale\nSimple threshold systems lead to oscillation, delayed response, or over-reaction. A PID controller with hysteresis provides:\n1. Smooth, proportional responses (not all-or-nothing)\n2. Faster reaction to rapid changes (derivative term)\n3. Persistent pressure handled by integral buildup\n4. No oscillation thanks to hysteresis band\n5. Tunable behavior via gains (users can adjust aggressiveness)\n\n## Acceptance Criteria\n- PID output is smooth and bounded (no oscillation in test scenarios)\n- Hysteresis prevents chattering between states\n- Anti-windup prevents integral runaway\n- Response proportional to pressure severity\n- Scan intervals adapt correctly to pressure level\n- Unit tests with simulated pressure scenarios\n- Test: sustained 10% pressure → integral buildup → escalated response\n- Test: sudden spike → derivative kicks in → fast response\n- Test: recovery → smooth return to normal scanning","acceptance_criteria":"1. Unit tests validate PID term calculations, anti-windup, clamps, and hysteresis transitions. 2. Closed-loop integration tests verify stable behavior with noisy EWMA pressure input. 3. E2E pressure scenarios validate action selection under burst, sustained, and recovery phases. 4. Controller output is monotonic with urgency and respects hard safety caps. 5. Detailed control-loop logs include P/I/D components, setpoint error, selected action, and guard/fallback reason codes.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:45:54.009722683Z","created_by":"ubuntu","updated_at":"2026-02-14T19:45:22.203475921Z","closed_at":"2026-02-14T19:45:22.203448800Z","close_reason":"PID pressure controller implemented in monitor/pid.rs (359 lines): PidPressureController with PressureLevel enum (Green-Critical), hysteresis, anti-windup integral, predictive boosting (time-to-red signals), response_policy with adaptive scan intervals, unit tests for escalation/hysteresis/prediction.","source_repo":".","compaction_level":0,"original_size":0,"labels":["alien-graveyard","monitoring"],"dependencies":[{"issue_id":"bd-3po","depends_on_id":"bd-3uk","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3po","depends_on_id":"bd-x1k","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":331,"issue_id":"bd-3po","author":"Dicklesworthstone","text":"REVIEW-2: Removed bd-2pj dependency, added bd-3uk dependency. PID controller receives PressureReading from the caller (main loop). It does not import or call FsStatsCollector. Data flow: main loop calls FsStatsCollector -> creates PressureReading -> passes to PressureController.update(). PID controller is pure computation on top of the reading. Needs bd-3uk for config validation errors (invalid PID gains).","created_at":"2026-02-14T19:03:06Z"}]}
{"id":"bd-3q8","title":"Guard status JSON ballast total from overflow","description":"sbh status --json multiplies ballast file_count * file_size_bytes directly; large configs can overflow u64 and panic in debug or wrap in release.","status":"closed","priority":1,"issue_type":"bug","assignee":"RedWren","created_at":"2026-02-15T22:58:38.759866213Z","created_by":"RedWren","updated_at":"2026-02-15T23:04:08.315429254Z","closed_at":"2026-02-15T23:04:08.315411100Z","close_reason":"Completed: status JSON ballast total now uses overflow-safe helper with unit coverage","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3qm","title":"Project protection system with marker files and CLI","description":"## Deliverable\nUser-controllable project protection that prevents sbh from ever deleting artifacts in protected directories.\n\n## The Problem\nThe scoring engine has hard vetoes (.git, system paths, age), but there is NO way for users to say \"never touch THIS specific project.\" Users WILL have projects with 6-hour builds they cannot afford to lose. Without explicit protection, they will never trust sbh on production machines.\n\n## The Solution\n\n### Marker Files\nDrop a .sbh-protect file in any directory to protect it and all children from sbh cleanup:\n  touch /data/projects/critical-app/.sbh-protect\n\nThe walker checks for .sbh-protect during traversal. If found, the entire directory subtree is skipped — not scored, not walked, not considered.\n\n### CLI Commands\n  sbh protect <path>        # Creates .sbh-protect marker file\n  sbh protect --list        # Shows all protected paths (marker files + config)\n  sbh unprotect <path>      # Removes .sbh-protect marker file\n  sbh scan --show-protected # Includes protected paths in output with [PROTECTED] label\n\n### Config-Level Protection\nFor system-wide or pattern-based protection:\n  [scanner.protected_paths]\n  paths = [\"/data/projects/production-*\", \"/home/*/critical-builds\"]\n\nConfig protection works via glob patterns and does NOT require marker files.\n\n### Implementation\n1. ProtectionRegistry: loaded at startup from config + discovered marker files\n2. Walker integration: during traversal, check each directory for .sbh-protect before descending\n3. Scoring integration: protected paths get hard veto (score = 0.0, veto_reason = \"Protected by .sbh-protect\")\n4. CLI commands: trivial file create/delete operations\n5. Protection persists across restarts (marker files are on disk, config is in TOML)\n\n### Data Structure\n```rust\npub struct ProtectionRegistry {\n    marker_paths: HashSet<PathBuf>,      // discovered .sbh-protect locations\n    config_patterns: Vec<GlobPattern>,   // from config file\n}\n\nimpl ProtectionRegistry {\n    pub fn is_protected(&self, path: &Path) -> bool;\n    pub fn protection_reason(&self, path: &Path) -> Option<String>;\n    pub fn discover_markers(&mut self, root: &Path);\n}\n```\n\n### .sbh-protect File Format\nThe file can be empty (presence is sufficient) OR contain optional JSON metadata:\n```json\n{\n  \"reason\": \"Production build - 6 hour compile time\",\n  \"protected_by\": \"jeff\",\n  \"protected_at\": \"2026-02-14T10:00:00Z\"\n}\n```\nThe metadata is displayed in sbh scan --show-protected and sbh protect --list.\n\n## Design Rationale\nThis is the #1 trust-building feature. Without it, sophisticated users won't deploy sbh on production machines. With it, they feel in control. Implementation cost is near-zero: one additional check in the walker + two CLI commands. The marker file approach is elegant because: (1) it's discoverable (ls shows it), (2) it's portable (survives config changes), (3) it's git-committable (team-wide protection), (4) it requires zero sbh knowledge to create (just touch a file).\n\n## Acceptance Criteria\n- .sbh-protect marker file prevents all cleanup in that directory and children\n- sbh protect <path> creates marker file correctly\n- sbh unprotect <path> removes marker file\n- sbh protect --list shows all protections (marker + config) with metadata\n- Config-level glob patterns work correctly\n- Protected paths appear in sbh scan with [PROTECTED] label\n- Walker skips protected directories entirely (no unnecessary traversal)\n- Protection survives daemon restart\n- Empty .sbh-protect file works (metadata optional)\n- Unit tests: protection check logic, glob patterns, nested protection\n- Integration test: protect dir -> scan -> verify not scored -> unprotect -> scan -> verify scored","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T18:31:09.551558875Z","created_by":"ubuntu","updated_at":"2026-02-14T21:33:45.424324194Z","closed_at":"2026-02-14T21:33:45.424302945Z","close_reason":"Implemented ProtectionRegistry with dual-mode (full/marker-only), marker file discovery, config glob patterns, 26 unit tests all passing","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli","scanner"],"dependencies":[{"issue_id":"bd-3qm","depends_on_id":"bd-1kn","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3qm","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3qm","depends_on_id":"bd-3uk","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":332,"issue_id":"bd-3qm","author":"Dicklesworthstone","text":"IMPORTANT: The protection system must work in TWO modes:\n1. FULL MODE (with config): reads scanner.protected_paths from config AND discovers .sbh-protect marker files\n2. MARKER-ONLY MODE (without config): only discovers .sbh-protect marker files during walker traversal\n\nThis is critical because the emergency mode (bd-2qa) uses the walker, and the walker depends on the protection system. Emergency mode operates WITHOUT any config file. The protection system must gracefully handle the 'no config available' case by falling back to marker-only mode.\n\nImplementation: ProtectionRegistry::new() takes Optional<Config>. When None, skip config-level glob patterns and only use marker file discovery.","created_at":"2026-02-14T18:36:31Z"},{"id":333,"issue_id":"bd-3qm","author":"Dicklesworthstone","text":"REVIEW-2: Removed bd-2rq dependency. The ProtectionRegistry is a LIBRARY component (marker file discovery, glob matching, is_protected() API). It does NOT import CLI framework code. CLI commands (sbh protect/unprotect) are wired into bd-2rq when that bead is implemented. bd-3qm deps: bd-3qw (config for glob patterns), bd-3uk (error types), bd-1kn (scaffolding).","created_at":"2026-02-14T19:02:48Z"}]}
{"id":"bd-3qw","title":"Configuration system with TOML + env vars + smart defaults","description":"## Deliverable\nComprehensive configuration system supporting layered config: defaults → system config → user config → env vars → CLI flags.\n\n## Technical Approach\n### Config File Location (XDG-compliant)\n- Linux: ~/.config/sbh/config.toml, /etc/sbh/config.toml\n- macOS: ~/Library/Application Support/sbh/config.toml\n- Windows: %APPDATA%\\sbh\\config.toml\n\n### Config Structure\n```toml\n[general]\nlog_level = \"info\"                  # trace/debug/info/warn/error\nscan_interval_seconds = 30          # base scan interval\ncritical_scan_interval_seconds = 5  # scan interval when pressure is high\ndry_run = false                     # log what would be deleted without deleting\n\n[ballast]\nenabled = true\nlocation = \"/var/lib/sbh/ballast\"   # or auto-detect\nfile_count = 10                     # number of 1GB ballast files\nfile_size_mb = 1024                 # size of each ballast file\nmin_free_after_release_pct = 15.0   # target free% after releasing ballast\n\n[pressure]\ngreen_threshold_pct = 20.0          # > 20% free = green\nyellow_threshold_pct = 15.0         # 10-20% = yellow (warning)\norange_threshold_pct = 10.0         # 5-10% = orange (alert)\nred_threshold_pct = 5.0             # < 5% = red (critical)\ncritical_threshold_pct = 2.0        # < 2% = emergency\n\n# PID controller tuning\npid_kp = 1.0                        # proportional gain\npid_ki = 0.1                        # integral gain (accumulated pressure)\npid_kd = 0.5                        # derivative gain (rate of change)\n\n[scanner]\nmax_depth = 10                      # max directory recursion depth\nmin_file_age_minutes = 30           # never delete files newer than this\nsweet_spot_min_hours = 2.0          # ideal deletion age range start\nsweet_spot_max_hours = 10.0         # ideal deletion age range end\nmin_size_mb = 10                    # skip files smaller than this\n\n[scanner.watched_paths]\n# paths to actively scan for build artifacts\npaths = [\"/data/projects\", \"/tmp\", \"/data/tmp\", \"/home\"]\n\n[scanner.excluded_paths]\n# paths to NEVER touch\npaths = [\"/\", \"/boot\", \"/etc\", \"/usr\", \"/bin\", \"/sbin\", \"/var/log\"]\n\n[scanner.special_locations]\n# RAM-backed locations requiring hawk-like monitoring\npaths = [\"/tmp\", \"/dev/shm\", \"/run/shm\"]\nbuffer_pct = 15.0                   # maintain this % free minimum\n\n[logger]\nsqlite_path = \"/var/lib/sbh/sbh.db\"\njsonl_path = \"/var/lib/sbh/sbh.jsonl\"\nmax_jsonl_size_mb = 100             # rotate JSONL at this size\nretention_days = 30                 # keep logs for this many days\n```\n\n### Environment Variable Override Pattern\nEvery config key maps to an env var: `SBH_BALLAST_FILE_COUNT=20` overrides `ballast.file_count`.\n\n### Validation\nAll config values validated on load with clear error messages. Invalid values → SBH-2xxx errors with suggestions.\n\n## Design Rationale\nLayered configuration with env var overrides is essential for containerized/systemd environments where you want to customize behavior without editing files. Smart defaults mean sbh works out of the box with zero configuration on typical Linux systems. The PID controller tuning parameters allow advanced users to tune pressure response behavior.\n\n## Acceptance Criteria\n- Default config works out of the box (no config file needed)\n- Config loads from correct platform-specific locations\n- Env vars override file config\n- All values validated with helpful error messages on invalid input\n- Config serializes to/from TOML round-trip perfectly\n- Unit tests for default values, overrides, validation","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:44:16.034562214Z","created_by":"ubuntu","updated_at":"2026-02-14T19:45:09.678739039Z","closed_at":"2026-02-14T19:45:09.678714423Z","close_reason":"Configuration system implemented in core/config.rs (481 lines): full TOML parsing, env var overrides (SBH_*), PressureConfig with thresholds, ScannerConfig, ScoringConfig with weights, BallastConfig, TelemetryConfig, PathsConfig, comprehensive validation, unit tests.","source_repo":".","compaction_level":0,"original_size":0,"labels":["foundation"],"dependencies":[{"issue_id":"bd-3qw","depends_on_id":"bd-1kn","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3qw","depends_on_id":"bd-3uk","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":334,"issue_id":"bd-3qw","author":"Dicklesworthstone","text":"REVIEW: Two additions needed:\n\n1. PID CONTROLLER CONFIG: The config bead's TOML example includes pid_kp, pid_ki, pid_kd, hysteresis_band parameters, but the bead description doesn't mention exposing these through the config structure. The Config struct must include a PidConfig section:\n  [pressure.pid]\n  kp = 1.0\n  ki = 0.1\n  kd = 0.5\n  hysteresis_band_pct = 2.0\n  setpoint_free_pct = 15.0\n  integral_clamp = 10.0\n\n2. SPECIAL LOCATIONS CONFIG: The config should include a [scanner.special_locations] section for configuring special location monitoring parameters beyond just the paths:\n  [scanner.special_locations]\n  paths = [\"/tmp\", \"/dev/shm\", \"/run/shm\"]\n  buffer_pct = 15.0\n  scan_interval_seconds = 5\n\nThis ensures the special location registry (bd-1td) can read its configuration from the same config system instead of having hardcoded defaults.","created_at":"2026-02-14T17:14:36Z"},{"id":335,"issue_id":"bd-3qw","author":"Dicklesworthstone","text":"ENHANCEMENT (idea-wizard): Add per-category retention policies in config. Different artifact types should have different age thresholds:\n  [scanner.retention]\n  rust_target.min_age_minutes = 60      # Rust builds are expensive\n  node_modules.min_age_minutes = 30     # npm install is fast\n  python_cache.min_age_minutes = 15     # __pycache__ is trivially regenerated\n  cache_dirs.min_age_minutes = 120      # ~/.cache might have important state\n  agent_workspace.min_age_minutes = 45  # Agent workspaces need moderate protection\n\nThe scoring engine (bd-x9z) would check the category-specific min_age rather than the global min_file_age_minutes. This makes sbh smarter about what to clean first: cheap-to-rebuild artifacts get cleaned before expensive-to-rebuild ones.","created_at":"2026-02-14T18:35:03Z"}]}
{"id":"bd-3s5","title":"Live TUI dashboard with real-time pressure visualization","description":"## Deliverable\nsbh dashboard — a live terminal UI showing real-time pressure gauges, EWMA trends, scan activity, and deletion history. Uses frankentui reference patterns from /dp/frankentui.\n\n## Technical Approach\n### CLI\n  sbh dashboard              # Launch interactive TUI dashboard\n  sbh dashboard --refresh 2  # Custom refresh interval (default 1s)\n\n### Layout\n```\n┌─ Storage Ballast Helper v0.1.0 ──────────────────────────── uptime: 3d 14h ─┐\n│                                                                               │\n│  Pressure Gauges                                                              │\n│  /data    [████████████░░░░░░░░] 62% used (684 GB free)  GREEN               │\n│  /tmp     [██████████████████░░] 90% used (3.2 GB free)  ORANGE  ⚠ 18m left  │\n│  /dev/shm [████░░░░░░░░░░░░░░░░] 23% used (198 GB free) GREEN               │\n│                                                                               │\n│  EWMA Trends (last 30 min)                                                    │\n│  /data  ▁▁▂▃▄▅▆▅▄▃▂▁▁▁▁  -12 MB/s (recovering)                             │\n│  /tmp   ▁▂▃▅▇█████████   +245 MB/s (accelerating) ⚠                         │\n│                                                                               │\n│  Recent Activity                                          Ballast             │\n│  16:30:01 DEL cargo-target-mvcc (4.2 GB, 0.94)          /data: 8/10 avail   │\n│  16:29:55 DEL .target_opus_main (8.1 GB, 0.91)          /tmp:  3/3 avail    │\n│  16:29:40 SCAN /data/projects (47 candidates)            /: 5/5 avail        │\n│  16:29:00 ALERT /tmp approaching threshold                                    │\n│                                                                               │\n│  PID: P=0.3 I=0.1 D=0.8 | Scans: 1542 | Deleted: 312 (467 GB) | Errs: 2   │\n└───────────────────────────────────────────────────────────────────────────────┘\n```\n\n### Implementation\n- Refresh via polling state.json + live fs stats\n- Sparkline charts for EWMA trends (unicode block characters)\n- Color-coded pressure levels (green/yellow/orange/red with ANSI colors)\n- Scrollable activity log\n- PID controller state at bottom\n- Uses crossterm for terminal manipulation (already used by frankentui)\n- Graceful exit on q/Ctrl-C\n\n### Reference\nFollow patterns from /dp/frankentui for rendering approach, color schemes, layout primitives.\n\n## Acceptance Criteria\n- Live updating display (1s default refresh)\n- All monitored volumes shown with pressure gauges\n- EWMA trend sparklines for each volume\n- Recent activity log with timestamps\n- Ballast inventory per volume\n- PID controller state summary\n- Graceful exit, restores terminal state\n- Works when daemon is not running (degraded mode showing static fs stats)\n- Handles terminal resize","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T18:33:16.217664974Z","created_by":"ubuntu","updated_at":"2026-02-15T00:33:25.250169770Z","closed_at":"2026-02-15T00:33:25.250006787Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"],"dependencies":[{"issue_id":"bd-3s5","depends_on_id":"bd-2np","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3s5","depends_on_id":"bd-2pj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3s5","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3s5","depends_on_id":"bd-3cj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-3sb","title":"Stress test and load simulator for extreme pressure scenarios","description":"## Deliverable\nStress and load simulator for extreme pressure scenarios, including adaptive-policy guard/fallback paths.\n\n## Scenario Matrix\nA. Rapid fill burst under compile-like load\nB. Sustained low-free-space pressure\nC. Flash fill in RAM-backed locations\nD. Recovery under ongoing write pressure\nE. High CPU + high I/O overload condition\nF. Decision-plane drift event triggering fallback\nG. Index integrity failure forcing full-scan mode\n\n## Metrics Collection\n- time to detection and first action\n- reclaimed vs consumed bytes\n- controller mode transitions and guard states\n- fallback trigger counts and recovery windows\n- sbh CPU/memory/IO overhead\n\n## Detailed Logging Contract\n- per-phase trace identifiers\n- action selection rationale\n- fallback reason codes and guard metrics\n- before/after pressure snapshots\n\n## Acceptance Criteria\n- all scenarios pass with deterministic checks\n- fallback behavior triggered and validated where expected\n- no crashes, deadlocks, or unbounded resource growth\n- machine-readable stress report emitted\n- stress harness integrated with CI/nightly path","acceptance_criteria":"1. Stress scenarios validate behavior under bursty load, sustained pressure, and recovery. 2. Resource ceilings and stability invariants are enforced (no deadlock/leak/unbounded growth). 3. Adaptive-policy guard/fallback transitions are triggered and verified under induced drift/faults. 4. Stress logs include per-phase metrics, action timelines, and failure snapshots for replay. 5. Reports are emitted in machine-readable form and archived by CI/nightly workflows.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T16:54:41.876853351Z","created_by":"ubuntu","updated_at":"2026-02-15T01:57:23.279207139Z","closed_at":"2026-02-15T01:57:23.279106831Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["testing"],"dependencies":[{"issue_id":"bd-3sb","depends_on_id":"bd-21z","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3sb","depends_on_id":"bd-2np","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3sb","depends_on_id":"bd-2q9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3sb","depends_on_id":"bd-2up","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3sb","depends_on_id":"bd-3po","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3sb","depends_on_id":"bd-izu.1","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3sb","depends_on_id":"bd-izu.3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3sb","depends_on_id":"bd-izu.4","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3sb","depends_on_id":"bd-izu.5","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3sb","depends_on_id":"bd-x1k","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":336,"issue_id":"bd-3sb","author":"Dicklesworthstone","text":"ENHANCEMENT (idea-wizard): Add realistic agent swarm simulation as Scenario F:\n\n**Scenario F: Multi-Agent Swarm Simulation**\n- Spawn N simulated agents (default 10, configurable) as separate threads\n- Each agent: creates a uniquely-named target dir, writes 500MB-2GB of fake build data over 30-60 seconds, pauses 10-30s, then starts another build\n- Agent naming follows real patterns: .target_opus_main, cargo-target-quietwillow, pi_agent_cyanrobin\n- Some agents finish and stop, others run continuously\n- Verify sbh correctly handles: overlapping builds, rapid creation, varying sizes, some targets with .git (should be vetoed), some with active processes (should be vetoed via is_open)\n- Metrics: total disk consumed by agents over 10 min, total freed by sbh, peak disk usage, number of false positives (vetoed items that were correctly protected)\n- This is the single most realistic test — it directly simulates the production scenario sbh exists for.","created_at":"2026-02-14T18:35:03Z"}]}
{"id":"bd-3t9","title":"Clippy debt burn-down slice: daemon signals + pid test lint blockers","description":"Fix immediate clippy -D warnings blockers in src/daemon/signals.rs and src/monitor/pid.rs (unchecked_time_subtraction and float_cmp in tests) while preserving behavior; validate via rch.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:30:57.245084878Z","created_by":"ubuntu","updated_at":"2026-02-15T16:33:55.224079431Z","closed_at":"2026-02-15T16:33:55.224057039Z","close_reason":"Completed targeted signals/pid clippy blocker slice with passing rch tests/check; remaining clippy failures are unrelated backlog.","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"],"comments":[{"id":337,"issue_id":"bd-3t9","author":"Dicklesworthstone","text":"Validated and completed targeted lint blockers for daemon signals/pid tests in current tree. Relevant lines now use checked Instant subtraction in src/daemon/signals.rs watchdog test and epsilon-based zero comparison in src/monitor/pid.rs free_pct test. Validation: cargo fmt --check failed globally due unrelated files; targeted cargo fmt --check on src/daemon/signals.rs and src/monitor/pid.rs PASS. rch exec 'cargo test --lib signals' PASS. rch exec 'cargo test --lib pid' PASS. rch exec 'cargo check --all-targets' PASS. rch exec 'cargo clippy --all-targets -- -D warnings' FAIL with unrelated backlog, with no reported clippy entries for src/daemon/signals.rs or src/monitor/pid.rs in output and targeted grep check.","created_at":"2026-02-15T16:33:52Z"}]}
{"id":"bd-3uc","title":"Guard EWMA against out-of-order timestamps","description":"DiskRateEstimator::update should not panic if observed_at regresses; use checked duration and fallback behavior with regression test.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T22:27:58.294632925Z","created_by":"ubuntu","updated_at":"2026-02-15T22:31:38.360986520Z","closed_at":"2026-02-15T22:31:38.360968476Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3uk","title":"Core error types with SBH-prefixed error codes","description":"## Deliverable\nDefine the comprehensive error type system for sbh with machine-parseable error codes.\n\n## Technical Approach\nFollowing dcg's pattern of prefixed error codes (DCG-XXXX), create SBH-XXXX codes:\n\n### Error Categories\n- SBH-1xxx: Storage monitoring errors (statvfs failures, mount detection errors)\n- SBH-2xxx: Configuration errors (parse failures, invalid values, missing config)\n- SBH-3xxx: Runtime/daemon errors (signal handling, service install failures)\n- SBH-4xxx: Scanner errors (permission denied, broken symlinks, walk failures)\n- SBH-5xxx: Logger errors (SQLite failures, JSONL write errors, disk full during logging)\n- SBH-6xxx: Ballast errors (creation failures, integrity check failures)\n\n### Error Traits\n- All errors implement std::error::Error via thiserror\n- All errors carry structured context (path, filesystem, operation)\n- Errors are serializable to JSON for machine consumption\n- Recoverability classification: Transient (retry), Permanent (fail), Unknown\n\n### Key Types\n```rust\npub enum SbhError {\n    Storage(StorageError),\n    Config(ConfigError),\n    Runtime(RuntimeError),\n    Scanner(ScannerError),\n    Logger(LoggerError),\n    Ballast(BallastError),\n}\n\npub enum Recoverability {\n    Transient,  // Safe to retry\n    Permanent,  // Unrecoverable\n    Unknown,    // Context-dependent\n}\n```\n\n## Design Rationale\nInspired by asupersync's three-tier error system and dcg's DCG-XXXX codes. Machine-parseable error codes let agents programmatically handle failures. Recoverability classification enables the daemon to auto-retry transient failures (disk temporarily busy) while surfacing permanent failures (permissions wrong) immediately.\n\n## Acceptance Criteria\n- All error variants have unique SBH-XXXX codes\n- All errors implement Display with human-readable messages\n- All errors serialize to JSON with code, category, message, context fields\n- Unit tests verify error code uniqueness and serialization round-trip","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:43:52.126552163Z","created_by":"ubuntu","updated_at":"2026-02-14T19:45:09.504253089Z","closed_at":"2026-02-14T19:45:09.504233472Z","close_reason":"Core error types implemented in core/errors.rs (138 lines): SBH-prefixed error codes (1001-3900), thiserror derives, Recoverability classification (is_retryable), Display/From impls for rusqlite/serde_json/toml errors.","source_repo":".","compaction_level":0,"original_size":0,"labels":["foundation"],"dependencies":[{"issue_id":"bd-3uk","depends_on_id":"bd-1kn","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-48o","title":"Main monitoring loop with tiered scan frequencies","description":"## Deliverable\nThe central daemon monitoring loop that orchestrates all sbh components: pressure monitoring, ballast management, artifact scanning, and cleanup.\n\n## Technical Approach\n### Architecture\nThe daemon runs as a single process with multiple threads:\n1. **Monitor thread**: Polls filesystem stats, updates EWMA, runs PID controller\n2. **Scanner thread**: Walks directories, scores candidates (triggered by monitor)\n3. **Executor thread**: Deletes candidates from the ranked queue\n4. **Logger thread**: Writes to SQLite and JSONL (receives events via channel)\n\nCommunication via crossbeam channels (no tokio, following asupersync's no-tokio philosophy):\n```\nMonitor → (PressureEvent) → Scanner\nScanner → (CandidateList) → Executor\nAll    → (ActivityEvent)  → Logger\n```\n\n### Tiered Scan Frequencies\nDifferent locations get different scan intervals based on criticality:\n\n**Tier 1: Special locations (5-second cycle)**\n- /tmp (tmpfs)\n- /dev/shm\n- Any RAM-backed mount\n- Check free% and alert if below buffer threshold\n\n**Tier 2: Primary project locations (30-second cycle)**\n- /data/projects/*\n- /home/*/projects/*\n- Full artifact scanning with scoring\n\n**Tier 3: Cache and misc locations (120-second cycle)**\n- ~/.cache/*\n- /data/tmp/*\n- Less aggressive scanning\n\n### Adaptive Frequency\nThe PID controller output adjusts these base intervals:\n- Green pressure: use base intervals\n- Yellow: halve intervals\n- Orange: quarter intervals\n- Red: minimum intervals (1s for special, 5s for primary, 15s for cache)\n- Critical: maximum frequency on all tiers\n\n### Main Loop Pseudocode\n```rust\nloop {\n    // 1. Collect filesystem stats (all monitored paths)\n    let stats = fs_collector.collect_all();\n    \n    // 2. Update EWMA rate estimator\n    rate_estimator.update(stats);\n    \n    // 3. Run PID pressure controller\n    let response = pressure_controller.update(stats, rate_estimator.estimate());\n    \n    // 4. Handle pressure response\n    match response.level {\n        Green => { /* normal operation, maybe replenish ballast */ },\n        Yellow => { /* increase scan frequency */ },\n        Orange => { /* start scanning + gentle cleanup */ },\n        Red => { /* release ballast + aggressive scan + delete */ },\n        Critical => { /* emergency: release all ballast + delete everything safe */ },\n    }\n    \n    // 5. Check special locations independently\n    for loc in special_locations.iter() {\n        if loc.needs_attention(stats) {\n            handle_special_location_pressure(loc, stats);\n        }\n    }\n    \n    // 6. Sleep for adaptive interval\n    thread::sleep(response.scan_interval);\n}\n```\n\n### Graceful Degradation Under Load\nWhen the system is already overloaded (high load average, heavy I/O wait):\n- Reduce parallelism in directory walker\n- Use ionice to lower I/O priority\n- Increase sleep between operations\n- Prefer ballast release over scanning (instant vs. slow)\n\nThe daemon must NEVER make an already-bad situation worse.\n\n### Startup Sequence\n1. Load/validate configuration\n2. Initialize platform abstraction\n3. Open/create SQLite database\n4. Open JSONL log file\n5. Discover special locations\n6. Verify/provision ballast files\n7. Initial pressure check (are we already in trouble?)\n8. Enter main loop\n\n### Shutdown Sequence (on SIGTERM/SIGINT)\n1. Stop accepting new scan requests\n2. Complete in-progress deletions (bounded timeout: 30s)\n3. Flush logger buffers\n4. Close SQLite connection\n5. Log shutdown event\n6. Exit 0\n\n## Design Rationale\nThe tiered scanning approach is essential because not all locations are equally critical. RAM-backed locations (tmpfs) need near-real-time monitoring because they can fill up in seconds during a cargo build. Disk-backed locations can be checked less frequently. The adaptive frequency ensures sbh responds quickly to pressure without wasting resources during calm periods.\n\nUsing threads with crossbeam channels instead of async/tokio follows the asupersync project's no-tokio philosophy and keeps the daemon simple, predictable, and debuggable. The daemon is fundamentally a polling-based system, not a network server, so async isn't needed.\n\n## Acceptance Criteria\n- Daemon starts up correctly and enters monitoring loop\n- Tiered scanning respects configured intervals\n- Adaptive frequency responds to pressure changes\n- Special locations monitored independently and more frequently\n- All events logged to both SQLite and JSONL\n- Graceful shutdown on SIGTERM/SIGINT\n- Startup detects and handles \"already in trouble\" scenarios\n- Thread communication via channels is reliable\n- Integration test: simulate full lifecycle (start → pressure → cleanup → stop)","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:50:47.398076489Z","created_by":"ubuntu","updated_at":"2026-02-14T20:19:18.616968954Z","closed_at":"2026-02-14T20:19:18.616881681Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["daemon"],"dependencies":[{"issue_id":"bd-48o","depends_on_id":"bd-1gm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-48o","depends_on_id":"bd-1hh","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-48o","depends_on_id":"bd-1td","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-48o","depends_on_id":"bd-224","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-48o","depends_on_id":"bd-2s9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-48o","depends_on_id":"bd-3po","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":338,"issue_id":"bd-48o","author":"Dicklesworthstone","text":"REVIEW: Three critical design details added:\n\n1. BOUNDED CHANNELS & BACKPRESSURE: All crossbeam channels must be bounded to prevent unbounded memory growth under load:\n  - Monitor → Scanner channel: bounded(16) — if scanner falls behind, monitor drops old pressure events (latest-wins)\n  - Scanner → Executor channel: bounded(64) — if executor is slow, scanner blocks (natural backpressure). This prevents scoring thousands of candidates that will never be executed.\n  - All → Logger channel: bounded(1024) — generous buffer since logging is fast. If buffer fills, events are dropped with a stderr warning (never block the monitoring loop for logging).\n\n2. THREAD PANIC RECOVERY: If any worker thread panics, the main monitoring thread must detect it and restart it:\n  - Store JoinHandle for each thread\n  - Check thread health every 10 seconds (is_finished())\n  - If a thread has exited unexpectedly, log the error and respawn it\n  - If the SAME thread panics 3 times in 5 minutes, stop respawning and escalate to error reporting\n  - The monitoring thread itself is the \"last line of defense\" — if it panics, systemd's WatchdogSec will restart the process\n\n3. EXECUTOR SLOWER THAN SCANNER: When the executor is slower than the scanner (e.g., deleting large directory trees while new candidates arrive), the bounded channel (64 slots) provides natural backpressure. The scanner blocks on send(), which slows down scanning. This is CORRECT behavior — there's no point discovering more candidates if we can't delete them fast enough. Under extreme pressure, the executor should prioritize the highest-scoring candidates first (the channel should be a priority queue or the executor should sort its batch before processing).","created_at":"2026-02-14T17:13:07Z"},{"id":339,"issue_id":"bd-48o","author":"Dicklesworthstone","text":"REVIEW: After removing bd-112 and bd-2up as hard dependencies, the main loop should accept these as optional integrations wired in at startup: (1) Option<NotificationSender> — if notification system (bd-112) is compiled in and configured, send pressure transition events. If None, notifications are simply skipped. (2) Option<PredictiveActionPolicy> — if predictive pipeline (bd-2up) is available, evaluate EWMA predictions each cycle and pre-empt if confidence is high. If None, rely solely on reactive PID response. This means bd-48o can ship and work correctly WITHOUT either feature. They are layered on top, not load-bearing. The startup sequence checks config to decide whether to construct these Option<T> values.","created_at":"2026-02-14T18:53:12Z"},{"id":340,"issue_id":"bd-48o","author":"Dicklesworthstone","text":"REVIEW-2: DaemonArgs specification: The 'sbh daemon' command starts the monitoring loop. DaemonArgs struct: --foreground (default, systemd manages backgrounding), --pidfile <path> (optional, for non-systemd setups). The daemon subcommand handler calls the startup sequence defined in this bead. Scanner thread data flow: (1) Walker produces Vec<WalkEntry>. (2) Scanner thread constructs ScoringInput for each (adding pressure_urgency, is_open, now). (3) ScoringEngine.score(input) produces CandidacyScore. (4) Candidates above threshold collected into ranked Vec sorted by score desc. (5) Ranked batch sent to Executor thread via bounded channel. All scoring happens inline in the scanner thread — scoring is cheap pure computation.","created_at":"2026-02-14T19:03:28Z"}]}
{"id":"bd-4hh","title":"Clippy debt burn-down slice: dual logger and ewma test lint blockers","description":"Fix immediate clippy -D warnings blockers in src/logger/dual.rs and src/monitor/ewma.rs (needless collect in tests, unnecessary casts in Duration::from_secs loops), preserving behavior with focused rch validation.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:27:42.345825352Z","created_by":"ubuntu","updated_at":"2026-02-15T16:30:26.462039818Z","closed_at":"2026-02-15T16:30:26.462021985Z","close_reason":"Completed targeted dual/ewma clippy lint blockers with passing rch tests/check; remaining clippy failures are unrelated backlog outside this slice.","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"],"comments":[{"id":341,"issue_id":"bd-4hh","author":"Dicklesworthstone","text":"Completed narrow clippy slice in reserved files. Changes: src/logger/dual.rs replaced two needless collect+len assertions with lines().count(); src/monitor/ewma.rs changed two test loops to u64 iteration and removed unnecessary i as u64 casts in Duration::from_secs. Validation: cargo fmt --check PASS; rch exec 'cargo test --lib dual' PASS; rch exec 'cargo test --lib ewma' PASS; rch exec 'cargo check --all-targets' PASS; rch exec 'cargo clippy --all-targets -- -D warnings' still FAIL due broad unrelated repo lint backlog; targeted grep on rch clippy --lib output shows no remaining mentions of src/logger/dual.rs or src/monitor/ewma.rs.","created_at":"2026-02-15T16:30:23Z"}]}
{"id":"bd-5fe","title":"Fix I1+I9+I10+I11: Pressure system data inconsistency (EWMA/PID metric mismatch, integral wind-down, biased residual)","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T21:20:34.725308404Z","created_by":"ubuntu","updated_at":"2026-02-15T21:22:40.666758667Z","closed_at":"2026-02-15T21:22:40.666741084Z","close_reason":"All 4 issues already fixed: I1 (both use available_bytes), I9 (error not clamped), I10 (residual before rate update), I11 (discriminant.abs for deceleration)","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-5vm","title":"CI/CD pipeline with GitHub Actions","description":"## Deliverable\nGitHub Actions CI/CD pipeline for automated linting, comprehensive testing, reproducibility artifact capture, and release.\n\n## Technical Approach\n### Workflow: ci.yml\nJobs:\n1. check: cargo fmt --check + cargo clippy --all-targets -- -D warnings\n2. unit: full unit/property suite (including invariant tests)\n3. integration: full pipeline integration suite\n4. e2e: scripts/e2e_test.sh plus decision-plane e2e scenarios\n5. stress: stress/load scenarios with bounded runtime profile\n6. coverage: cargo llvm-cov thresholds with module-specific minimums\n7. provenance: emit env/manifest/repro.lock style metadata for benchmark/test runs\n\n### Logging and Artifact Contract\nEach CI stage publishes:\n- machine-readable test summary\n- detailed logs for failed cases\n- trace bundles for decision-plane failures\n- timing metrics and flaky-test diagnostics\n\n### Workflow: release.yml\nTriggered by version bump:\n1. Run full quality gate (all ci.yml stages)\n2. Build release binaries for Linux/macOS targets\n3. Create archives + SHA256 checksums\n4. Attach test/provenance summary to release artifacts\n\n## Acceptance Criteria\n- CI runs on PR and push to main\n- Unit, integration, e2e, and stress gates are enforced\n- Decision-plane logs/artifacts are retained on failures\n- Coverage and lint thresholds are enforced\n- Release jobs require successful quality gates and attach checksums/provenance","acceptance_criteria":"1. CI enforces fmt/clippy/tests/coverage gates on PR and push to main. 2. Unit/integration/e2e/stress suites execute with artifact retention for failures. 3. Decision-plane trace bundles and provenance metadata are attached to failing runs. 4. Release workflow requires passing quality gates and emits checksummed artifacts. 5. CI logging remains structured and queryable for root-cause analysis.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T16:54:52.150598426Z","created_by":"ubuntu","updated_at":"2026-02-15T01:58:23.045969744Z","closed_at":"2026-02-15T01:58:23.045902228Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["infrastructure","testing"],"dependencies":[{"issue_id":"bd-5vm","depends_on_id":"bd-21z","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-5vm","depends_on_id":"bd-2j5","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-5vm","depends_on_id":"bd-2q9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-5vm","depends_on_id":"bd-3sb","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-5vm","depends_on_id":"bd-7ls","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-5vm","depends_on_id":"bd-izu.7","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-5vm","depends_on_id":"bd-izu.8","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-7ls","title":"Comprehensive unit test suite for all modules","description":"## Deliverable\nComprehensive unit and property tests co-located with each module, with deterministic fixtures and detailed failure logging.\n\n## Scope Expansion (Plan-Space Revision)\nThe unit-test matrix must cover both baseline and advanced tracks:\n- core config/errors/platform\n- monitor (EWMA, PID, predictive policy)\n- scanner (walker, patterns, scoring, deletion)\n- ballast and release logic\n- logger and stats layers\n- decision-plane guards, scheduler, and evidence schema\n\n## Test Families\n### Core/Foundation\n- error code stability and serialization compatibility\n- config parsing/validation/override precedence\n- platform trait behavior with mocks\n\n### Monitoring and Control\n- EWMA trend/forecast correctness\n- PID hysteresis and anti-windup\n- predictive policy mode transitions\n- conformal/e-process guard behavior\n\n### Scanner and Cleanup\n- walker safety invariants (symlink/cross-device/exclusions)\n- scoring determinism + veto invariants\n- deletion safety/circuit-breaker behavior\n- incremental-index equivalence properties\n\n### Logging/Explainability\n- SQLite/JSONL dual-write consistency\n- evidence-ledger schema compatibility\n- explain rendering stability and JSON schema checks\n\n## Detailed Logging Contract\nEvery failing unit/property test logs seed, minimized fixture, invariant delta, and trace IDs when available.\n\n## Acceptance Criteria\n- deterministic and non-flaky unit/property tests\n- explicit coverage for advanced decision-plane features\n- regression fixtures for discovered edge cases\n- CI hard-fail on invariant violations\n- machine-readable failure logs suitable for replay","acceptance_criteria":"1. Every core module has deterministic unit coverage including error and boundary paths. 2. Property/invariant tests cover scoring, control logic, and safety veto semantics. 3. Golden fixtures remain stable across runs and are versioned for reproducibility. 4. Test logs include case identifiers, seed info, and failure context sufficient for replay. 5. Coverage report maps each feature bead to at least one unit/property test group.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T16:53:49.351806776Z","created_by":"ubuntu","updated_at":"2026-02-15T00:44:52.008429831Z","closed_at":"2026-02-15T00:44:52.008351444Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["testing"],"dependencies":[{"issue_id":"bd-7ls","depends_on_id":"bd-112","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-1gm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-1hh","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-1sw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-1td","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-1w9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-224","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-25g","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-2f8","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-2it","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-2m9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-2np","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-2pj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-2qa","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-2s9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-2up","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-394","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-395","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-3cj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-3po","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-3qm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-3s5","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-3uk","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-48o","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-7vl","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-g0c","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-p2u","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-sth","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-u92","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-x1k","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7ls","depends_on_id":"bd-x9z","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":342,"issue_id":"bd-7ls","author":"Dicklesworthstone","text":"REVIEW: Clarifying the role of this bead vs module-level tests:\n\nEach implementation bead (bd-x9z, bd-3po, bd-25g, etc.) MUST include its own unit tests as part of its deliverable — every bead's acceptance criteria already requires tests.\n\nThis bead (bd-7ls) serves three distinct purposes that go BEYOND individual module tests:\n\n1. CROSS-CUTTING TEST INFRASTRUCTURE: Create shared test helpers used by many modules:\n   - MockPlatform (comprehensive: configurable mount points, memory, fs stats)\n   - TestEnvironment builder (creates realistic directory trees with varied ages, sizes, patterns)\n   - create_fake_rust_target() — builds a realistic target dir with incremental/, deps/, .fingerprint/\n   - SyntheticTimeSeries — generates pressure patterns for EWMA/PID testing\n   These helpers live in a tests/common/ module and are imported by all tests.\n\n2. COVERAGE VERIFICATION: Run cargo-llvm-cov and verify coverage thresholds:\n   - Overall: > 80%\n   - Scoring engine (bd-x9z): > 90%\n   - Pattern matching (bd-1sw): > 95%\n   - PID controller (bd-3po): > 90%\n\n3. GAP-FILLING TESTS: After all modules are implemented, review coverage reports and add tests for any uncovered edge cases, especially:\n   - Cross-module interactions not caught by unit tests\n   - Error paths that require multiple components to fail simultaneously\n   - Boundary conditions at the intersections of modules","created_at":"2026-02-14T17:13:22Z"}]}
{"id":"bd-7vl","title":"Post-event config analysis and auto-tuning recommendations","description":"## Deliverable\nAfter each pressure event, automatically analyze what happened and generate actionable config recommendations. Makes PID controller tuning approachable for non-control-theory users.\n\n## The Problem\nsbh exposes PID gains (kp, ki, kd), hysteresis bands, scoring weights, ballast sizing, and threshold percentages. These are powerful but intimidating. Most users will never tune them. Suboptimal defaults for a specific machine's workload pattern make sbh either too aggressive or too passive.\n\n## The Solution\n\n### Automatic Post-Event Analysis\nAfter each pressure event (transition from Green to elevated level and back), analyze:\n1. Duration of the event\n2. Peak pressure level reached\n3. Ballast files released vs available\n4. Number of artifacts deleted, their scores, and categories\n5. Time from threshold breach to resolution\n6. PID controller integral term behavior (did it reach clamp?)\n7. EWMA prediction accuracy (did we see it coming?)\n\n### Generated Recommendations\nStored in SQLite activity_log, surfaced via CLI:\n\n**Ballast sizing:**\n- \"Ballast exhausted 8 min before pressure resolved on /data. Suggest: ballast.file_count = 15 (currently 10)\"\n- \"Ballast was never fully used — 8/10 files always available. Suggest: ballast.file_count = 6 to save 4 GB\"\n\n**PID tuning:**\n- \"PID integral reached clamp 4 times this week without resolving. Suggest: pid_ki = 0.15 (currently 0.1)\"\n- \"Response oscillated between Orange and Yellow 12 times. Suggest: hysteresis_band_pct = 3.0 (currently 2.0)\"\n\n**Scoring:**\n- \"12 artifacts were deleted during active compilation (age < 45 min). Suggest: min_file_age_minutes = 45 (currently 30)\"\n- \"95% of freed space came from RustTarget category. Other patterns rarely match — scan is efficient.\"\n\n**Threshold:**\n- \"Pressure stayed Yellow for 4+ hours without escalation. Suggest: yellow_threshold_pct = 18.0 (currently 15.0)\"\n\n### CLI Interface\n  sbh tune                    # Show current recommendations\n  sbh tune --apply            # Apply all recommendations (with confirmation)\n  sbh tune --apply --yes      # Apply without confirmation\n  sbh tune --history          # Show past recommendations and whether they were applied\n  sbh tune --json             # Machine-readable output\n\n### Implementation\n```rust\npub struct TuningEngine {\n    stats: Arc<StatsEngine>,\n    config: Config,\n}\n\npub struct Recommendation {\n    pub category: TuningCategory,    // Ballast, PID, Scoring, Threshold\n    pub config_key: String,          // e.g., \"ballast.file_count\"\n    pub current_value: String,\n    pub suggested_value: String,\n    pub rationale: String,           // Plain English explanation\n    pub confidence: f64,             // 0.0-1.0\n    pub evidence: Vec<String>,       // Supporting data points\n    pub risk: TuningRisk,            // Low, Medium, High\n}\n\npub enum TuningRisk {\n    Low,    // Safe to apply automatically\n    Medium, // Review recommended\n    High,   // Manual review required\n}\n```\n\n### Analysis Triggers\n- After each pressure event resolution (Green → Elevated → Green)\n- On weekly schedule (for long-term trend analysis)\n- On demand via sbh tune --analyze\n\n### Learning from User Feedback\nTrack which recommendations users accept/reject:\n- Accepted: reinforce similar recommendations\n- Rejected: reduce confidence for that category\n- Applied then reverted: strong negative signal\n\n## Design Rationale\nThis is the difference between \"works OK with defaults\" and \"gets better over time.\" The data exists in the SQLite activity database — this is pure analysis. Users who don't understand PID controllers get concrete, actionable suggestions. Self-improving systems feel magical.\n\n## Acceptance Criteria\n- Generates recommendations after pressure events\n- Recommendations include plain-English rationale\n- sbh tune shows current recommendations with confidence levels\n- sbh tune --apply modifies config file correctly\n- Recommendations based on actual historical data (not hypothetical)\n- Handles edge cases: no pressure events yet, insufficient data, conflicting signals\n- Risk level assigned to each recommendation\n- Unit tests: recommendation generation with synthetic event data\n- Integration test: simulate pressure event -> verify recommendation generated\n- Test: apply recommendation -> verify config updated -> verify new behavior","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T18:31:38.926752400Z","created_by":"ubuntu","updated_at":"2026-02-14T23:26:41.497060116Z","closed_at":"2026-02-14T23:26:41.496960990Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli","daemon"],"dependencies":[{"issue_id":"bd-7vl","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7vl","depends_on_id":"bd-3cj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7vl","depends_on_id":"bd-3po","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-7vl","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":343,"issue_id":"bd-7vl","author":"Dicklesworthstone","text":"REVIEW: Test coverage requirements: (1) Unit test: generate synthetic PressureEvent sequence -> verify TuningEngine produces correct recommendations for ballast sizing, PID gains, scoring weights. (2) Unit test: conflicting signals (oscillation + integral clamp) -> verify recommendation priority/risk. (3) Integration test: populate SQLite with realistic event data -> run TuningEngine -> verify recommendations match expected output. (4) Test: sbh tune --apply modifies config file atomically (write to .tmp, rename). (5) Test: insufficient data (<3 events) -> TuningEngine returns empty recommendations with 'insufficient data' message.","created_at":"2026-02-14T18:54:14Z"},{"id":344,"issue_id":"bd-7vl","author":"Dicklesworthstone","text":"MINOR: Config-write capability — sbh tune --apply needs to modify the TOML config file. Implementation: (1) Read existing config file as raw TOML string. (2) Use toml_edit crate (preserves formatting, comments) to modify specific values. (3) Write to .tmp file, then atomic rename. (4) Log each changed value with old and new values. NOTE: toml_edit must be added as a dependency in bd-1kn scaffolding. It is NOT the same as the toml crate (toml parses, toml_edit preserves structure).","created_at":"2026-02-14T18:55:13Z"}]}
{"id":"bd-dt4","title":"Clean stale dead_code scaffolding in cli_app command layer","description":"Remove stale dead_code allowances and unused command label helpers in src/cli_app.rs; keep only active command/runtime paths.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-15T22:33:05.702616431Z","created_by":"ubuntu","updated_at":"2026-02-15T22:33:54.048745671Z","closed_at":"2026-02-15T22:33:54.048724802Z","close_reason":"Superseded (cli_app reserved by MaroonMaple)","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-ezo","title":"Implement live dashboard command and status watch loop","description":"Replace dashboard stub with live-refresh implementation, reuse status rendering path, honor dashboard refresh_ms, and make status --watch functional in human mode with clear output and interval control.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T22:26:37.464998262Z","created_by":"ubuntu","updated_at":"2026-02-15T22:28:50.134874628Z","closed_at":"2026-02-15T22:28:50.134853348Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-g0c","title":"Pre-build disk space check command (sbh check)","description":"## Deliverable\nA fast (<50ms) command that checks if there is enough disk space for a build, designed for use as a pre-build gate.\n\n## Usage\n  sbh check                     # Check default paths, exit 0 if OK\n  sbh check /data               # Check specific path\n  sbh check --need 20G          # Check if 20GB available\n  sbh check --predict 60        # Check if EWMA predicts enough space for 60 min\n  sbh check && cargo build      # Pre-build gate\n  alias cb='sbh check && cargo build'  # Shell alias\n\n## Exit Codes\n  0 = OK (enough space)\n  1 = WARNING (space available but predicted to run out within --predict window)\n  2 = CRITICAL (insufficient space right now)\n\n## Output (stderr, non-blocking)\n  On success: nothing (silent)\n  On warning: \"sbh: /data has 12.3 GB free but predicted full in 45 min\"\n  On critical: \"sbh: /data has 1.2 GB free (0.8%). Run: sbh emergency /data\"\n\n## Implementation\n- Read state.json for daemon data (EWMA predictions) if available\n- Fallback: direct statvfs call if daemon not running\n- Must complete in <50ms (no scanning, no database, just fs stats + prediction check)\n- JSON output with --json flag for agent consumption\n\n## Design Rationale\nPrevents the problem entirely rather than cleaning up after. Users can integrate into their workflow with a one-line alias. Agents can use it as a pre-build check in their workflows. The <50ms latency requirement means it adds negligible overhead to build commands.\n\n## Acceptance Criteria\n- Completes in <50ms (benchmarked)\n- Correct exit codes for all scenarios\n- Works without daemon running (degraded mode, no prediction)\n- Works with daemon running (uses EWMA prediction from state.json)\n- --need flag checks absolute space requirement\n- --predict flag checks time-to-exhaustion\n- --json output for agent consumption\n- Silent on success (no stdout, no stderr)","acceptance_criteria":"1. Unit tests cover threshold math, target-free calculations, and exit-code semantics. 2. Integration tests validate coupling with fs stats, notifier, and CLI formatting layers. 3. E2E scenarios simulate low-space and healthy-space runs with --json and human outputs. 4. Command never mutates disk state and returns deterministic recommendations for fixed inputs. 5. Detailed logs include free/used snapshots, threshold comparisons, and recommended next actions.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T18:33:31.760342120Z","created_by":"ubuntu","updated_at":"2026-02-14T21:55:02.889097942Z","closed_at":"2026-02-14T21:55:02.889020908Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"],"dependencies":[{"issue_id":"bd-g0c","depends_on_id":"bd-2pj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-g0c","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":345,"issue_id":"bd-g0c","author":"Dicklesworthstone","text":"REVIEW: Removed bd-x1k (EWMA) dependency. sbh check reads daemon state from state.json (bd-2np) which already contains EWMA predictions. When daemon is not running, sbh check falls back to direct statvfs() — no EWMA needed. The check command does NOT import or run the EWMA module; it only reads pre-computed predictions from state.json. Dependencies: bd-2rq (CLI framework) + bd-2pj (fs stats for fallback mode).","created_at":"2026-02-14T18:53:30Z"},{"id":346,"issue_id":"bd-g0c","author":"Dicklesworthstone","text":"REVIEW-2: state.json format contract is defined in bd-2np. sbh check reads it opportunistically — if the file exists and is fresh (<30s old), use EWMA predictions for --predict flag; otherwise fall back to direct statvfs(). No hard dep on bd-2np needed since the read is optional with graceful fallback.","created_at":"2026-02-14T19:03:14Z"}]}
{"id":"bd-ipx","title":"Fix I30: JSON injection via rfind in integrations","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T21:22:54.705889177Z","created_by":"ubuntu","updated_at":"2026-02-15T21:26:24.688559782Z","closed_at":"2026-02-15T21:26:24.688541027Z","close_reason":"Fixed: replaced rfind with depth-tracking parser that handles strings and JSONC comments","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-izu","title":"Alien Artifact Decision Plane v1 (shadow-first, explainable, calibrated)","description":"## Background\nsbh has strong foundational beads, but advanced decision-plane capabilities (shadow rollout, calibrated uncertainty, explainability contracts, and reproducible proof artifacts) were not represented as a cohesive executable plan.\n\n## Goal\nShip a mathematically-rigorous decision plane that stays conservative by default, exposes full evidence for every action, and provides deterministic fallbacks under uncertainty and drift.\n\n## Scope\nThis epic coordinates six implementation tracks plus dedicated verification tracks:\n1. Shadow mode + progressive rollout controller\n2. Evidence ledger schema + explain surfaces\n3. Incremental Merkle scan index\n4. VOI-based scan budget scheduler\n5. Conformal/e-process guardrails for adaptive actions\n6. Proof-grade benchmark/replay/fault-injection harness\n7. Decision-plane unit/property tests\n8. Decision-plane e2e scenarios with trace logging\n\n## Constraints\n- Safe under partial failure and low-confidence prediction\n- Deterministic conservative fallback always available\n- Comprehensive unit and e2e validation with detailed logs\n- Reproducibility artifacts attached to performance and safety claims\n\n## Adoption Wedge\nobserve-only (shadow) -> canary -> controlled ramp -> default-on with kill-switch.\n\n## Budgeted Mode Requirement\nEvery adaptive component must define explicit resource caps (time/memory/work budget) and exact on-exhaustion behavior.\n\n## Success Criteria\n- No dependency cycles introduced\n- Every track has explicit fallback semantics and recovery criteria\n- Decision traces are explainable and queryable via CLI/API\n- Unit and e2e tracks cover all decision-plane features\n- Performance and safety claims have replayable evidence packs","acceptance_criteria":"1. All decision-plane tracks define deterministic fallback-safe behavior and recovery criteria. 2. Every adaptive decision is explainable via evidence ledger and trace surfaces. 3. Unit/property/e2e/stress/proof beads collectively cover all scoped decision-plane features. 4. Detailed structured logging and trace bundles are mandatory for failures and regressions. 5. No dependency cycles or unverifiable performance/safety claims remain.","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-14T18:48:13.506612829Z","created_by":"ubuntu","updated_at":"2026-02-15T01:48:18.977804533Z","closed_at":"2026-02-15T01:48:18.977699466Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["alien-artifact","alien-graveyard","decision-plane"]}
{"id":"bd-izu.1","title":"Shadow-mode policy engine with progressive delivery gates","description":"## Deliverable\\nA decision-policy engine that runs in shadow mode first (observe-only), computes the same cleanup actions as enforce mode, and logs decision deltas without deleting anything.\\n\\n## Background and Rationale\\nThe project already has predictive and scoring beads, but production-safe rollout needs an explicit policy lifecycle. Shadow-first rollout is the highest-confidence way to prevent destructive false positives while still learning from real workload behavior.\\n\\n## Adoption Wedge\\nobserve -> canary -> enforce, with immediate fallback_safe at any time.\\n\\n## Budgeted Mode\\n- Max evaluations per loop: 100 candidates\\n- Max hypothetical delete set per loop: 25\\n- Max canary deletes per hour: configurable cap\\n- On budget exhaustion: stop action planning and remain in observe mode\\n\\n## Expected-Loss Model\\nStates: useful, abandoned\\nActions: keep, delete, review\\nLoss defaults: L(delete,useful)=100, L(keep,abandoned)=30, L(review,*)=5\\nPolicy applies delete only when expected_loss_delete + guard_penalty is strictly below expected_loss_keep.\\n\\n## Calibration and Fallback Trigger\\nFallback_safe trigger when any condition holds:\\n- calibration_score below configured floor for N windows\\n- guardrail breach (delete budget, drift alarm, policy error)\\n- evidence serialization failure\\nRecovery requires M consecutive clean windows.\\n\\n## Implementation Plan\\n1. Add policy modes and mode transitions to daemon loop.\\n2. Execute scoring/planning in observe mode with side effects disabled.\\n3. Emit decision_trace events for hypothetical and actual paths.\\n4. Enforce rollout guardrails and kill-switches.\\n5. Add automatic fallback transitions and recovery gates.\\n\\n## Proof Artifacts\\n- Shadow-vs-enforce replay diff report\\n- Drift and guardrail activation report\\n- Deterministic trace corpus with fixed seeds\\n\\n## Rollback\\nSingle config/env switch forces fallback_safe and disables enforce actions.\\n\\n## Baseline Comparator\\nCurrent threshold-plus-scoring reactive execution without progressive delivery gates.\\n\\n## Acceptance Criteria\\n- Observe mode produces no filesystem mutation\\n- Guardrails cap canary impact deterministically\\n- Fallback_safe engages automatically on trigger conditions\\n- Recovery requires explicit clean-window criterion\\n- Unit tests for transition graph and guardrails\\n- E2E scenario validates shadow, canary, fallback with detailed logs","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T18:48:21.719089634Z","created_by":"ubuntu","updated_at":"2026-02-15T00:47:04.752757737Z","closed_at":"2026-02-15T00:47:04.752667117Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["alien-artifact","daemon","safety"],"dependencies":[{"issue_id":"bd-izu.1","depends_on_id":"bd-1gm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.1","depends_on_id":"bd-1hh","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.1","depends_on_id":"bd-2up","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.1","depends_on_id":"bd-48o","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.1","depends_on_id":"bd-izu","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.1","depends_on_id":"bd-izu.2","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.1","depends_on_id":"bd-x9z","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-izu.2","title":"Evidence ledger schema + explain command (galaxy-brain levels)","description":"## Deliverable\\nA unified evidence-ledger schema recording why each cleanup decision was made, with explain surfaces for operators and agents.\\n\\n## Background and Rationale\\nAdvanced policy behavior is unusable without transparent decision provenance. This bead provides machine-readable and human-readable explainability that can be audited and replayed.\\n\\n## Schema Contract\\nEach decision record must include:\\n- decision_id, trace_id, policy_mode, timestamp\\n- candidate features and factor contributions\\n- posterior estimates and expected-loss values\\n- selected action and guard outcomes\\n- calibration_score, fallback_active, fallback_reason\\n- comparator_action (for shadow/canary diffing)\\n\\n## Explain Surfaces\\n- sbh explain --id <decision_id>\\n- sbh scan --explain <path>\\n- dashboard integration with level-0 to level-3 detail\\n\\n## Galaxy-Brain Levels\\nLevel 0: concise recommendation\\nLevel 1: weighted factor table\\nLevel 2: posterior, loss, calibration values\\nLevel 3: full serialized trace payload for replay/debug\\n\\n## Budgeted Mode\\nIf evidence rendering is expensive, cap expanded explain payload generation per request; return compact mode with pointer to stored trace.\\n\\n## Fallback Trigger\\nAny ledger write/serialization failure triggers safe policy fallback and emits explicit error events.\\n\\n## Proof Artifacts\\n- Snapshot corpus for explain outputs\\n- Compatibility tests for schema evolution\\n- Replay verifier reading ledger-only traces\\n\\n## Baseline Comparator\\nCurrent ad-hoc scan explanation and log records without unified decision provenance.\\n\\n## Acceptance Criteria\\n- Every decision has a persistent evidence record\\n- Explain output deterministic for identical inputs\\n- Stats engine can aggregate on evidence fields\\n- Unit tests for schema and rendering stability\\n- E2E test covers scan/clean/explain path with verbose logs","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T18:48:29.946253205Z","created_by":"ubuntu","updated_at":"2026-02-15T00:42:26.056843967Z","closed_at":"2026-02-15T00:42:26.056775899Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["alien-artifact","cli","logger"],"dependencies":[{"issue_id":"bd-izu.2","depends_on_id":"bd-1gm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.2","depends_on_id":"bd-3cj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.2","depends_on_id":"bd-3s5","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.2","depends_on_id":"bd-izu","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.2","depends_on_id":"bd-nhm","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.2","depends_on_id":"bd-x9z","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-izu.3","title":"Incremental Merkle scan index with full-scan fallback","description":"## Deliverable\\nAn incremental scan index keyed by path and metadata hashes so repeated daemon cycles avoid full recursive scans when nothing changed.\\n\\n## Background and Rationale\\nFull recursive scanning is expected to dominate runtime cost as monitored trees grow. Incremental Merkle indexing provides an asymptotic and practical latency reduction while preserving deterministic behavior via reference fallback.\\n\\n## Adoption Wedge\\n- Phase A: index build + shadow comparison only\\n- Phase B: canary incremental reads on subset of paths\\n- Phase C: full incremental default with periodic full-scan verification\\n\\n## Budgeted Mode\\n- Max subtree hash updates per loop\\n- Max checkpoint write bytes per interval\\n- On budget exhaustion: partial updates deferred and full scan used for affected roots\\n\\n## Isomorphism Proof Plan\\nFor the same filesystem snapshot, incremental and full scan must yield identical candidate set/order.\\n- Candidate-set equality checks\\n- Stable ordering checks\\n- Mismatch auto-fallback and trace emission\\n\\n## Safety and Fallback\\nAny index checksum mismatch, corruption, or replay inconsistency forces immediate full-scan mode and marks index unhealthy until rebuilt.\\n\\n## Proof Artifacts\\n- Replay fixtures for churn/no-churn workloads\\n- p50/p95/p99 scan latency report before/after\\n- mismatch incident traces with root-cause fields\\n\\n## Baseline Comparator\\nCurrent full recursive walk on each scan cycle.\\n\\n## Acceptance Criteria\\n- Incremental and full paths are behaviorally isomorphic\\n- Automatic fallback works for all detected integrity failures\\n- Demonstrable low-churn speedup without safety regression\\n- Unit tests for Merkle updates/checkpoint recovery\\n- E2E tests for healthy/degraded/index-rebuild scenarios","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T18:48:36.299300341Z","created_by":"ubuntu","updated_at":"2026-02-14T23:40:23.865001004Z","closed_at":"2026-02-14T23:40:23.864978842Z","close_reason":"Implemented incremental Merkle scan index with full-scan fallback: 20 unit tests, SHA-256 metadata hashing, checkpoint persistence with integrity verification, budget-aware diff, automatic corruption detection","source_repo":".","compaction_level":0,"original_size":0,"labels":["alien-graveyard","performance","scanner"],"dependencies":[{"issue_id":"bd-izu.3","depends_on_id":"bd-1w9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.3","depends_on_id":"bd-3qw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.3","depends_on_id":"bd-48o","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.3","depends_on_id":"bd-izu","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-izu.4","title":"Value-of-Information scheduler for scan budget allocation","description":"## Deliverable\\nA Value-of-Information scheduler that allocates scan budget to paths with highest expected reclaimed-bytes-per-IO while maintaining safety and exploration guarantees.\\n\\n## Background and Rationale\\nFixed-frequency scanning wastes cycles under pressure and large tree counts. VOI scheduling prioritizes high-yield scan targets while preserving deterministic safety behavior.\\n\\n## Utility Model\\nutility(path) = expected_reclaim_bytes - io_cost_penalty - false_positive_risk_penalty\\nwith explicit uncertainty discount and exploration bonus for under-sampled paths.\\n\\n## Budgeted Mode\\n- Fixed scan budget per interval\\n- Per-path minimum exploration quota\\n- On budget exhaustion: deterministic round-robin fallback for remaining paths\\n\\n## Expected-Loss Framing\\nStates: high-yield, low-yield, risky\\nActions: scan_now, defer, fallback_scan\\nLoss discourages starvation and risky over-scanning.\\n\\n## Calibration and Fallback\\nIf forecast-error exceeds threshold across N windows, disable VOI prioritization and revert to baseline tiered scheduler until recalibrated.\\n\\n## Proof Artifacts\\n- Forecast vs realized utility report\\n- reclaim-per-IO comparison against fixed-tier baseline\\n- starvation guard audit for low-activity paths\\n\\n## Baseline Comparator\\nCurrent tiered fixed-interval scan scheduling.\\n\\n## Acceptance Criteria\\n- Higher reclaim-per-IO than baseline in benchmark scenarios\\n- No path starvation under exploration constraints\\n- Deterministic fallback path tested and documented\\n- Unit tests for ranking, quotas, and forecast error handling\\n- E2E mixed-workload scenario with full scheduler telemetry","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T18:48:44.768366852Z","created_by":"ubuntu","updated_at":"2026-02-14T23:56:04.375601382Z","closed_at":"2026-02-14T23:56:04.375580853Z","close_reason":"Implemented VOI scheduler: utility model (reclaim/IO/FP-risk/exploration), budgeted mode with exploration quotas, calibration with automatic round-robin fallback, 14 unit tests","source_repo":".","compaction_level":0,"original_size":0,"labels":["alien-artifact","monitoring","scheduler"],"dependencies":[{"issue_id":"bd-izu.4","depends_on_id":"bd-2up","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.4","depends_on_id":"bd-48o","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.4","depends_on_id":"bd-izu","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.4","depends_on_id":"bd-izu.3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.4","depends_on_id":"bd-x9z","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-izu.5","title":"Conformal and e-process guardrails for adaptive controller actions","description":"## Deliverable\\nA statistical guard layer for predictive and PID-driven adaptive decisions using conformal-style calibration checks plus anytime-valid e-process alarms.\\n\\n## Background and Rationale\\nAdaptive controllers can become overconfident under distribution shift. This bead provides explicit finite-sample guardrails so high-impact actions are blocked when confidence is not justified.\\n\\n## Guard Contract\\n- Compute rolling calibration diagnostics for forecast quality\\n- Maintain e-process statistic for drift/overconfidence detection\\n- Gate aggressive cleanup and emergency escalation on guard pass\\n- Trigger fallback-safe policy on guard fail\\n\\n## Budgeted Mode\\n- Bounded historical window for guard computation\\n- Bounded per-loop statistic updates\\n- On compute budget exhaustion: mark guard unknown and force conservative fallback\\n\\n## Expected-Loss and Safety\\nExpected-loss controller output is considered valid only when guard status is PASS.\\nStates: calibrated, uncalibrated\\nActions: adaptive_allowed, adaptive_blocked\\nLoss strongly penalizes adaptive actions under uncalibrated state.\\n\\n## Recovery Policy\\nRequire M consecutive clean windows plus low e-process evidence before re-enabling adaptive mode.\\n\\n## Proof Artifacts\\n- Synthetic drift injections with trigger timestamps\\n- False-alarm and miss-rate tradeoff report\\n- Replay traces showing guard-driven action suppression\\n\\n## Baseline Comparator\\nCurrent controller behavior without formal calibration gate.\\n\\n## Acceptance Criteria\\n- Guard catches induced drift and overconfidence cases\\n- High-impact actions blocked when guard != PASS\\n- Recovery flow requires explicit clean-window criterion\\n- Unit tests for sequential guard math and thresholds\\n- E2E drift scenario validates fallback activation with detailed logs","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T18:48:53.315900870Z","created_by":"ubuntu","updated_at":"2026-02-15T00:33:12.424765560Z","closed_at":"2026-02-15T00:33:12.424694608Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["alien-graveyard","monitoring","safety"],"dependencies":[{"issue_id":"bd-izu.5","depends_on_id":"bd-2up","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.5","depends_on_id":"bd-3po","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.5","depends_on_id":"bd-izu","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.5","depends_on_id":"bd-x1k","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-izu.6","title":"Decision-plane proof harness: replay, fault-injection, and reproducibility pack","description":"## Deliverable\\nA proof harness validating decision-plane behavior with deterministic replay, fault-injection, and reproducibility artifacts suitable for CI and local triage.\\n\\n## Background and Rationale\\nAdvanced policy work must ship with evidence, not anecdotes. This harness is the contract that turns optimization/safety claims into reproducible proof artifacts.\\n\\n## Scope\\n1. Deterministic replay engine for decision traces and mode transitions\\n2. Fault-injection suite (IO errors, stale stats, lock contention, delayed telemetry, serializer failures)\\n3. Reproducibility pack emission: env.json, manifest.json, repro.lock, trace bundle\\n4. Statistical benchmark report: p50/p95/p99 with baseline comparator and variance context\\n\\n## Budgeted Mode\\nTest harness supports fast and full modes:\\n- Fast mode: reduced scenario set for pre-commit\\n- Full mode: complete matrix for CI/nightly\\n\\n## Fallback Validation\\nEvery fault scenario must assert expected fallback behavior and explicit reason codes.\\n\\n## Proof Artifacts\\n- Replay report with pass/fail by invariant\\n- Fault matrix with expected vs observed fallback action\\n- Benchmark delta report against baseline\\n\\n## Baseline Comparator\\nCurrent ad-hoc tests without formal replay/fault/provenance packaging.\\n\\n## Acceptance Criteria\\n- Replay outcomes deterministic across repeated runs\\n- Fault matrix validates all fallback invariants\\n- Repro packs generated and consumable by tooling\\n- Unit tests validate parser/invariant checks\\n- E2E workflow integrates into CI with verbose logging outputs","acceptance_criteria":"1. Proof harness reproduces decision outcomes from evidence traces across runs. 2. Fault-injection suite validates conservative fallback on serialization/index/guard failures. 3. Benchmark and replay artifacts include manifest + seed + environment provenance. 4. Harness emits machine-readable verdicts and differential reports for regression detection. 5. Logging captures full proof chain from input trace through policy decision assertions.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T18:48:59.044222337Z","created_by":"ubuntu","updated_at":"2026-02-15T01:11:55.110735548Z","closed_at":"2026-02-15T01:11:55.110632946Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["alien-graveyard","infrastructure","testing"],"dependencies":[{"issue_id":"bd-izu.6","depends_on_id":"bd-21z","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.6","depends_on_id":"bd-7ls","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.6","depends_on_id":"bd-izu","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.6","depends_on_id":"bd-izu.1","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.6","depends_on_id":"bd-izu.2","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.6","depends_on_id":"bd-izu.3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.6","depends_on_id":"bd-izu.4","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.6","depends_on_id":"bd-izu.5","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-izu.7","title":"Decision-plane e2e scenario pack with verbose trace logging","description":"## Deliverable\nEnd-to-end scenario pack for shadow, canary, enforce, and fallback behavior under realistic pressure and failure modes.\n\n## Scenario Matrix\n1. Burst growth with safe shadow recommendations\n2. Canary pass with bounded impact and trace capture\n3. Calibration drift causing guard fail and fallback\n4. Index corruption causing full-scan fallback\n5. Injected IO/serializer faults causing safe degradation\n6. Progressive recovery from fallback after clean windows\n\n## Logging Contract\nEach step emits:\n- trace_id and decision_id\n- policy mode and guard status\n- pressure before/after, bytes reclaimed, action reason\n- fallback reason code when relevant\n- scan budget and scheduler decision details\n\n## Determinism Contract\nScenario outcomes must be deterministic under fixed seeds and fixture inputs.\n\n## Artifacts\n- machine-readable run report\n- per-scenario logs\n- summary pass/fail table\n- per-scenario replay bundle references\n\n## Acceptance Criteria\n- deterministic scenario outcomes\n- asserted fallback triggers and reasons\n- integrated into CI e2e workflow\n- verbose logs sufficient for postmortem debugging\n- explicit checks for no unintended deletions in shadow mode","acceptance_criteria":"1. E2E scenarios cover observe/canary/enforce/fallback/recovery decision-plane lifecycle. 2. Scenarios include drift, budget exhaustion, evidence failures, and index fallback cases. 3. Verbose logging captures action decisions, guard statuses, and remediation triggers at each step. 4. Machine-readable outputs include trace IDs and expected-vs-actual comparisons. 5. Scenario set is deterministic under fixed seeds and reproducible in CI.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T18:49:11.597026399Z","created_by":"ubuntu","updated_at":"2026-02-15T01:47:43.086344525Z","closed_at":"2026-02-15T01:47:43.086283Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["alien-graveyard","e2e","testing"],"dependencies":[{"issue_id":"bd-izu.7","depends_on_id":"bd-2q9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.7","depends_on_id":"bd-izu","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.7","depends_on_id":"bd-izu.6","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.7","depends_on_id":"bd-izu.8","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-izu.8","title":"Decision-plane unit-test matrix with invariant/property checks","description":"## Deliverable\nComprehensive unit and property-test matrix for decision-plane math, invariants, and safe-mode transitions.\n\n## Invariant Families\n- deterministic ranking and tie-break stability\n- posterior/loss monotonicity under stronger evidence\n- guard state machine safety (no unsafe transitions)\n- Merkle incremental equivalence properties\n- fallback dominance under uncertainty/error states\n\n## Property Testing Requirements\n- randomized fixtures with reproducible seeds\n- shrink to minimal counterexample\n- include seed and reduced case in failure logs\n- capture decision trace snapshot for each failing property\n\n## Detailed Logging Contract\nEach test failure must log:\n- seed and minimized input fixture\n- expected vs actual invariant expression\n- relevant policy mode and guard state\n- trace identifiers for replay reproduction\n\n## Acceptance Criteria\n- invariant coverage across all core decision components\n- deterministic re-run reproducibility for failures\n- regression fixtures for discovered edge cases\n- CI gating on invariant/property failures\n- explicit tests for shadow/canary/fallback mode transition safety","acceptance_criteria":"1. Unit/property matrix covers all decision-plane components and invariants. 2. Determinism, calibration, and fallback contracts are validated under seeded replay fixtures. 3. Statistical guard math and scheduler/index interactions have boundary and adversarial tests. 4. Verbose traces include seed, rule IDs, posterior/guard values, and assertion provenance. 5. Failures produce replay-ready artifacts consumed by proof/e2e beads.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T18:49:11.608749397Z","created_by":"ubuntu","updated_at":"2026-02-15T00:52:14.963835038Z","closed_at":"2026-02-15T00:52:14.963770507Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["alien-artifact","testing"],"dependencies":[{"issue_id":"bd-izu.8","depends_on_id":"bd-7ls","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.8","depends_on_id":"bd-izu","type":"parent-child","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.8","depends_on_id":"bd-izu.1","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.8","depends_on_id":"bd-izu.2","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.8","depends_on_id":"bd-izu.3","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.8","depends_on_id":"bd-izu.4","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-izu.8","depends_on_id":"bd-izu.5","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-k6o","title":"Clippy micro-slice: decision_plane_tests redundant clones + default-init cleanup","description":"Reduce clippy -D warnings in src/decision_plane_tests.rs with a narrow, non-behavioral slice: remove redundant clones and simple field_reassign_with_default cases in one local test region; validate with rch.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:57:51.740270865Z","created_by":"ubuntu","updated_at":"2026-02-15T17:00:44.665158367Z","closed_at":"2026-02-15T17:00:44.665140273Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"]}
{"id":"bd-l6y","title":"Clippy micro-slice: cli_app test literals/default-init cleanup","description":"Fix remaining small clippy warnings in src/cli_app.rs test section: unreadable numeric literals and field_reassign_with_default in update_options test setup, preserving behavior.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:42:22.117720604Z","created_by":"ubuntu","updated_at":"2026-02-15T16:43:35.192284994Z","closed_at":"2026-02-15T16:43:35.192265898Z","close_reason":"Completed cli_app micro lint cleanup for test literals/default-init pattern with focused validation.","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"],"comments":[{"id":347,"issue_id":"bd-l6y","author":"Dicklesworthstone","text":"Implemented micro clippy cleanup in src/cli_app.rs tests: added numeric separators in parse_window_duration_valid_inputs cases and replaced UpdateArgs field reassignment-after-default with a struct literal using ..UpdateArgs::default(). Validation: cargo fmt --check PASS; rch exec \"cargo check --all-targets\" PASS; rch exec \"cargo test --bin sbh -- setup\" PASS; targeted clippy grep shows no hits for addressed line cluster (4899/5174+). Global clippy still fails due unrelated repository backlog.","created_at":"2026-02-15T16:43:32Z"}]}
{"id":"bd-mlm","title":"Remove unwrap panic risk in dashboard refresh anchor","description":"Replace checked_sub(...).unwrap() in cli/dashboard run loop with safe fallback and add regression test for oversized refresh durations.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-02-15T22:35:57.504159117Z","created_by":"ubuntu","updated_at":"2026-02-15T22:39:22.300785926Z","closed_at":"2026-02-15T22:39:22.300763284Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-nhm","title":"sbh scan command: manual artifact scan with scoring report","description":"## Deliverable\nCommand to manually trigger a build artifact scan, showing all candidates with their scores and classification, without deleting anything.\n\n## Technical Approach\n### Usage\n```bash\nsbh scan                     # Scan all configured paths\nsbh scan /data/projects      # Scan specific path\nsbh scan --min-score 0.5     # Only show candidates above threshold\nsbh scan --top 20            # Show top 20 candidates\nsbh scan --json              # Machine-readable output\nsbh scan --explain <path>    # Detailed scoring breakdown for specific path\n```\n\n### Output\n```\nBuild Artifact Scan Results\n  Scanned: 15,234 directories in 3.2 seconds\n  Candidates found: 47 (above threshold 0.3)\n\n  ┌─────┬──────────────────────────────────────────┬──────────┬──────────┬────────┬────────┐\n  │  #  │ Path                                     │ Size     │ Age      │ Score  │ Type   │\n  ├─────┼──────────────────────────────────────────┼──────────┼──────────┼────────┼────────┤\n  │  1  │ /tmp/cargo-target-quietwillow-mvcc       │   4.2 GB │ 6h 15m   │  0.94  │ Rust   │\n  │  2  │ /data/projects/pi/.target_opus_main      │   8.1 GB │ 4h 02m   │  0.91  │ Rust   │\n  │  3  │ /data/tmp/cargo-target                   │  12.4 GB │ 3h 45m   │  0.89  │ Rust   │\n  │  4  │ /tmp/target-ubuntu-am                    │   2.8 GB │ 8h 30m   │  0.87  │ Rust   │\n  │  ...│                                          │          │          │        │        │\n  └─────┴──────────────────────────────────────────┴──────────┴──────────┴────────┴────────┘\n\n  Total reclaimable: 142.7 GB\n  Use 'sbh clean' to delete these candidates.\n```\n\n### Explain Mode\nFor debugging scoring decisions:\n```\nsbh scan --explain /data/projects/pi/.target_opus_main\n\nScoring Breakdown for: /data/projects/pi/.target_opus_main\n  Type: Directory (8.1 GB, 14,523 files)\n  Modified: 4 hours 2 minutes ago\n  Classification: RustTarget (confidence: 0.95)\n\n  Factor        │ Weight │ Raw Value │ Weighted\n  ──────────────┼────────┼───────────┼─────────\n  Location      │  0.25  │    0.80   │   0.200\n  Name/Pattern  │  0.25  │    0.95   │   0.238\n  Age           │  0.20  │    0.90   │   0.180\n  Size          │  0.15  │    0.95   │   0.143\n  Structure     │  0.15  │    0.90   │   0.135\n  ──────────────┼────────┼──────────┼─────────\n  Base Score    │        │           │   0.895\n  Pressure ×    │        │     1.0   │\n  Final Score   │        │           │   0.895\n\n  Structural markers found: incremental/, deps/, .fingerprint/\n  No vetoes triggered.\n  Verdict: HIGH confidence deletion candidate\n```\n\n## Acceptance Criteria\n- Scans configured paths and reports all candidates\n- Scoring matches the scoring engine output exactly\n- --explain provides full factor breakdown\n- --json output includes all scoring data\n- Performance: scans /data/projects in < 10 seconds\n- Results sorted by score descending\n- No modifications to filesystem (read-only scan)\n- Unit tests for output formatting","acceptance_criteria":"1. Unit tests cover filter parsing, ranking limits, and deterministic ordering output. 2. Integration tests validate scanner + scorer + protection interactions and veto visibility. 3. E2E scripts cover dry-run style scans, min-score, top-N, explain output, and JSON contracts. 4. Output schemas remain stable and machine-parseable under empty and high-volume scan sets. 5. Detailed scan traces include candidate factors, veto reasons, and summary counters.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T16:53:01.202437634Z","created_by":"ubuntu","updated_at":"2026-02-14T21:47:22.615744673Z","closed_at":"2026-02-14T21:47:22.615657640Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"],"dependencies":[{"issue_id":"bd-nhm","depends_on_id":"bd-1w9","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-nhm","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-nhm","depends_on_id":"bd-x9z","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-p1b","title":"Clippy debt burn-down slice: logger stats numeric/cast cleanup","description":"Reduce top clippy blockers in src/logger/stats.rs (readable literals, safer casts, arithmetic style) with behavior-preserving changes and rch validation.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:22:14.616844350Z","created_by":"ubuntu","updated_at":"2026-02-15T16:24:16.646299722Z","closed_at":"2026-02-15T16:24:16.646272551Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"],"comments":[{"id":348,"issue_id":"bd-p1b","author":"Dicklesworthstone","text":"Completed logger stats clippy slice in src/logger/stats.rs with behavior-preserving fixture cleanup: removed risky casts by using explicit typed tuples, replaced index-based casts in loops, and fixed unreadable duration literals (259_200, 604_800). Validation: rch exec \"cargo test --lib stats\" PASS; rch exec \"cargo check --all-targets\" PASS; cargo fmt --check PASS; rch exec \"cargo clippy --all-targets -- -D warnings\" still fails with broader backlog, now reporting 68 lib-test errors in final summary plus non-lib/example/test issues.","created_at":"2026-02-15T16:24:11Z"}]}
{"id":"bd-p2u","title":"sbh stats command: activity statistics with time-window aggregation","description":"## Deliverable\nCommand that queries the activity database and displays comprehensive statistics about sbh's recent behavior across multiple time windows.\n\n## Technical Approach\n### Usage\n```bash\nsbh stats                    # Full summary across all windows\nsbh stats --window 1h        # Stats for specific window\nsbh stats --top-patterns 10  # Top 10 most-deleted patterns\nsbh stats --top-deletions 5  # 5 largest individual deletions\nsbh stats --pressure-history # Pressure level history\nsbh stats --json             # Machine-readable output\n```\n\n### Output\nUses the StatsEngine from the statistics query engine bead. Formats the WindowStats data into colored tables for terminal or JSON for agents.\n\n### Additional Views\n- **Pressure timeline**: ASCII chart showing pressure level over time\n- **Deletion heatmap**: Which hours of day see the most deletions\n- **Pattern breakdown**: Pie-chart-like breakdown of deleted patterns\n\n## Acceptance Criteria\n- All time windows produce correct, verifiable statistics\n- --json output is complete and well-formed\n- Works with empty database (shows zeros, not errors)\n- Performance: < 200ms even with large databases\n- Human output is clear and scannable","acceptance_criteria":"1. Unit tests validate window aggregation, percentile math, and top-N ranking determinism. 2. Integration tests validate query engine interaction with realistic activity database volumes. 3. E2E scripts cover empty DB, normal workload, and heavy-history scenarios with JSON and human outputs. 4. Performance remains within target latency under large datasets. 5. Detailed stats logs include query window selection, aggregation counts, and fallback/empty-result reasoning.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T16:52:37.134261855Z","created_by":"ubuntu","updated_at":"2026-02-14T23:20:04.532795883Z","closed_at":"2026-02-14T23:20:04.532729178Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"],"dependencies":[{"issue_id":"bd-p2u","depends_on_id":"bd-2rq","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-p2u","depends_on_id":"bd-3cj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-r1b","title":"Clippy debt burn-down slice: integration/common test helper lint blockers","description":"Fix immediate clippy -D warnings blockers in tests/common/mod.rs and tests/integration_tests.rs (format_push_string and needless_raw_string_hashes), preserving behavior with focused rch validation.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:29:05.571196609Z","created_by":"ubuntu","updated_at":"2026-02-15T16:32:45.743979591Z","closed_at":"2026-02-15T16:32:45.743960826Z","close_reason":"Completed: integration/common test clippy blockers resolved and validated","source_repo":".","compaction_level":0,"original_size":0,"labels":["clippy","lint","quality"],"comments":[{"id":349,"issue_id":"bd-r1b","author":"Dicklesworthstone","text":"Completed non-overlap clippy slice in tests/common + integration test target.\\n\\nChanges:\\n- tests/common/mod.rs: replaced format!+push_str with writeln! to clear format_push_string.\\n- tests/integration_tests.rs: removed needless raw-string hashes; fixed redundant clone; inlined format args in asserts; replaced float assert_eq with epsilon comparisons; removed lossy casts/suboptimal flops in calibration helpers using checked u32 conversion + mul_add; switched candidate loops to u64 ranges to avoid sign-loss casts.\\n\\nValidation:\\n- rch exec \"cargo clippy --test integration_tests -- -D warnings\" ✅\\n- rch exec \"cargo check --test integration_tests\" ✅\\n- rch exec \"cargo check --all-targets\" ✅\\n- cargo fmt --check ✅\\n- rch exec \"cargo clippy --all-targets -- -D warnings\" ❌ (remaining repo-wide lint backlog outside this slice; e.g., src/scanner/merkle.rs and other files)","created_at":"2026-02-15T16:32:39Z"}]}
{"id":"bd-rmt","title":"Harden parse_meminfo unit handling","description":"Address remaining M10 parser hardening gap: validate /proc/meminfo units explicitly instead of silently treating unknown units as raw bytes; preserve robust behavior with clear tests.","status":"closed","priority":3,"issue_type":"bug","created_at":"2026-02-15T22:19:09.526676809Z","created_by":"ubuntu","updated_at":"2026-02-15T22:22:06.350989229Z","closed_at":"2026-02-15T22:22:06.350971356Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-sth","title":"Platform abstraction layer (PAL) for Linux/macOS/Windows","description":"## Deliverable\nCross-platform abstraction traits that encapsulate OS-specific operations.\n\n## Technical Approach\n### Core PAL Trait\n```rust\npub trait Platform: Send + Sync {\n    /// Get filesystem statistics for a path (free space, total space, filesystem type)\n    fn fs_stats(&self, path: &Path) -> Result<FsStats, SbhError>;\n    \n    /// List all mount points with their filesystem types\n    fn mount_points(&self) -> Result<Vec<MountPoint>, SbhError>;\n    \n    /// Check if a path is on a RAM-backed filesystem (tmpfs, devshm, ramfs)\n    fn is_ram_backed(&self, path: &Path) -> Result<bool, SbhError>;\n    \n    /// Get the platform-specific service management interface\n    fn service_manager(&self) -> Box<dyn ServiceManager>;\n    \n    /// Get the platform-specific default paths\n    fn default_paths(&self) -> PlatformPaths;\n    \n    /// Get current system memory info (total, available, used)\n    fn memory_info(&self) -> Result<MemoryInfo, SbhError>;\n}\n```\n\n### Platform Implementations\n- **LinuxPlatform**: statvfs for fs stats, /proc/mounts for mounts, /proc/meminfo for memory, systemd for service\n- **MacosPlatform**: statvfs for fs stats, getmntinfo for mounts, sysctl for memory, launchd for service\n- **WindowsPlatform**: GetDiskFreeSpaceEx, volume enumeration, GlobalMemoryStatusEx, Windows Service API\n\n### Key Types\n```rust\npub struct FsStats {\n    pub total_bytes: u64,\n    pub free_bytes: u64,\n    pub available_bytes: u64,  // available to non-root users\n    pub fs_type: String,       // \"ext4\", \"tmpfs\", \"apfs\", \"ntfs\", etc.\n    pub mount_point: PathBuf,\n    pub is_readonly: bool,\n}\n\npub struct MountPoint {\n    pub path: PathBuf,\n    pub device: String,\n    pub fs_type: String,\n    pub is_ram_backed: bool,\n}\n\npub struct MemoryInfo {\n    pub total_bytes: u64,\n    pub available_bytes: u64,\n    pub swap_total_bytes: u64,\n    pub swap_free_bytes: u64,\n}\n```\n\n### Conditional Compilation\nUse `#[cfg(target_os = \"linux\")]`, `#[cfg(target_os = \"macos\")]`, `#[cfg(target_os = \"windows\")]` with a factory function `Platform::detect() -> Box<dyn Platform>`.\n\n## Design Rationale\nFollowing asupersync's reactor pattern: abstract the OS-specific bits behind a trait so the rest of the codebase is platform-agnostic. Linux is the primary target (where agent swarms run), macOS for development, Windows for completeness. The trait-based design also enables testing with a MockPlatform.\n\n## Acceptance Criteria\n- Compiles on Linux, macOS, and Windows (may need CI matrix)\n- LinuxPlatform correctly reads /proc/mounts and statvfs\n- MockPlatform allows deterministic testing\n- All FsStats fields populated correctly\n- is_ram_backed correctly identifies tmpfs, devshm, ramfs\n- Unit tests with mock platform","acceptance_criteria":"1. PAL APIs compile and behave consistently across Linux/macOS/Windows adapters. 2. Unit tests cover error mapping, permission failures, and platform edge cases with mock adapters. 3. Integration tests validate fs/process operations used by scanner, monitor, and daemon subsystems. 4. E2E smoke scripts verify core commands run correctly on each supported platform matrix target. 5. Structured platform logs include adapter, syscall result, normalized error code, and fallback path.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:44:33.564848054Z","created_by":"ubuntu","updated_at":"2026-02-14T19:45:09.592465840Z","closed_at":"2026-02-14T19:45:09.592443658Z","close_reason":"Platform abstraction layer implemented in platform/pal.rs (385 lines): Platform trait with fs_stats/mount_points/is_ram_backed/default_paths/memory_info/service_manager, LinuxPlatform with /proc/mounts parsing and statvfs, MockPlatform for testing, FsStats/MountPoint/MemoryInfo structs, unit tests.","source_repo":".","compaction_level":0,"original_size":0,"labels":["foundation"],"dependencies":[{"issue_id":"bd-sth","depends_on_id":"bd-1kn","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-sth","depends_on_id":"bd-3uk","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":350,"issue_id":"bd-sth","author":"Dicklesworthstone","text":"ENHANCEMENT (idea-wizard): Centralize filesystem type detection and strategy selection. Currently ad-hoc across beads (bd-25g uses fs_type for fallocate, bd-1w9 has cross-device checks). Add to Platform trait:\n  fn fs_strategy(&self, path: &Path) -> FsStrategy\nWhere FsStrategy encodes:\n  - ballast_method: Fallocate | RandomData | Skip (for tmpfs/NFS)\n  - deletion_method: Standard | CowAware (btrfs/zfs may not free space immediately)\n  - scan_strategy: Full | ReadOnly | Skip (NFS mounts: read-only scanning, skip deletion, warn user)\n  - size_estimation: StatBased | DuBased (CoW filesystems lie about size via stat)\nThis prevents each bead from independently querying fs_type.","created_at":"2026-02-14T18:35:03Z"},{"id":351,"issue_id":"bd-sth","author":"Dicklesworthstone","text":"REVIEW-2: Windows support is STUB ONLY for v1. WindowsPlatform implements the trait with NotImplemented returns for service_manager(). Core fs_stats() and mount_points() work via GetDiskFreeSpaceEx / GetVolumeInformation. Full Windows support is a future release target. #[cfg(target_os = 'windows')] compiles but methods return SbhError::NotSupported except for basic fs stats.","created_at":"2026-02-14T19:03:32Z"}]}
{"id":"bd-ty7","title":"Risk-sensitive loss-ratio gating in scoring decisions","description":"Introduce a principled delete-vs-review gate in src/scanner/scoring.rs using expected-loss ratio thresholds that adapt to calibration/uncertainty. Goal: make deletion decisions more conservative under uncertainty while preserving deterministic behavior and explainability. Add focused unit tests and validate with rch.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T16:56:40.539796880Z","created_by":"ubuntu","updated_at":"2026-02-15T17:00:40.256611464Z","closed_at":"2026-02-15T17:00:40.256585606Z","close_reason":"Implemented risk-sensitive delete-vs-review loss-ratio gating in scoring engine with focused tests and validation","source_repo":".","compaction_level":0,"original_size":0,"labels":["decision","quality","scoring"]}
{"id":"bd-u92","title":"Multi-volume ballast pool coordinator","description":"## Deliverable\nSupport ballast files distributed across multiple volumes so each monitored filesystem has its own relief pool. Fixes the fundamental gap where ballast on /var can't help /data.\n\n## The Problem\nThe current design has a single ballast.location. On machines with multiple data volumes (/data, /scratch, /home), ballast on /var/lib/sbh/ballast can only relieve pressure on the root filesystem. If /data fills up, deleting ballast on /var does nothing. This breaks the ballast feature for the most common production setup.\n\n## The Solution: Per-Volume Ballast Pools\n\n### Architecture\nEach monitored filesystem gets its own ballast pool:\n- /data has ballast at /data/.sbh/ballast/\n- /scratch has ballast at /scratch/.sbh/ballast/\n- /home has ballast at /home/.sbh/ballast/\n- Root filesystem uses /var/lib/sbh/ballast/ (default)\n\n### Configuration\n```toml\n[ballast]\nauto_provision = true           # Auto-create pools on each monitored mount\nper_volume_file_count = 5       # Default files per volume\nper_volume_file_size_mb = 1024  # Default size per file\n\n# Override for specific mounts\n[ballast.overrides.\"/data\"]\nfile_count = 10\nfile_size_mb = 2048             # /data is large, bigger ballast\n\n[ballast.overrides.\"/scratch\"]\nfile_count = 3\nfile_size_mb = 512              # /scratch is small\n\n[ballast.overrides.\"/tmp\"]\nenabled = false                 # Never ballast tmpfs (defeats purpose)\n```\n\n### BallastPoolCoordinator\n```rust\npub struct BallastPoolCoordinator {\n    pools: HashMap<MountPoint, BallastPool>,\n}\n\npub struct BallastPool {\n    mount_point: PathBuf,\n    ballast_dir: PathBuf,          // e.g., /data/.sbh/ballast/\n    manager: BallastManager,       // existing manager, per-pool instance\n    fs_type: String,               // ext4, xfs, btrfs, etc.\n}\n\nimpl BallastPoolCoordinator {\n    /// Provision all pools (auto-detect from watched_paths + overrides)\n    pub fn provision_all(&mut self) -> Result<Vec<ProvisionReport>, SbhError>;\n    \n    /// Release ballast for a SPECIFIC filesystem under pressure\n    pub fn release_for_mount(&mut self, mount: &Path, count: usize) -> Result<ReleaseReport, SbhError>;\n    \n    /// Replenish a specific pool when its filesystem recovers\n    pub fn replenish_for_mount(&mut self, mount: &Path) -> Result<ProvisionReport, SbhError>;\n    \n    /// Get inventory across all pools\n    pub fn inventory(&self) -> Vec<PoolInventory>;\n    \n    /// Total releasable bytes across all pools\n    pub fn total_releasable(&self) -> u64;\n}\n```\n\n### Auto-Detection Logic\nOn startup:\n1. Enumerate all mount points from scanner.watched_paths\n2. Resolve each path to its mount point (e.g., /data/projects -> /data)\n3. Deduplicate by mount point\n4. For each unique mount: check if ballast pool exists, provision if needed\n5. Apply overrides from config\n6. Skip tmpfs/ramfs mounts (ballast on RAM defeats the purpose)\n7. Skip read-only mounts\n\n### Filesystem Type Awareness\nDifferent provisioning strategies per filesystem type:\n- ext4/xfs: use fallocate() for instant provisioning\n- btrfs/zfs: write random data (CoW prevents fallocate from reserving actual blocks)\n- tmpfs: skip entirely (warn in logs)\n- NFS: skip by default (warn: network ballast is unreliable)\n\n### Integration with Pressure Response\nWhen PID controller says ReleaseBallast for mount /data:\n1. Coordinator routes to /data's pool\n2. Releases N files from that specific pool\n3. Verifies space freed on /data (not on /var or anywhere else)\n4. If /data has no pool (e.g., not provisioned), log warning and skip to artifact scanning\n\n### sbh ballast status (enhanced)\n```\nVolume    │ Pool Location           │ Files │ Available │ Reclaimable\n/data     │ /data/.sbh/ballast      │ 10/10 │ 10        │ 20.0 GB\n/scratch  │ /scratch/.sbh/ballast   │ 3/3   │ 3         │ 1.5 GB\n/         │ /var/lib/sbh/ballast    │ 5/5   │ 5         │ 5.0 GB\n/tmp      │ (skipped: tmpfs)        │  -    │ -         │ -\nTotal:    │                         │ 18/18 │ 18        │ 26.5 GB\n```\n\n## Design Rationale\nThis is a genuine architectural gap. The single-volume ballast breaks on the most common production setup (separate data and system volumes). Agent swarms often use machines with /data on a large partition and / on a smaller root — ballast on root can't help when /data fills up. Implementation extends BallastManager from a single inventory to a HashMap<MountPoint, BallastPool> — significant but well-contained.\n\n## Acceptance Criteria\n- Each monitored filesystem gets its own ballast pool\n- Auto-detection correctly identifies mount points from watched_paths\n- Per-volume overrides work correctly\n- Filesystem type detection selects correct provisioning strategy\n- tmpfs and NFS mounts are skipped with warnings\n- Release targets the correct volume's pool\n- sbh ballast status shows per-volume inventory\n- Provisioning respects per-volume free space (don't provision if < 20% free)\n- Unit tests: pool coordination, mount point resolution, override merging\n- Integration test: two mock volumes -> provision both -> release on specific volume -> verify\n- Test: volume with no pool -> graceful fallback to artifact scanning","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T18:32:15.733168537Z","created_by":"ubuntu","updated_at":"2026-02-14T22:54:16.411247394Z","closed_at":"2026-02-14T22:54:16.411216887Z","close_reason":"Implemented BallastPoolCoordinator with per-volume pool management, auto-detection, config overrides, targeted release, and 12 comprehensive tests. All 36 ballast tests pass.","source_repo":".","compaction_level":0,"original_size":0,"labels":["ballast"],"dependencies":[{"issue_id":"bd-u92","depends_on_id":"bd-25g","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-u92","depends_on_id":"bd-2pj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":352,"issue_id":"bd-u92","author":"Dicklesworthstone","text":"MINOR: Ballast file index design — each BallastPool (per-filesystem) maintains its OWN index of ballast files (Vec<BallastFile>). The BallastPoolCoordinator holds a HashMap<PathBuf, BallastPool> keyed by mount point. There is NO global ballast file index. This keeps pools independent and avoids cross-pool coordination complexity.","created_at":"2026-02-14T18:54:44Z"}]}
{"id":"bd-vt1","title":"Set restrictive permissions on JSONL and notification log files","description":"JSONL logger and notification file writer use OpenOptions without explicit mode, inheriting default umask. Apply 0o600 on file creation for consistency with state.json and merkle checkpoint fixes.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-15T23:17:58.009179123Z","created_by":"ubuntu","updated_at":"2026-02-15T23:20:20.586997087Z","closed_at":"2026-02-15T23:20:20.586911988Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-x1k","title":"EWMA disk usage rate estimator","description":"## Deliverable\nExponentially Weighted Moving Average estimator that tracks the RATE of disk consumption, enabling predictive intervention before storage actually runs out.\n\n## Technical Approach\n### Theory (Alien Graveyard: EWMA from time-series analysis)\nEWMA smooths noisy measurements while giving more weight to recent observations:\n  EWMA_t = α × x_t + (1 - α) × EWMA_{t-1}\nwhere α ∈ (0, 1) is the smoothing factor (higher = more reactive).\n\nFor sbh, we track:\n- bytes_consumed_per_second: how fast disk is being consumed\n- time_to_exhaustion: estimated seconds until disk is full at current rate\n- acceleration: is the consumption rate itself increasing? (second derivative)\n\n### Implementation\n```rust\npub struct DiskRateEstimator {\n    alpha: f64,                     // smoothing factor (default 0.3)\n    ewma_bytes_per_sec: f64,        // smoothed consumption rate\n    ewma_acceleration: f64,         // smoothed rate of rate change\n    last_free_bytes: u64,\n    last_sample_time: Instant,\n    samples_count: u64,\n    min_samples_for_prediction: u64, // need at least N samples (default 3)\n}\n\npub struct RateEstimate {\n    pub bytes_per_second: f64,       // current smoothed rate (positive = consuming)\n    pub seconds_to_exhaustion: f64,  // predicted time until 0% free\n    pub seconds_to_threshold: f64,   // predicted time until red threshold\n    pub acceleration: f64,           // rate change (positive = accelerating)\n    pub confidence: f64,             // 0.0-1.0 based on sample count and variance\n    pub trend: Trend,\n}\n\npub enum Trend {\n    Stable,        // consumption rate is constant\n    Accelerating,  // consumption rate is increasing (agent swarm ramping up)\n    Decelerating,  // consumption rate is decreasing (builds finishing)\n    Recovering,    // disk is being freed (negative consumption rate)\n}\n```\n\n### Prediction\ntime_to_exhaustion = free_bytes / bytes_per_second (when rate > 0)\nWith acceleration correction: t = (-v + sqrt(v² + 2*a*d)) / a (quadratic model)\nwhere v = current rate, a = acceleration, d = free bytes remaining\n\n### Adaptive Alpha\nWhen disk consumption is very bursty (e.g., cargo build starts), increase alpha temporarily to be more responsive. When stable, decrease alpha for smoother estimates.\n\n### Why This Matters\nWithout rate estimation, sbh can only react AFTER thresholds are crossed. With EWMA prediction, sbh can start preparing BEFORE the threshold is crossed:\n- If time_to_exhaustion < 5 minutes → start preemptive cleanup\n- If acceleration is positive → start monitoring more frequently\n- If trend is Recovering → reduce scan frequency to save CPU\n\n## Design Rationale\nEWMA is the right tool because: (1) disk consumption is noisy (builds start/stop), (2) we need recency-biased smoothing, (3) it's O(1) memory and O(1) per update, (4) the alpha parameter lets us tune reactivity. The acceleration term (second derivative) catches the \"10 agents started compiling simultaneously\" scenario before it fills the disk.\n\n## Acceptance Criteria\n- EWMA correctly smooths noisy input sequences\n- Predictions are reasonable for linear consumption patterns\n- Quadratic prediction handles acceleration correctly\n- Confidence increases with sample count\n- Trend detection correctly identifies all four states\n- Thread-safe (the monitoring loop updates this from a single thread, but readers may be concurrent)\n- Unit tests with synthetic consumption patterns","acceptance_criteria":"1. Unit tests validate EWMA smoothing, acceleration estimates, and confidence computation across synthetic traces. 2. Integration tests verify estimator outputs feed controller thresholds without instability. 3. E2E pressure timelines validate early-warning trigger quality against known workloads. 4. Estimator remains deterministic for fixed sample streams and alpha settings. 5. Detailed estimator logs include raw samples, EWMA value, derivative estimates, confidence, and trend state.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T16:45:29.069195094Z","created_by":"ubuntu","updated_at":"2026-02-14T19:45:22.110276563Z","closed_at":"2026-02-14T19:45:22.110251165Z","close_reason":"EWMA rate estimator implemented in monitor/ewma.rs (255 lines): DiskRateEstimator with adaptive alpha, EWMA rate/acceleration/confidence, Trend classification (Stable/Accelerating/Decelerating/Recovering), quadratic projection with linear fallback, unit tests.","source_repo":".","compaction_level":0,"original_size":0,"labels":["alien-graveyard","monitoring"],"dependencies":[{"issue_id":"bd-x1k","depends_on_id":"bd-2pj","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}]}
{"id":"bd-x9z","title":"Multi-factor deterministic candidacy scoring engine","description":"The scoring engine that computes a file_deletion_candidacy_score for every discovered artifact, combining multiple independent factors into a single deterministic score with hard safety vetoes.\n\n## CRITICAL CONTRACT: Pure Computation, Zero I/O\nThe scoring engine is a PURE FUNCTION. Given identical inputs, it produces identical outputs. It NEVER performs filesystem I/O, network calls, or any side effects. All data it needs is provided by callers:\n- Path + metadata → from DirectoryWalker (bd-1w9)\n- Artifact classification → from PatternRegistry (bd-1sw)\n- pressure_multiplier → from PID controller output (bd-3po), passed in by main loop\n- Structural markers → pre-collected by walker as part of WalkEntry.structural_markers: Vec<String>\n\nThis means the walker must collect structural markers (checking for subdirs like incremental/, deps/, .fingerprint/) during traversal, and attach them to WalkEntry. The scoring engine then uses these pre-collected markers without touching the filesystem.\n\n## Scoring Formula (Alien Artifact: information-theoretic multi-factor scoring)\n\n```\ncandidacy_score = pressure_multiplier × Σ(weight_i × factor_i)\n```\n\nWith hard vetoes that force score to 0.0 regardless of other factors.\n\n## Factor Functions (each normalized to [0.0, 1.0])\n\n**f_location(path)**: Location safety factor\n```\n/tmp, /data/tmp, /dev/shm     → 0.95  (temp dirs, very safe)\n/data/projects/*/target        → 0.80  (build output, safe)\n/data/projects/*/.target*      → 0.85  (hidden build output, safe)\n/data/projects/*/.tmp_*        → 0.90  (explicitly temporary)\n~/.cache/*                     → 0.60  (caches, usually safe)\n/home/*/projects/*             → 0.40  (user projects, moderate risk)\n/home/*/Documents/*            → 0.10  (user data, high risk)\n/ system directories           → 0.00  (never touch)\n```\n\n**f_name(entry, classification)**: Name/type classification factor\n```\nclassification.combined_confidence directly (0.0-1.0)\nBoost +0.1 if name contains \"tmp\", \"temp\", \"cache\"\nBoost +0.15 if classification category is RustTarget\nPenalty -0.3 if name contains \"backup\", \"save\", \"important\"\n```\n\n**f_age(modified_time, now)**: Age sweet-spot factor (bell curve, not linear)\nNote: \"now\" is passed explicitly for determinism (never call SystemTime::now())\n```\n< 30 minutes      → 0.00  (too recent, may be in active use)\n30 min - 2 hours   → 0.20  (probably still in use)\n2 - 4 hours        → 0.70  (cooling off)\n4 - 10 hours       → 1.00  (sweet spot: old enough to be stale)\n10 - 24 hours      → 0.85  (definitely stale)\n1 - 7 days         → 0.60  (old, but user might remember it)\n7 - 30 days        → 0.40  (very old, ambiguous)\n> 30 days          → 0.25  (ancient - might be intentional)\n```\n\n**f_size(bytes)**: Size-efficiency factor (prefer deleting large items)\n```\n< 1 MB             → 0.05  (not worth the syscall overhead)\n1 - 10 MB          → 0.20\n10 - 100 MB        → 0.40\n100 MB - 1 GB      → 0.70\n1 - 10 GB          → 1.00  (maximum value - huge space recovery)\n10 - 50 GB         → 0.90  (enormous, slight extra caution)\n> 50 GB            → 0.75  (suspiciously large, extra caution)\n```\n\n**f_structure(structural_markers)**: Internal structure indicators\nUses pre-collected structural_markers from WalkEntry (NO filesystem I/O here):\n```\nContains .fingerprint/ or incremental/  → 0.95  (definitely build artifacts)\nContains deps/ + build/                 → 0.85  (very likely build artifacts)\nContains .git/                          → 0.00  (VETO: this is a repo!)\nContains Cargo.toml at root             → 0.05  (this is a project, not a target)\nContains only .d, .o, .rlib files       → 0.90  (build outputs)\n```\n\n## Weights\nDefault weights (configurable):\n```\nw_location  = 0.25\nw_name      = 0.25\nw_age       = 0.20\nw_size      = 0.15\nw_structure = 0.15\n```\n\n## Pressure Multiplier\nFrom PID controller urgency (0.0-1.0), passed in by caller:\n```\nurgency 0.0    → multiplier 1.0  (normal scoring)\nurgency 0.3    → multiplier 1.3  (slightly lower bar)\nurgency 0.5    → multiplier 1.5  (moderate pressure)\nurgency 0.8    → multiplier 2.0  (aggressive)\nurgency 1.0    → multiplier 3.0  (emergency - almost anything goes)\n```\n\n## Hard Vetoes (override score to 0.0)\nThese CANNOT be overridden even under maximum pressure:\n1. structural_markers contains \".git\" → VETO (never delete repos)\n2. Path matches system directory pattern → VETO\n3. File age < min_file_age_minutes (default 30) → VETO (age computed from passed-in \"now\")\n4. Path matches any user-configured exclusion → VETO\n5. File is currently open by a process → VETO (this is the ONE check that requires I/O — but it's done by the CALLER before invoking the scoring engine, and passed as an `is_open: bool` flag)\n\n## Implementation\n```rust\npub struct ScoringEngine {\n    weights: ScoringWeights,\n    pattern_registry: ArtifactPatternRegistry,\n    excluded_paths: Vec<PathBuf>,\n    min_file_age: Duration,\n}\n\n/// All inputs needed to score a single candidate. No I/O needed.\npub struct ScoringInput {\n    pub path: PathBuf,\n    pub size_bytes: u64,\n    pub modified_at: SystemTime,\n    pub structural_markers: Vec<String>,  // pre-collected by walker\n    pub is_open: bool,                     // pre-checked by caller\n    pub now: SystemTime,                   // explicit timestamp for determinism\n    pub pressure_urgency: f64,             // from PID controller\n}\n\npub struct CandidacyScore {\n    pub path: PathBuf,\n    pub total_score: f64,\n    pub factors: ScoreFactors,\n    pub vetoed: bool,\n    pub veto_reason: Option<String>,\n    pub classification: ArtifactClassification,\n    pub size_bytes: u64,\n    pub age: Duration,\n}\n```\n\n## Determinism\nGiven the same ScoringInput, the scoring engine MUST produce identical CandidacyScore. No randomness, no implicit time-dependency (all time-dependent computations use the passed-in `now` field). This enables testing and reproducibility.\n\n\n## Acceptance Criteria\n- Deterministic scoring and ordering for identical inputs\n- Hard vetoes always dominate computed score\n- Pressure scaling monotonic with urgency\n- Boundary-value tests for all factors\n- Pure-computation contract (no I/O in scorer)\n- Integration ranking test with realistic fixtures","acceptance_criteria":"1. Deterministic scoring: identical ScoringInput yields identical CandidacyScore and ordering. 2. Hard vetoes always override score for git/system/excluded/recent/open-file paths. 3. Pressure multiplier mapping is monotonic in urgency. 4. Factor boundary values are unit-tested. 5. Pure-function contract holds: no filesystem or network I/O inside scoring engine. 6. Explainability fields are always populated for decision traces. 7. Integration test validates realistic ranking and veto behavior.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-14T16:48:21.317243458Z","created_by":"ubuntu","updated_at":"2026-02-14T19:46:14.739828846Z","closed_at":"2026-02-14T19:46:14.739801955Z","close_reason":"Implemented in scanner/scoring.rs","source_repo":".","compaction_level":0,"original_size":0,"labels":["alien-artifact","scanner"],"dependencies":[{"issue_id":"bd-x9z","depends_on_id":"bd-1sw","type":"blocks","created_at":"2026-02-16T00:06:56Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":353,"issue_id":"bd-x9z","author":"Dicklesworthstone","text":"REVIEW: Removed dependency on bd-2pj (FsStatsCollector). The scoring engine is a PURE COMPUTATION — it takes pre-collected metadata (from walker) and a pressure_multiplier (from PID controller) as inputs. It should never call filesystem APIs directly. This was an erroneous dependency that added unnecessary critical path length. The pressure_multiplier the scoring engine needs comes from the PID controller's output, which the main loop passes in when invoking scoring.","created_at":"2026-02-14T17:11:18Z"},{"id":354,"issue_id":"bd-x9z","author":"Dicklesworthstone","text":"REVIEW-2: Removed bd-1w9 dependency. The scoring engine is pure computation with zero I/O. It takes ScoringInput struct populated by the caller. The walker PROVIDES data but the scorer does not import walker code. Data contract: walker produces WalkEntry with structural_markers, caller constructs ScoringInput adding pressure_urgency + is_open + now timestamp.","created_at":"2026-02-14T19:02:52Z"}]}
{"id":"bd-xn8","title":"Validate protected_paths glob patterns at config load time","description":"Invalid glob patterns in scanner.protected_paths are only caught when ProtectionRegistry::new() runs at daemon start. Move validation to Config::validate() so sbh config validate and other early checks catch these errors immediately.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T23:22:09.811068198Z","created_by":"ubuntu","updated_at":"2026-02-15T23:29:34.789328875Z","closed_at":"2026-02-15T23:29:34.789251390Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-xzt","title":"Massive TUI overhaul: FrankentUI-inspired SBH operator cockpit with zero feature regression","description":"Mission\nReplace the current dashboard path with a significantly more capable, operator-grade TUI inspired by /dp/frankentui showcase patterns while preserving all existing SBH safety and observability behavior.\n\nContext\n- Current implementation is split between cli_app live status rendering and a separate crossterm dashboard module, creating drift and limited UX depth.\n- SBH is safety-critical: dashboard behavior must respect daemon state-file contracts, stale-state detection, guarded fallback behavior, and no JSON live streaming for dashboard mode.\n- We need an intentional architecture (model/update/view + bounded subscriptions), not ad hoc render loops.\n\nNon-negotiables\n- Do not lose any existing dashboard/status information surface (pressure, EWMA/trend visibility, ballast inventory/counters, daemon freshness indicators).\n- Preserve existing safety semantics and read-only boundaries unless explicitly adding guarded operator actions.\n- Keep deterministic behavior, robust terminal cleanup, and strong test/e2e coverage with detailed logs.\n\n## Success Criteria\n- New TUI is the default dashboard path with feature parity plus meaningful operator upgrades from frankentui patterns.\n- Full unit/integration/e2e/perf test matrix passes and logs are actionable for failures.\n- Documentation is updated so future maintainers can evolve the cockpit without re-deriving intent from old notes.\n- Rollback controls and fallback behavior are validated before go-live signoff.","status":"in_progress","priority":0,"issue_type":"epic","created_at":"2026-02-16T03:17:15.462700587Z","created_by":"ubuntu","updated_at":"2026-02-16T04:46:43.796402635Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["dashboard","frankentui","ops","safety","tui"],"comments":[{"id":355,"issue_id":"bd-xzt","author":"Dicklesworthstone","text":"Investigation summary (for future maintainers)\n\nCurrent dashboard reality:\n- `Command::Dashboard` in `src/cli_app.rs` routes to the live status loop (`run_live_status_loop`) with a refresh floor and explicit rejection of live JSON mode.\n- A separate `src/cli/dashboard.rs` crossterm implementation exists with richer frame rendering but is not the canonical path today.\n- Data contract is anchored on `SelfMonitor::read_state()` of daemon `state.json` (with stale-state threshold) plus filesystem fallback.\n\nOverhaul intent:\n- Converge to one canonical dashboard runtime path.\n- Keep all existing safety semantics and operator-critical data surfaces.\n- Upgrade UX by borrowing high-value patterns from `/dp/frankentui` demos (overview layout, timeline, explainability, command palette, diagnostics) without importing unnecessary demo complexity.\n\nKey guardrails:\n- No feature loss.\n- No silent degradation of safety or explainability signals.\n- Verification track is mandatory before default cutover.","created_at":"2026-02-16T03:22:35Z"},{"id":361,"issue_id":"bd-xzt","author":"Dicklesworthstone","text":"Graph refinement note (post-bv diagnostics)\n\nUsed `bv --robot-triage` and `bv --robot-insights` to validate dependency health.\n\nAdjustments made:\n- Removed unnecessary track-level block edges that created an articulation bottleneck and over-serialized execution.\n- Kept sequencing control at task-level dependencies (more parallelizable while preserving correctness gates).\n- Added explicit tasks/deps for licensing+toolchain compliance, schema-shielding, scenario e2e drills, and legacy deprecation policy.\n\nCurrent graph state:\n- No dependency cycles.\n- No xzt articulation points.\n- Critical bottlenecks now reflect expected high-impact tasks, not accidental graph structure.","created_at":"2026-02-16T03:26:34Z"},{"id":362,"issue_id":"bd-xzt","author":"Dicklesworthstone","text":"Second-pass optimization sweep completed (plan-space hardening)\n\nWhat was revised:\n- Added explicit success-criteria sections to all xzt epics.\n- Added deep test beads: PTY interaction harness, deterministic replay suite, property-based invariant suite, structured artifact schema, and legacy-vs-new parity harness.\n- Added user-outcome bead: operator workflow benchmark validation feeding UX tuning.\n- Strengthened dependency graph so quality-gate and signoff tasks require these new safeguards.\n\nWhy this improves user outcomes:\n- Stronger guarantee of zero feature loss and safer rollout behavior.\n- Better failure diagnosability via standardized artifacts and trace IDs.\n- Measurable operator effectiveness improvements, not just visual upgrades.\n\nGraph health after revision:\n- `bv` cycle check: none\n- `bv` xzt articulation points: none\n- Critical bottlenecks are now meaningful implementation gates, not accidental graph structure.","created_at":"2026-02-16T03:32:21Z"},{"id":363,"issue_id":"bd-xzt","author":"Dicklesworthstone","text":"Refinement pass on 2026-02-16: tightened dependency coverage for preference and degradation paths without introducing cycles. Added explicit pathing runtime->preferences model (bd-xzt.2.10)->preference-driven UX (bd-xzt.3.11)->verification/docs/signoff. Added failure-injection gate (bd-xzt.4.14) into quality-runbook and testing-doc flow. Validation snapshot: br dep cycles=0, br lint=0, bv shows no xzt articulation points. Intentional tradeoff: fewer immediately actionable nodes in exchange for guaranteed test/logging completeness and lower risk of feature regression.","created_at":"2026-02-16T03:37:42Z"}]}
{"id":"bd-xzt.1","title":"Track A: Architecture contracts and migration strategy for FrankentUI adoption","description":"Purpose\nLock down architecture, compatibility constraints, and migration approach before writing runtime code, so we avoid rework and preserve safety-critical semantics.\n\nScope\n- Verify live dashboard/status contracts currently depended on by operators and tests.\n- Evaluate frankentui adoption options against SBH stable toolchain and maintenance goals.\n- Produce explicit acceptance criteria and failure budgets for the overhaul.\n\nWhy this matters\nA dashboard rewrite can easily regress hidden operational assumptions (refresh floor behavior, stale-state detection, fallback semantics). This track makes those assumptions explicit and testable.\n\n## Success Criteria\n- A signed-off architectural baseline exists (contracts + ADR + acceptance budgets).\n- Compliance/toolchain decisions are explicit enough to prevent accidental nightly lock-in or attribution errors.\n- Downstream runtime/screen/testing tasks can proceed without architecture ambiguity.","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-16T03:17:21.725760417Z","created_by":"ubuntu","updated_at":"2026-02-16T03:57:25.322973947Z","closed_at":"2026-02-16T03:57:25.322946797Z","close_reason":"Completed: all Track A child beads (bd-xzt.1.1, .1.2, .1.3, .1.4, .1.5, .1.6) are closed with architecture/compliance/IA/gate artifacts delivered","source_repo":".","compaction_level":0,"original_size":0,"labels":["architecture","planning","tui"],"dependencies":[{"issue_id":"bd-xzt.1","depends_on_id":"bd-xzt","type":"parent-child","created_at":"2026-02-16T03:17:21.725760417Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":356,"issue_id":"bd-xzt.1","author":"Dicklesworthstone","text":"Rationale notes\n\n`/dp/frankentui` is MIT-licensed and offers strong reusable UX patterns, but its broader stack currently carries nightly/toolchain and dependency-surface considerations. This track exists to prevent premature architectural lock-in.\n\nDo not start broad runtime coding before:\n1) baseline contracts are frozen,\n2) integration strategy ADR is approved,\n3) acceptance/perf/error budgets are explicit.\n\nSkipping this sequencing historically causes expensive rewrites and hidden operator regressions.","created_at":"2026-02-16T03:22:39Z"}]}
{"id":"bd-xzt.1.1","title":"Audit and freeze current dashboard/status behavior contracts (pre-overhaul baseline)","description":"Background\nCurrent behavior is split across `src/cli_app.rs` and `src/cli/dashboard.rs`; parity can be lost unless contracts are codified first.\n\nWork\n- Enumerate all user-visible dashboard/status semantics: refresh floor, key bindings, no-JSON live dashboard behavior, stale daemon-state handling, degraded fallback to live fs stats, ballast/counter displays.\n- Capture exact data dependencies and schema assumptions (`DaemonState`, `PressureState`, `BallastState`, `Counters`).\n- Capture terminal lifecycle invariants (raw mode, alt-screen/cleanup obligations).\n\nAcceptance criteria\n- A baseline contract checklist exists and is referenced by all implementation/testing tasks.\n- Every baseline item has a planned verification method (unit/integration/e2e/manual).\n- No ambiguous “nice to have” items remain in the contract list.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-16T03:17:50.518184539Z","created_by":"ubuntu","updated_at":"2026-02-16T03:34:19.783990052Z","closed_at":"2026-02-16T03:34:19.783971367Z","close_reason":"Completed: froze dashboard/status baseline contract in docs/dashboard-status-contract-baseline.md and linked from README/docs/testing-and-logging","source_repo":".","compaction_level":0,"original_size":0,"labels":["architecture","parity","safety","tui"],"dependencies":[{"issue_id":"bd-xzt.1.1","depends_on_id":"bd-xzt.1","type":"parent-child","created_at":"2026-02-16T03:17:50.518184539Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.1.2","title":"Triage FrankentUI showcase elements and map to SBH-safe reusable components","description":"Background\nFrankenTUI has strong demo patterns, but SBH must avoid accidental dependency/toolchain blowups and demo-only complexity.\n\nWork\n- Evaluate candidate modules/screens from `/dp/frankentui` for direct reuse vs adaptation vs re-implementation.\n- Document dependency and toolchain impact (nightly requirement, crate fan-out, feature gates, licensing obligations).\n- Produce a ranked shortlist of “must copy” UX elements (overview layout, timeline, explainability panes, command palette, async task visibility, accessibility toggles).\n\nAcceptance criteria\n- Each candidate has a clear disposition (adopt/adapt/reject) with rationale.\n- Risks and mitigations are explicit (stability, maintenance, performance, compatibility).\n- Result is actionable enough to drive an implementation ADR without re-research.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-16T03:17:57.493496583Z","created_by":"ubuntu","updated_at":"2026-02-16T03:39:37.411315718Z","closed_at":"2026-02-16T03:39:37.411292324Z","close_reason":"Completed: FrankentUI triage matrix produced at docs/frankentui-triage-matrix.md with full disposition analysis (7 MUST COPY, 4 SHOULD ADAPT, 30 REJECT), dependency/toolchain impact analysis, risk matrix, and ranked shortlist of 12 must-copy UX elements.","source_repo":".","compaction_level":0,"original_size":0,"labels":["architecture","dependencies","frankentui"],"dependencies":[{"issue_id":"bd-xzt.1.2","depends_on_id":"bd-xzt.1","type":"parent-child","created_at":"2026-02-16T03:17:57.493496583Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.1.3","title":"Choose integration strategy (vendor vs selective adaptation) and publish implementation ADR","description":"Background\nThe biggest strategic risk is choosing an integration path that blocks delivery or creates long-term maintenance debt.\n\nWork\n- Compare at least two viable strategies: (A) broader ftui runtime adoption, (B) selective component adaptation with SBH-native runtime, (C) hybrid if justified.\n- Decide feature-flag and migration boundaries, including fallback path expectations.\n- Record ownership boundaries and update impact on existing modules (`cli_app`, `cli/dashboard`, telemetry consumers).\n\nAcceptance criteria\n- One strategy is explicitly selected with rejection reasons for alternatives.\n- ADR includes implementation phases, risk controls, and rollback mechanics.\n- All downstream tasks reference this ADR as the source of architectural truth.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-16T03:18:03.772093780Z","created_by":"ubuntu","updated_at":"2026-02-16T03:47:25.627182367Z","closed_at":"2026-02-16T03:45:40.383001980Z","close_reason":"Completed: Integration strategy ADR published at docs/adr-tui-integration-strategy.md. Decision: selective adaptation. Incorporates baseline contract (bd-xzt.1.1), triage matrix (bd-xzt.1.2), and compliance plan (bd-xzt.1.6). Unblocks bd-xzt.2.1, bd-xzt.2.4, bd-xzt.1.4.","source_repo":".","compaction_level":0,"original_size":0,"labels":["adr","architecture","frankentui","tui"],"dependencies":[{"issue_id":"bd-xzt.1.3","depends_on_id":"bd-xzt.1","type":"parent-child","created_at":"2026-02-16T03:18:03.772093780Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.1.3","depends_on_id":"bd-xzt.1.1","type":"blocks","created_at":"2026-02-16T03:22:10.468125768Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.1.3","depends_on_id":"bd-xzt.1.2","type":"blocks","created_at":"2026-02-16T03:22:10.577632499Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.1.3","depends_on_id":"bd-xzt.1.6","type":"blocks","created_at":"2026-02-16T03:25:18.856235262Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":367,"issue_id":"bd-xzt.1.3","author":"Dicklesworthstone","text":"Execution start (CalmCompass): picked by bv robot triage as highest-impact actionable blocker (unblocks bd-xzt.1.4 and then bd-xzt.2.1 chain). Implementing the integration-strategy ADR now with explicit alternatives, risk controls, migration phases, and rollback mechanics.","created_at":"2026-02-16T03:45:46Z"},{"id":368,"issue_id":"bd-xzt.1.3","author":"Dicklesworthstone","text":"Implemented bd-xzt.1.3 deliverable in docs/adr-tui-integration-strategy.md: added mandatory decision invariants, integrated new preference and failure-injection tracks (bd-xzt.2.10, bd-xzt.3.11, bd-xzt.4.14), and added downstream bead mapping table for execution traceability.","created_at":"2026-02-16T03:47:25Z"}]}
{"id":"bd-xzt.1.4","title":"Design dashboard information architecture and cross-screen navigation map","description":"Background\nThe new cockpit must optimize operator decision speed under pressure, not just visual polish.\n\nWork\n- Define primary/secondary operator journeys (pressure triage, explainability drill-down, cleanup candidate review, ballast response).\n- Specify screen topology, pane priorities, and cross-screen navigation model.\n- Define when information is always-on vs drill-down (to avoid clutter and missed alerts).\n\nAcceptance criteria\n- Navigation and screen IA are concrete enough to implement without UI guesswork.\n- Every major SBH workflow is mapped to a clear screen path.\n- Layout decisions include rationale tied to operator cognition and incident response speed.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-16T03:18:09.184720878Z","created_by":"ubuntu","updated_at":"2026-02-16T03:50:36.092314762Z","closed_at":"2026-02-16T03:49:14.796645059Z","close_reason":"Completed: authored docs/dashboard-information-architecture.md with operator journeys, topology, pane priorities, and cross-screen navigation map","source_repo":".","compaction_level":0,"original_size":0,"labels":["information-architecture","tui","ux"],"dependencies":[{"issue_id":"bd-xzt.1.4","depends_on_id":"bd-xzt.1","type":"parent-child","created_at":"2026-02-16T03:18:09.184720878Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.1.4","depends_on_id":"bd-xzt.1.3","type":"blocks","created_at":"2026-02-16T03:22:10.680706088Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":369,"issue_id":"bd-xzt.1.4","author":"Dicklesworthstone","text":"Validation pass (CalmCompass):  now provides explicit primary/secondary workflows, screen topology, cross-screen navigation contract, always-on vs drill-down hierarchy, pane priorities, and downstream guardrails. This satisfies bd-xzt.1.4 acceptance criteria and unblocks bd-xzt.1.5/bd-xzt.2.5.","created_at":"2026-02-16T03:50:36Z"}]}
{"id":"bd-xzt.1.5","title":"Define non-regression acceptance gates and performance/error budgets for TUI rollout","description":"Background\nWe need objective gates to prevent “looks good” from masking regressions in safety-critical behavior.\n\nWork\n- Define parity checklist gates for legacy behavior retention.\n- Define dashboard performance targets (refresh cadence, CPU envelope, frame-time jitter tolerance, memory growth limits).\n- Define error budget and fallback rules (stale state handling, data source failure behavior, terminal cleanup guarantees).\n\nAcceptance criteria\n- Gate list is machine-verifiable where possible and linked to concrete tests.\n- Performance/error budgets are explicit numeric targets, not qualitative claims.\n- Rollout and rollback tasks consume these gates directly.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-16T03:18:15.464735578Z","created_by":"ubuntu","updated_at":"2026-02-16T03:52:11.349451908Z","closed_at":"2026-02-16T03:51:13.198260360Z","close_reason":"Completed: authored docs/tui-rollout-acceptance-gates.md with numeric parity/perf/error gates and rollout/rollback criteria","source_repo":".","compaction_level":0,"original_size":0,"labels":["acceptance","performance","quality","safety"],"dependencies":[{"issue_id":"bd-xzt.1.5","depends_on_id":"bd-xzt.1","type":"parent-child","created_at":"2026-02-16T03:18:15.464735578Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.1.5","depends_on_id":"bd-xzt.1.1","type":"blocks","created_at":"2026-02-16T03:22:10.793916992Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.1.5","depends_on_id":"bd-xzt.1.4","type":"blocks","created_at":"2026-02-16T03:22:10.906152871Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":370,"issue_id":"bd-xzt.1.5","author":"Dicklesworthstone","text":"Completed acceptance-gate specification draft: added docs/tui-acceptance-gates-and-budgets.md with hard/soft gate policy, C-01..C-18 non-regression mapping, explicit performance + error budgets, required rch command sequence, artifact schema, and release decision criteria. Also linked new doc in README Operator Docs and docs/testing-and-logging.md.","created_at":"2026-02-16T03:52:11Z"}]}
{"id":"bd-xzt.1.6","title":"Establish licensing and toolchain compliance plan for FrankentUI code reuse","description":"Background\nReusing frankentui elements requires explicit compliance decisions (MIT attribution, dependency/toolchain policy).\n\nWork\n- Define how attribution/license notices are preserved for copied/adapted code.\n- Define acceptable dependency/toolchain posture for SBH (stable-first strategy, feature gates if nightly-only code is unavoidable).\n- Document review checklist for future imports from frankentui to prevent silent policy drift.\n\nAcceptance criteria\n- Compliance plan is explicit and referenced by implementation PRs.\n- Toolchain policy prevents accidental nightly lock-in unless intentionally approved.\n- Future self can safely import additional components without legal/toolchain ambiguity.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-16T03:24:35.950746672Z","created_by":"ubuntu","updated_at":"2026-02-16T03:40:58.268854092Z","closed_at":"2026-02-16T03:40:58.268832261Z","close_reason":"Completed: compliance plan at docs/frankentui-compliance-plan.md","source_repo":".","compaction_level":0,"original_size":0,"labels":["compliance","frankentui","licensing","toolchain"],"dependencies":[{"issue_id":"bd-xzt.1.6","depends_on_id":"bd-xzt.1","type":"parent-child","created_at":"2026-02-16T03:24:35.950746672Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.2","title":"Track B: Core TUI runtime, data adapters, and command wiring","description":"Purpose\nImplement the new dashboard runtime spine (state model, update loop, subscriptions, renderer integration, data adapters) and integrate it into CLI command flow.\n\nScope\n- Stable command entrypoint and lifecycle management (raw mode, alt screen/inline behavior, cleanup).\n- Strongly typed adapters for daemon state, live fs fallback, and telemetry-backed panes.\n- Deterministic refresh scheduling and event handling compatible with SBH guardrails.\n\nWhy this matters\nWithout a robust runtime/data spine, advanced screens become brittle and difficult to test.\n\n## Success Criteria\n- Dashboard command uses one canonical runtime path with preserved flag semantics and safety behavior.\n- Runtime state transitions and async effects are deterministic, bounded, and testable.\n- Terminal lifecycle, data adapters, and schema shielding hold under degraded and failure conditions.","status":"open","priority":0,"issue_type":"epic","created_at":"2026-02-16T03:17:26.556197599Z","created_by":"ubuntu","updated_at":"2026-02-16T03:30:28.922689246Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["integration","runtime","tui"],"dependencies":[{"issue_id":"bd-xzt.2","depends_on_id":"bd-xzt","type":"parent-child","created_at":"2026-02-16T03:17:26.556197599Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":357,"issue_id":"bd-xzt.2","author":"Dicklesworthstone","text":"Implementation intent\n\nThis track should treat runtime/data boundaries as first-class API surfaces:\n- command entrypoint,\n- model/update transitions,\n- adapters for state/log data,\n- scheduler/backpressure behavior,\n- terminal lifecycle guarantees.\n\nFuture self warning:\nIf these boundaries are blurry, every screen addition will re-open core stability bugs. Keep the spine minimal, deterministic, and well-tested before layering more UI complexity.","created_at":"2026-02-16T03:22:45Z"}]}
{"id":"bd-xzt.2.1","title":"Create new TUI module scaffold and route sbh dashboard through a single canonical runtime entrypoint","description":"Background\nCurrent dashboard behavior is split; we need one canonical path before richer features.\n\nWork\n- Introduce/normalize module layout for the new runtime (model, update, view, adapters, widgets, input, telemetry hooks).\n- Wire CLI command dispatch so dashboard invocations enter the new runtime entrypoint (feature-gated if needed during migration).\n- Preserve baseline CLI argument semantics (`--refresh-ms` normalization, no live JSON dashboard mode).\n\nAcceptance criteria\n- There is exactly one canonical runtime entrypoint for dashboard mode.\n- Existing dashboard command flags continue to parse and enforce baseline constraints.\n- Legacy code path remains callable only via explicit migration controls if required.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-16T03:18:22.246041233Z","created_by":"ubuntu","updated_at":"2026-02-16T04:05:49.812192182Z","closed_at":"2026-02-16T04:05:44.383995129Z","close_reason":"Canonical dashboard runtime entrypoint + module scaffold implemented and wired; migration controls + non-regression flag semantics preserved","source_repo":".","compaction_level":0,"original_size":0,"labels":["architecture","cli","runtime","tui"],"dependencies":[{"issue_id":"bd-xzt.2.1","depends_on_id":"bd-xzt.1.3","type":"blocks","created_at":"2026-02-16T03:22:11.023709600Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.1","depends_on_id":"bd-xzt.1.5","type":"blocks","created_at":"2026-02-16T03:22:11.142251402Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.1","depends_on_id":"bd-xzt.2","type":"parent-child","created_at":"2026-02-16T03:18:22.246041233Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":371,"issue_id":"bd-xzt.2.1","author":"Dicklesworthstone","text":"Completed runtime-skeleton and canonical routing work: added  scaffold seams (), added canonical runtime entrypoint (), and rewired  dispatch in  through a single runtime selector with explicit migration controls ( and ). Preserved existing dashboard constraints ( minimum floor and live JSON rejection). Added focused tests for runtime selection and flag conflicts plus TUI module unit coverage.","created_at":"2026-02-16T04:05:44Z"},{"id":372,"issue_id":"bd-xzt.2.1","author":"Dicklesworthstone","text":"Completion details: implemented TUI scaffold seams in src/tui (adapters, input, model, render, runtime, telemetry, update, widgets), introduced canonical runtime entrypoint in src/tui/runtime.rs, and routed sbh dashboard dispatch in src/cli_app.rs through one runtime selector with explicit migration controls (--new-dashboard and --legacy-dashboard). Existing contracts were preserved: refresh floor normalization and dashboard live JSON rejection. Added tests for runtime-selection behavior and dashboard flag conflicts, and executed focused TUI unit tests under --features tui.","created_at":"2026-02-16T04:05:49Z"}]}
{"id":"bd-xzt.2.10","title":"Add dashboard user-preferences model and safe persistence boundaries","description":"## Background\nOperators repeatedly reconfigure dashboard defaults (start screen, density, hint verbosity), which adds friction during incidents. Preferences are useful only if they are deterministic, resilient to corruption, and never coupled to safety-critical code paths.\n\n## Goals\n- Introduce a versioned preferences schema for dashboard UX settings (default screen, density mode, hint/help verbosity, visual preference toggles).\n- Define deterministic merge order: compiled defaults -> persisted preferences -> explicit session/CLI overrides.\n- Ensure persistence and read failures cannot block dashboard startup, redraw, navigation, cleanup, or emergency actions.\n\n## Implementation Scope\n- Add typed preferences model with strict validation and forward-compatible unknown-field handling.\n- Add atomic persistence semantics (temp write + fsync + rename) and debounce policy for write frequency.\n- Add bounded error handling path for corrupt/missing/permission-denied preference files.\n- Emit explicit in-memory fallback mode when persistence is unavailable (read-only/degraded profile mode).\n\n## Test + Logging Requirements\n- Unit tests: schema validation, default merge precedence, corruption fallback, migration/version handling.\n- Integration tests: permission failures, partial writes, stale/corrupt preference payloads, startup recovery path.\n- E2E hooks: preference reset/reload path captured in scripted dashboard scenarios with per-case trace identifiers.\n- Logging: structured preference load/save events with reason codes (applied_default, recovered_corrupt, write_degraded, write_skipped).\n\n## Acceptance Criteria\n- Preference corruption/missing data always falls back to deterministic defaults with no panic.\n- Preference storage failures are operator-visible but non-blocking for safety-critical workflows.\n- Preference behavior is fully covered by unit + integration tests and traceable in e2e logs.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-16T03:33:59.128567336Z","created_by":"ubuntu","updated_at":"2026-02-16T05:11:11.365869996Z","closed_at":"2026-02-16T05:11:11.365787742Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["config","preferences","reliability","ux"],"dependencies":[{"issue_id":"bd-xzt.2.10","depends_on_id":"bd-xzt.2","type":"parent-child","created_at":"2026-02-16T03:33:59.128567336Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.10","depends_on_id":"bd-xzt.2.1","type":"blocks","created_at":"2026-02-16T03:35:59.147193721Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.10","depends_on_id":"bd-xzt.2.2","type":"blocks","created_at":"2026-02-16T03:35:59.262533150Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.10","depends_on_id":"bd-xzt.2.5","type":"blocks","created_at":"2026-02-16T03:35:59.382168168Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":364,"issue_id":"bd-xzt.2.10","author":"Dicklesworthstone","text":"Dependency rationale: bd-xzt.2.10 depends on bd-xzt.2.1, bd-xzt.2.2, and bd-xzt.2.5 so preference persistence is anchored to canonical runtime entrypoint, deterministic model semantics, and theme/density primitives before UX integration work begins.","created_at":"2026-02-16T03:37:42Z"}]}
{"id":"bd-xzt.2.2","title":"Implement deterministic dashboard state model and update loop (Elm-style model/update/cmd)","description":"Background\nA deterministic reducer-style state model is needed for reliability, testing, and replayability under pressure.\n\nWork\n- Define typed model state for global UI + screen-local domains.\n- Implement pure update/reducer pathways for input events, timer ticks, data refreshes, and error events.\n- Define bounded command/effect interfaces for async fetches and background work.\n\nAcceptance criteria\n- State transitions for the same input sequence are deterministic.\n- Reducer/update logic is testable without terminal rendering side effects.\n- Async effects are bounded and observable (no untracked background mutation).","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-16T03:18:33.146838873Z","created_by":"ubuntu","updated_at":"2026-02-16T04:56:26.871579314Z","closed_at":"2026-02-16T04:53:05.340017390Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["determinism","runtime","state-model"],"dependencies":[{"issue_id":"bd-xzt.2.2","depends_on_id":"bd-xzt.2","type":"parent-child","created_at":"2026-02-16T03:18:33.146838873Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.2","depends_on_id":"bd-xzt.2.1","type":"blocks","created_at":"2026-02-16T03:22:11.257712498Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":375,"issue_id":"bd-xzt.2.2","author":"Dicklesworthstone","text":"Execution update (RedPlateau): using bv robot triage, I took highest-impact bead bd-xzt.2.2 and claimed non-conflicting surface src/tui/test_harness.rs (reservation id 1878) due active conflicts on src/tui/model.rs (SilverHarbor) and src/tui/update.rs/src/tui/runtime.rs (TanBasin). Implemented deterministic replay extensions: HarnessStep scripted inputs, run_script(), command_trace(), and trace_digest() (stable SHA-256 over state/command transitions). Added tests scripted_replay_yields_stable_transition_digest and script_command_trace_exposes_effect_boundaries. Validation: cargo fmt --check passed. rch exec cargo test --lib --features tui tui::test_harness:: and rch exec cargo check --all-targets --features tui are currently blocked by unrelated concurrent compile errors in src/daemon/loop_main.rs (ScanRequest config_update field mismatch + last_predictive_warning type mismatch).","created_at":"2026-02-16T04:52:43Z"},{"id":376,"issue_id":"bd-xzt.2.2","author":"Dicklesworthstone","text":"Follow-up validation: after fixing local clippy nits in src/tui/test_harness.rs (removed unnecessary semicolon in run_script and changed capture_frame to borrow DashboardCmd), validation now passes for this slice: cargo fmt --check ✅; rch exec cargo test --lib --features tui tui::test_harness:: ✅ (24 tests); rch exec cargo check --all-targets --features tui ✅. Global clippy still reports broad pre-existing warnings in unrelated files (notably src/tui/e2e_artifact.rs, src/tui/render.rs, src/tui/widgets.rs, src/tui/theme.rs, src/tui/test_artifact.rs, src/daemon/loop_main.rs).","created_at":"2026-02-16T04:56:26Z"}]}
{"id":"bd-xzt.2.3","title":"Build typed data adapters for daemon state file, staleness checks, and live filesystem fallback","description":"Background\nDashboard reliability depends on honoring existing state-file contracts and safe degraded behavior when daemon data is stale/unavailable.\n\nWork\n- Implement adapter layer for `DaemonState` ingestion and schema-safe mapping into view models.\n- Preserve stale-state thresholds and explicit stale/unknown UI states.\n- Implement fallback data path via filesystem stats collector when daemon state cannot be trusted.\n\nAcceptance criteria\n- Adapter behavior matches baseline semantics for fresh, stale, missing, and malformed state file cases.\n- Fallback path is bounded and clearly visible to operators in the UI.\n- Adapter layer has unit tests for success/failure permutations.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-16T03:18:40.417105020Z","created_by":"ubuntu","updated_at":"2026-02-16T04:53:06.198575314Z","closed_at":"2026-02-16T04:53:06.198507968Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["adapters","safety","state-file"],"dependencies":[{"issue_id":"bd-xzt.2.3","depends_on_id":"bd-xzt.1.1","type":"blocks","created_at":"2026-02-16T03:22:11.547950996Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.3","depends_on_id":"bd-xzt.2","type":"parent-child","created_at":"2026-02-16T03:18:40.417105020Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.3","depends_on_id":"bd-xzt.2.1","type":"blocks","created_at":"2026-02-16T03:22:11.427131060Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":373,"issue_id":"bd-xzt.2.3","author":"Dicklesworthstone","text":"Started execution with typed state-file/fallback adapter validation. Added/verified stale, missing, malformed, and fallback-mount dedupe coverage in src/tui/adapters.rs. Validation: cargo fmt --check passed; rch exec \"cargo test --lib --features tui tui::adapters::\" passed (7 tests); rch exec \"cargo check --all-targets --features tui\" passed. Full clippy currently blocked by unrelated concurrent changes in src/tui/widgets.rs and src/tui/test_harness.rs.","created_at":"2026-02-16T04:37:48Z"}]}
{"id":"bd-xzt.2.4","title":"Add telemetry query adapters for timeline/explainability panes without breaking logger contracts","description":"Background\nAdvanced screens need richer event context from SQLite/JSONL, but schema and write-path safety must not regress.\n\nWork\n- Implement read adapters for activity/decision evidence needed by timeline and explainability screens.\n- Keep adapter boundaries read-only and resilient when one backend is unavailable.\n- Surface partial-data states clearly when telemetry backends degrade.\n\nAcceptance criteria\n- Timeline/explainability adapters return stable typed views from existing logger schemas.\n- No changes are required to critical logging write paths to support dashboard reads.\n- Adapter errors degrade gracefully with explicit UI indicators.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-16T03:18:46.136953786Z","created_by":"ubuntu","updated_at":"2026-02-16T04:32:33.806339932Z","closed_at":"2026-02-16T04:32:33.806257718Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["adapters","jsonl","sqlite","telemetry"],"dependencies":[{"issue_id":"bd-xzt.2.4","depends_on_id":"bd-xzt.1.3","type":"blocks","created_at":"2026-02-16T03:22:11.878450573Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.4","depends_on_id":"bd-xzt.2","type":"parent-child","created_at":"2026-02-16T03:18:46.136953786Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.4","depends_on_id":"bd-xzt.2.1","type":"blocks","created_at":"2026-02-16T03:22:11.764313025Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.2.5","title":"Implement reusable layout and theme foundation inspired by FrankentUI showcase primitives","description":"Background\nWe want the best parts of frankentui look/structure, but tuned to SBH operator readability and safety use-cases.\n\nWork\n- Define shared spacing, color, emphasis, and semantic status tokens (green/yellow/orange/red/critical).\n- Implement responsive pane composition primitives for narrow and wide terminals.\n- Include accessibility hooks (high contrast, reduced motion, no-color compatibility).\n\nAcceptance criteria\n- Screens share one consistent theming/layout vocabulary.\n- Visual hierarchy emphasizes critical pressure/safety states first.\n- Theming works in color and no-color paths without losing semantic clarity.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-16T03:18:52.408030113Z","created_by":"ubuntu","updated_at":"2026-02-16T04:44:16.783478867Z","closed_at":"2026-02-16T04:44:16.783460553Z","close_reason":"Completed","source_repo":".","compaction_level":0,"original_size":0,"labels":["accessibility","frankentui","layout","theme"],"dependencies":[{"issue_id":"bd-xzt.2.5","depends_on_id":"bd-xzt.1.2","type":"blocks","created_at":"2026-02-16T03:22:12.094796993Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.5","depends_on_id":"bd-xzt.1.4","type":"blocks","created_at":"2026-02-16T03:22:12.197781786Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.5","depends_on_id":"bd-xzt.1.6","type":"blocks","created_at":"2026-02-16T03:25:18.962547564Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.5","depends_on_id":"bd-xzt.2","type":"parent-child","created_at":"2026-02-16T03:18:52.408030113Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.5","depends_on_id":"bd-xzt.2.1","type":"blocks","created_at":"2026-02-16T03:22:11.996709195Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":374,"issue_id":"bd-xzt.2.5","author":"Dicklesworthstone","text":"Attempted to start after bv triage but encountered active reservation conflicts on src/tui/mod.rs, src/tui/render.rs, and src/tui/widgets.rs held by IndigoStream. Deferring edits on this bead to avoid overlap; execution focus moved to bd-xzt.2.3.","created_at":"2026-02-16T04:38:12Z"}]}
{"id":"bd-xzt.2.6","title":"Build global input system: keymap engine, contextual help, and command palette backbone","description":"Background\nA multi-screen cockpit requires coherent keyboard-first interaction, not ad hoc per-screen key handling.\n\nWork\n- Define global vs screen-local key handling precedence.\n- Implement command palette backbone with discoverable actions and fuzzy command routing.\n- Provide contextual help overlays and consistent quit/escape semantics.\n\nAcceptance criteria\n- Key conflicts are deterministic and documented.\n- Command palette can trigger cross-screen actions without fragile coupling.\n- Help overlay reflects real-time bindings and screen context.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-16T03:18:58.755621103Z","created_by":"ubuntu","updated_at":"2026-02-16T05:08:59.950604151Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["command-palette","input","keymap","ux"],"dependencies":[{"issue_id":"bd-xzt.2.6","depends_on_id":"bd-xzt.2","type":"parent-child","created_at":"2026-02-16T03:18:58.755621103Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.6","depends_on_id":"bd-xzt.2.2","type":"blocks","created_at":"2026-02-16T03:22:12.301075788Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.6","depends_on_id":"bd-xzt.2.5","type":"blocks","created_at":"2026-02-16T03:22:12.408665240Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.2.7","title":"Implement bounded subscriptions/timers and background refresh scheduler for dashboard data flows","description":"Background\nContinuous dashboards can leak resources or thrash CPU if refresh and async work are not governed centrally.\n\nWork\n- Implement timer/subscription model for periodic updates and event ingestion.\n- Enforce bounded in-flight work and cancellation semantics for stale refresh jobs.\n- Respect refresh-floor constraints and avoid starvation across panes/screens.\n\nAcceptance criteria\n- Refresh behavior remains stable under slow I/O and high event rates.\n- No unbounded queue growth or orphaned background tasks.\n- Scheduler behavior is observable for debugging and perf testing.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-16T03:19:03.942736431Z","created_by":"ubuntu","updated_at":"2026-02-16T05:03:03.304651928Z","closed_at":"2026-02-16T05:03:03.304571368Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["performance","refresh","runtime","scheduler"],"dependencies":[{"issue_id":"bd-xzt.2.7","depends_on_id":"bd-xzt.2","type":"parent-child","created_at":"2026-02-16T03:19:03.942736431Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.7","depends_on_id":"bd-xzt.2.2","type":"blocks","created_at":"2026-02-16T03:22:12.506211133Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.7","depends_on_id":"bd-xzt.2.3","type":"blocks","created_at":"2026-02-16T03:22:12.604302026Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.2.8","title":"Harden terminal lifecycle and failure handling (raw mode cleanup, panic safety, graceful exit)","description":"Background\nTerminal corruption on crashes is unacceptable for operator tooling.\n\nWork\n- Ensure robust enter/exit behavior for raw mode and alternate-screen or inline modes.\n- Add panic/error guards that always restore terminal state and emit actionable diagnostics.\n- Validate quit paths (q/Esc/Ctrl-C) and signal interactions for clean teardown.\n\nAcceptance criteria\n- Terminal is restored correctly after normal exit, error exit, and panic exit.\n- Failure cases are logged with enough context for debugging.\n- Reliability behavior is covered by automated tests where feasible.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-16T03:19:11.107040906Z","created_by":"ubuntu","updated_at":"2026-02-16T04:24:59.826794355Z","closed_at":"2026-02-16T04:24:59.826684820Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["reliability","safety","terminal"],"dependencies":[{"issue_id":"bd-xzt.2.8","depends_on_id":"bd-xzt.2","type":"parent-child","created_at":"2026-02-16T03:19:11.107040906Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.8","depends_on_id":"bd-xzt.2.1","type":"blocks","created_at":"2026-02-16T03:22:12.700907308Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.2.9","title":"Implement schema-shielding layer for dashboard data models (state + telemetry)","description":"Background\nDashboard crashes due to schema drift are a common operational failure mode in fast-moving systems.\n\nWork\n- Introduce translation/validation layer between raw daemon/log schemas and UI view models.\n- Handle missing/new fields gracefully with explicit UI placeholders and warnings.\n- Add versioned mapping tests to prevent accidental hard-coupling to transient schema details.\n\nAcceptance criteria\n- Minor schema evolution does not hard-fail dashboard startup/rendering.\n- Drift is surfaced transparently to operators and maintainers.\n- Mapping layer has deterministic error behavior and test coverage.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-16T03:24:42.367586592Z","created_by":"ubuntu","updated_at":"2026-02-16T05:04:04.478515504Z","closed_at":"2026-02-16T05:02:24.950043113Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["adapters","compatibility","reliability","schema"],"dependencies":[{"issue_id":"bd-xzt.2.9","depends_on_id":"bd-xzt.2","type":"parent-child","created_at":"2026-02-16T03:24:42.367586592Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.9","depends_on_id":"bd-xzt.2.3","type":"blocks","created_at":"2026-02-16T03:25:19.067106563Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.2.9","depends_on_id":"bd-xzt.2.4","type":"blocks","created_at":"2026-02-16T03:25:19.167807361Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":377,"issue_id":"bd-xzt.2.9","author":"Dicklesworthstone","text":"Execution update (RedPlateau): implemented schema-shielding hardening for state+telemetry adapters.\n\nState-side:\n- DashboardSnapshot warning propagation is covered with explicit drift tests (unknown + missing top-level keys) for both fresh and stale state-file paths.\n\nTelemetry-side:\n- JsonlTelemetryAdapter now uses a schema-shield parser fallback for legacy/variant JSONL shapes.\n- Tracks recovered vs dropped lines and surfaces diagnostics (`jsonl schema-shield recovered=<n> dropped=<n>`).\n- Sets `partial=true` when malformed lines are dropped.\n\nAdded tests:\n- `jsonl_schema_shield_recovers_legacy_alias_fields`\n- `jsonl_schema_shield_marks_partial_when_lines_are_dropped`\n\nValidation:\n- `cargo fmt` applied\n- `rch exec \"cargo test --lib --features tui tui::adapters::\"` passed (18 tests)\n- `rch exec \"cargo test --lib --features tui tui::telemetry::\"` passed (29 tests)\n- `rch exec \"cargo check --all-targets --features tui\"` passed\n","created_at":"2026-02-16T05:04:04Z"}]}
{"id":"bd-xzt.3","title":"Track C: Screen suite and operator interactions (overview, timeline, explainability, ballast, diagnostics)","description":"Purpose\nDeliver a multi-screen cockpit that copies the strongest practical ideas from /dp/frankentui demo screens while staying aligned with SBH operational workflows.\n\nScope\n- Screen set for overview, action timeline, explainability, scan candidates, ballast operations, and diagnostics.\n- Global navigation and interaction ergonomics (keyboard-first command palette + contextual help).\n- Accessibility-aware theming and responsive layouts for common terminal sizes.\n\nWhy this matters\nThe major value upgrade comes from richer operator cognition: faster triage, clearer root cause visibility, and less CLI context switching.\n\n## Success Criteria\n- Every critical operator workflow is executable in-dashboard with less friction than baseline.\n- Screen content and interactions preserve all existing critical visibility while improving decision speed.\n- Accessibility and responsive behavior are validated across supported terminal contexts.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-16T03:17:31.819961550Z","created_by":"ubuntu","updated_at":"2026-02-16T03:30:28.970570889Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["frankentui","screens","tui","ux"],"dependencies":[{"issue_id":"bd-xzt.3","depends_on_id":"bd-xzt","type":"parent-child","created_at":"2026-02-16T03:17:31.819961550Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":358,"issue_id":"bd-xzt.3","author":"Dicklesworthstone","text":"UX extraction targets from FrankentUI demos\n\nPrioritize these concrete patterns:\n- multi-panel overview hierarchy (`dashboard.rs` style composition),\n- bounded severity-filtered event stream (`action_timeline.rs`),\n- explainability-first decision drilldown (`explainability_cockpit.rs`),\n- command palette guided navigation,\n- diagnostics pane for runtime trust.\n\nAvoid demo-only complexity that does not improve incident response (ornamental effects, heavyweight optional modules with weak ops value).","created_at":"2026-02-16T03:22:53Z"}]}
{"id":"bd-xzt.3.1","title":"Implement Overview screen with full parity plus upgraded situational panels","description":"Background\nOverview is the first responder surface and must preserve all current high-signal dashboard information.\n\nWork\n- Render pressure state per mount, trend indicators, ballast inventory, and critical counters.\n- Preserve/upgrade EWMA sparkline visibility and daemon freshness indicators.\n- Add operator-focused hierarchy (critical alerts and bottlenecks surfaced before secondary stats).\n\nAcceptance criteria\n- Overview covers all baseline dashboard information with no regressions.\n- Critical conditions are visually and textually unmistakable.\n- Works in normal and degraded data modes.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-16T03:19:19.088374337Z","created_by":"ubuntu","updated_at":"2026-02-16T05:18:36.229869072Z","closed_at":"2026-02-16T05:18:36.229776769Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["overview","parity","safety","screen"],"dependencies":[{"issue_id":"bd-xzt.3.1","depends_on_id":"bd-xzt.2.2","type":"blocks","created_at":"2026-02-16T03:22:12.793556816Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.1","depends_on_id":"bd-xzt.2.3","type":"blocks","created_at":"2026-02-16T03:22:12.891009264Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.1","depends_on_id":"bd-xzt.2.5","type":"blocks","created_at":"2026-02-16T03:22:12.990159600Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.1","depends_on_id":"bd-xzt.2.7","type":"blocks","created_at":"2026-02-16T03:22:13.087948999Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.1","depends_on_id":"bd-xzt.2.9","type":"blocks","created_at":"2026-02-16T03:25:19.272700998Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.1","depends_on_id":"bd-xzt.3","type":"parent-child","created_at":"2026-02-16T03:19:19.088374337Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.3.10","title":"Run operator workflow benchmark validation (task-time, error-rate, confidence) and feed UX tuning","description":"Background\nA better-looking TUI is not enough; we need measurable operator outcomes.\n\nWork\n- Define benchmark tasks reflecting real incidents (pressure triage, explainability query, ballast diagnosis, cleanup candidate review).\n- Measure baseline vs new cockpit on completion time, error rate, and confidence.\n- Convert findings into prioritized UX tuning adjustments before final docs/signoff.\n\nAcceptance criteria\n- Benchmark results show equal or improved operator effectiveness vs baseline.\n- Regressions are captured as explicit follow-up tasks before go/no-go.\n- Findings are documented for future UX iteration cycles.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-16T03:31:24.920233504Z","created_by":"ubuntu","updated_at":"2026-02-16T03:36:00.877125115Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["benchmark","operators","ux","validation"],"dependencies":[{"issue_id":"bd-xzt.3.10","depends_on_id":"bd-xzt.3","type":"parent-child","created_at":"2026-02-16T03:31:24.920233504Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.10","depends_on_id":"bd-xzt.3.1","type":"blocks","created_at":"2026-02-16T03:31:48.734926539Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.10","depends_on_id":"bd-xzt.3.11","type":"blocks","created_at":"2026-02-16T03:36:00.877083196Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.10","depends_on_id":"bd-xzt.3.2","type":"blocks","created_at":"2026-02-16T03:31:48.851115417Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.10","depends_on_id":"bd-xzt.3.3","type":"blocks","created_at":"2026-02-16T03:31:48.960812174Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.10","depends_on_id":"bd-xzt.3.4","type":"blocks","created_at":"2026-02-16T03:31:49.080201502Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.10","depends_on_id":"bd-xzt.3.5","type":"blocks","created_at":"2026-02-16T03:31:49.189795927Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.10","depends_on_id":"bd-xzt.3.7","type":"blocks","created_at":"2026-02-16T03:31:49.292983270Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.10","depends_on_id":"bd-xzt.3.8","type":"blocks","created_at":"2026-02-16T03:31:49.400224470Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.10","depends_on_id":"bd-xzt.3.9","type":"blocks","created_at":"2026-02-16T03:31:49.506192347Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.3.11","title":"Integrate preference-driven UX controls (default screen, density, hints) into cockpit navigation","description":"## Background\nPreference plumbing is only valuable if operator workflows actually consume it. This task applies persistent preferences to real cockpit behavior while preserving high-signal incident visibility.\n\n## Goals\n- Apply persisted preferences to startup routing (default screen), panel density, and help/hint verbosity.\n- Keep navigation and command palette deterministic regardless of preference profile.\n- Provide transparent controls for reset/revert so operators can recover instantly from bad personalization.\n\n## Implementation Scope\n- Integrate preference profile into navigation bootstrap and per-screen rendering settings.\n- Expose command palette actions for set/reset/revert-to-defaults and indicate active profile mode.\n- Enforce safety visibility floor: critical pressure and veto/safety indicators remain visible in all density modes.\n- Ensure preference application is idempotent across redraw loops and reload events.\n\n## Test + Logging Requirements\n- Unit tests: reducer/state transitions for preference application and reset actions.\n- Integration tests: startup default-screen routing, profile persistence round-trip, deterministic command availability.\n- E2E scenarios: operator flow comparison with/without preferences, including reset-to-default during active session.\n- Logging: structured events for preference apply/reset actions with actor context and resulting profile hash/version.\n\n## Acceptance Criteria\n- Preference-driven UX reduces repeated setup friction without hiding critical safety data.\n- Operators can always inspect, reset, and override profile behavior in-session.\n- Preference UX paths are covered by unit/integration/e2e tests with reproducible logs.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T03:33:59.139365577Z","created_by":"ubuntu","updated_at":"2026-02-16T03:37:42.330739511Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["navigation","preferences","ux"],"dependencies":[{"issue_id":"bd-xzt.3.11","depends_on_id":"bd-xzt.2.10","type":"blocks","created_at":"2026-02-16T03:35:59.499255428Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.11","depends_on_id":"bd-xzt.3","type":"parent-child","created_at":"2026-02-16T03:33:59.139365577Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.11","depends_on_id":"bd-xzt.3.7","type":"blocks","created_at":"2026-02-16T03:35:59.608341732Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":365,"issue_id":"bd-xzt.3.11","author":"Dicklesworthstone","text":"Dependency rationale: bd-xzt.3.11 depends on bd-xzt.2.10 and bd-xzt.3.7 to guarantee preference-driven UX is layered on stable preference persistence + finalized navigation semantics. This prevents drift between profile behavior and command-palette/navigation contracts.","created_at":"2026-02-16T03:37:42Z"}]}
{"id":"bd-xzt.3.2","title":"Implement Action Timeline screen (event stream, severity filters, detail drill-down)","description":"Background\nA timeline view improves operator understanding of causality during pressure incidents.\n\nWork\n- Build bounded event stream panel with severity/component filters and follow mode.\n- Support detail pane for selected events with enough context to map to logs/explain traces.\n- Keep deterministic ordering and stable behavior under bursty event ingestion.\n\nAcceptance criteria\n- Operators can quickly isolate high-severity events without leaving the dashboard.\n- Timeline remains responsive with high event volume.\n- Event-to-detail mapping is reliable and testable.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-16T03:19:23.908997225Z","created_by":"ubuntu","updated_at":"2026-02-16T05:10:52.475123431Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["frankentui","screen","telemetry","timeline"],"dependencies":[{"issue_id":"bd-xzt.3.2","depends_on_id":"bd-xzt.2.2","type":"blocks","created_at":"2026-02-16T03:22:13.190083010Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.2","depends_on_id":"bd-xzt.2.4","type":"blocks","created_at":"2026-02-16T03:22:13.294782853Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.2","depends_on_id":"bd-xzt.2.5","type":"blocks","created_at":"2026-02-16T03:22:13.400825660Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.2","depends_on_id":"bd-xzt.2.7","type":"blocks","created_at":"2026-02-16T03:22:13.517761436Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.2","depends_on_id":"bd-xzt.2.9","type":"blocks","created_at":"2026-02-16T03:25:19.375604178Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.2","depends_on_id":"bd-xzt.3","type":"parent-child","created_at":"2026-02-16T03:19:23.908997225Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.3.3","title":"Implement Explainability cockpit for decision rationale, veto reasons, and policy state","description":"Background\nSBH decisions must be explainable; operators need in-dashboard access to rationale during incidents.\n\nWork\n- Build panes for recent decisions, factor contributions, veto reasons, and policy mode transitions.\n- Link explain data to concrete artifacts (decision IDs, timestamps, affected paths/components).\n- Surface uncertainty/drift indicators where relevant to trust assessment.\n\nAcceptance criteria\n- Operators can answer “why did this happen/not happen?” without leaving dashboard context.\n- Explainability data never implies stronger certainty than available evidence.\n- Failure/partial-data states are explicit, not silent.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-16T03:19:28.942204371Z","created_by":"ubuntu","updated_at":"2026-02-16T05:22:14.845033418Z","closed_at":"2026-02-16T05:22:14.844958899Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["explainability","policy","safety","screen"],"dependencies":[{"issue_id":"bd-xzt.3.3","depends_on_id":"bd-xzt.2.2","type":"blocks","created_at":"2026-02-16T03:22:13.618829111Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.3","depends_on_id":"bd-xzt.2.4","type":"blocks","created_at":"2026-02-16T03:22:13.739370406Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.3","depends_on_id":"bd-xzt.2.5","type":"blocks","created_at":"2026-02-16T03:22:13.860188619Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.3","depends_on_id":"bd-xzt.2.9","type":"blocks","created_at":"2026-02-16T03:25:19.486158390Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.3","depends_on_id":"bd-xzt.3","type":"parent-child","created_at":"2026-02-16T03:19:28.942204371Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.3.4","title":"Implement Scan Candidates screen with score breakdown and safety-veto visibility","description":"Background\nOperators need fast inspection of cleanup candidates and why items are included/excluded.\n\nWork\n- Display ranked candidates with factor-level score contributions and estimated reclaim size.\n- Expose safety-veto and protection reasons (marker, glob, open-file, git, permissions).\n- Support sorting/filtering for high-impact triage.\n\nAcceptance criteria\n- Candidate list is deterministic and consistent with scanner/scoring outputs.\n- Vetoed/protected paths are understandable without digging through raw logs.\n- Screen does not bypass existing deletion safety policy.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-16T03:19:34.856347872Z","created_by":"ubuntu","updated_at":"2026-02-16T05:23:39.570007721Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cleanup","scanner","scoring","screen"],"dependencies":[{"issue_id":"bd-xzt.3.4","depends_on_id":"bd-xzt.2.2","type":"blocks","created_at":"2026-02-16T03:22:13.986477122Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.4","depends_on_id":"bd-xzt.2.3","type":"blocks","created_at":"2026-02-16T03:22:14.110643281Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.4","depends_on_id":"bd-xzt.2.5","type":"blocks","created_at":"2026-02-16T03:22:14.225418553Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.4","depends_on_id":"bd-xzt.2.9","type":"blocks","created_at":"2026-02-16T03:25:19.593809467Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.4","depends_on_id":"bd-xzt.3","type":"parent-child","created_at":"2026-02-16T03:19:34.856347872Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.3.5","title":"Implement Ballast Operations screen with per-volume inventory and guarded action flow","description":"Background\nBallast release/replenish is central to incident response; operators need clear, safe visibility and actions.\n\nWork\n- Display per-volume ballast inventory, release/replenish status, and recent operations.\n- If interactive actions are enabled, require explicit confirmation and guard messaging before state-changing commands.\n- Make mount-to-ballast mapping obvious to avoid wrong-volume assumptions during incidents.\n\nAcceptance criteria\n- Ballast state in dashboard matches CLI/status outputs.\n- Action affordances (if present) are safe-by-default and auditable.\n- Screen remains useful in read-only mode when actions are disabled by policy.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T03:19:42.345038684Z","created_by":"ubuntu","updated_at":"2026-02-16T03:25:19.703037967Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["ballast","operations","safety","screen"],"dependencies":[{"issue_id":"bd-xzt.3.5","depends_on_id":"bd-xzt.2.2","type":"blocks","created_at":"2026-02-16T03:22:14.337716849Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.5","depends_on_id":"bd-xzt.2.3","type":"blocks","created_at":"2026-02-16T03:22:14.451274583Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.5","depends_on_id":"bd-xzt.2.5","type":"blocks","created_at":"2026-02-16T03:22:14.569685580Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.5","depends_on_id":"bd-xzt.2.6","type":"blocks","created_at":"2026-02-16T03:22:14.678108562Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.5","depends_on_id":"bd-xzt.2.9","type":"blocks","created_at":"2026-02-16T03:25:19.702980920Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.5","depends_on_id":"bd-xzt.3","type":"parent-child","created_at":"2026-02-16T03:19:42.345038684Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.3.6","title":"Implement Diagnostics/Performance HUD for frame health, refresh lag, and data-source state","description":"Background\nOperators and maintainers need immediate visibility into dashboard health to trust it during long-running sessions.\n\nWork\n- Add diagnostics pane for frame timing, skipped frames, refresh lag, and data adapter error counts.\n- Surface active mode details (normal/degraded/stale-data) and scheduler pressure.\n- Provide lightweight toggles for verbose diagnostics to avoid clutter in normal operation.\n\nAcceptance criteria\n- Diagnostics are useful for troubleshooting without requiring external profilers.\n- Overhead is low enough to keep normal dashboard performance within budget.\n- Metrics definitions are documented and testable.","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-02-16T03:19:47.676111504Z","created_by":"ubuntu","updated_at":"2026-02-16T05:25:15.257110585Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["diagnostics","performance","reliability","screen"],"dependencies":[{"issue_id":"bd-xzt.3.6","depends_on_id":"bd-xzt.2.5","type":"blocks","created_at":"2026-02-16T03:22:14.776702938Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.6","depends_on_id":"bd-xzt.2.7","type":"blocks","created_at":"2026-02-16T03:22:14.885881564Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.6","depends_on_id":"bd-xzt.3","type":"parent-child","created_at":"2026-02-16T03:19:47.676111504Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.3.7","title":"Complete cross-screen navigation model and command palette action catalog","description":"Background\nScreen implementations are incomplete until cross-screen navigation and global actions are coherent.\n\nWork\n- Implement tab/screen switching, focused-pane navigation, and breadcrumb/context state.\n- Register command palette actions for key workflows (jump to pressure hotspots, open explain detail, inspect ballast, search timeline).\n- Ensure action routing remains deterministic even during rapid refresh/input.\n\nAcceptance criteria\n- Operators can traverse major workflows without memorizing hidden key combos.\n- Command palette and direct key bindings remain consistent and conflict-free.\n- Navigation state survives refresh cycles without jarring resets.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T03:19:53.665652632Z","created_by":"ubuntu","updated_at":"2026-02-16T03:22:15.524294493Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["command-palette","navigation","screen","ux"],"dependencies":[{"issue_id":"bd-xzt.3.7","depends_on_id":"bd-xzt.2.6","type":"blocks","created_at":"2026-02-16T03:22:14.998087217Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.7","depends_on_id":"bd-xzt.3","type":"parent-child","created_at":"2026-02-16T03:19:53.665652632Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.7","depends_on_id":"bd-xzt.3.1","type":"blocks","created_at":"2026-02-16T03:22:15.096223284Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.7","depends_on_id":"bd-xzt.3.2","type":"blocks","created_at":"2026-02-16T03:22:15.199544407Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.7","depends_on_id":"bd-xzt.3.3","type":"blocks","created_at":"2026-02-16T03:22:15.310254140Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.7","depends_on_id":"bd-xzt.3.4","type":"blocks","created_at":"2026-02-16T03:22:15.413461189Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.7","depends_on_id":"bd-xzt.3.5","type":"blocks","created_at":"2026-02-16T03:22:15.524246353Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.3.8","title":"Accessibility and responsive hardening pass across all dashboard screens","description":"Background\nA high-density ops TUI must remain usable across terminal sizes and accessibility constraints.\n\nWork\n- Validate screen behavior at narrow/medium/wide terminal dimensions with stable fallbacks.\n- Ensure high contrast and no-color modes preserve semantic meaning and alert salience.\n- Minimize motion/distraction in critical incident scenarios while preserving orientation cues.\n\nAcceptance criteria\n- No screen becomes functionally unusable at supported terminal sizes.\n- Color is never the only channel conveying critical state.\n- Accessibility behavior is documented and covered by tests/snapshots where feasible.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T03:19:58.822119611Z","created_by":"ubuntu","updated_at":"2026-02-16T03:22:16.389656246Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["accessibility","no-color","responsive","ux"],"dependencies":[{"issue_id":"bd-xzt.3.8","depends_on_id":"bd-xzt.2.5","type":"blocks","created_at":"2026-02-16T03:22:15.622625064Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.8","depends_on_id":"bd-xzt.3","type":"parent-child","created_at":"2026-02-16T03:19:58.822119611Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.8","depends_on_id":"bd-xzt.3.1","type":"blocks","created_at":"2026-02-16T03:22:15.731726867Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.8","depends_on_id":"bd-xzt.3.2","type":"blocks","created_at":"2026-02-16T03:22:15.831787387Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.8","depends_on_id":"bd-xzt.3.3","type":"blocks","created_at":"2026-02-16T03:22:15.949530214Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.8","depends_on_id":"bd-xzt.3.4","type":"blocks","created_at":"2026-02-16T03:22:16.070432124Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.8","depends_on_id":"bd-xzt.3.5","type":"blocks","created_at":"2026-02-16T03:22:16.171448392Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.8","depends_on_id":"bd-xzt.3.6","type":"blocks","created_at":"2026-02-16T03:22:16.278908943Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.8","depends_on_id":"bd-xzt.3.7","type":"blocks","created_at":"2026-02-16T03:22:16.389603267Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.3.9","title":"Add incident workflow shortcuts (guided actions/playbook links) for high-pressure scenarios","description":"Background\nDuring incidents, operators need minimal-latency navigation to the right actions and evidence views.\n\nWork\n- Provide workflow shortcuts from alerts to relevant screens/panes (timeline, explainability, ballast, candidate review).\n- Add optional in-dashboard playbook hints/linkouts for recurring incident patterns.\n- Ensure shortcuts are keyboard-first and non-intrusive in calm periods.\n\nAcceptance criteria\n- Incident triage path length is reduced vs baseline manual navigation.\n- Shortcut actions are deterministic and easy to audit.\n- Feature can be disabled if operators prefer a minimal dashboard.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-16T03:24:48.064365558Z","created_by":"ubuntu","updated_at":"2026-02-16T03:25:20.303796064Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["incident-workflow","operations","screen","ux"],"dependencies":[{"issue_id":"bd-xzt.3.9","depends_on_id":"bd-xzt.3","type":"parent-child","created_at":"2026-02-16T03:24:48.064365558Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.9","depends_on_id":"bd-xzt.3.3","type":"blocks","created_at":"2026-02-16T03:25:20.086419877Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.9","depends_on_id":"bd-xzt.3.5","type":"blocks","created_at":"2026-02-16T03:25:20.194921427Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.3.9","depends_on_id":"bd-xzt.3.7","type":"blocks","created_at":"2026-02-16T03:25:20.303733477Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.4","title":"Track D: Verification matrix (unit, integration, snapshot, e2e, perf) with high-fidelity logging","description":"Purpose\nEstablish a comprehensive verification harness that proves the new TUI is correct, stable, performant, and operable under real pressure scenarios.\n\nScope\n- Granular unit tests for model/update/render helpers and adapter failure modes.\n- Integration tests for command semantics and state-file contracts.\n- E2E script expansion with deterministic assertions and rich per-case logs.\n- Performance/load tests and quality-gate orchestration via rch.\n\nWhy this matters\nA visual overhaul without deep tests is high-risk for this safety-critical tool. This track makes regressions cheap to detect and triage.\n\n## Success Criteria\n- Unit/integration/snapshot/e2e/stress/parity suites exist and run in reproducible quality gates.\n- Interactive behavior is testable via automated harnesses with detailed artifact capture.\n- Test logs are structured and actionable enough for rapid failure diagnosis.","status":"open","priority":0,"issue_type":"epic","created_at":"2026-02-16T03:17:37.393645201Z","created_by":"ubuntu","updated_at":"2026-02-16T03:30:38.908667009Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["e2e","quality","testing","tui"],"dependencies":[{"issue_id":"bd-xzt.4","depends_on_id":"bd-xzt","type":"parent-child","created_at":"2026-02-16T03:17:37.393645201Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":359,"issue_id":"bd-xzt.4","author":"Dicklesworthstone","text":"Verification philosophy\n\nThe old e2e script still contains a dashboard stub expectation; this overhaul is not done until real interactive dashboard behavior is e2e-validated with rich logs.\n\nTest stack expectations:\n- fast deterministic unit tests for state/adapters,\n- integration tests for command/state contracts,\n- snapshot tests for layout regressions,\n- e2e smoke + degraded-mode + exit-path checks,\n- stress/perf suites for long-session stability.\n\nIf a behavior cannot be asserted automatically, document exact manual validation steps and required artifacts.","created_at":"2026-02-16T03:22:59Z"}]}
{"id":"bd-xzt.4.1","title":"Add unit tests for model reducers, adapters, keymap logic, and render helpers","description":"Background\nReducer-heavy UI architecture is only reliable if state transitions and helper math are unit-tested exhaustively.\n\nWork\n- Add table-driven unit tests for model/update transitions and edge cases.\n- Add adapter tests for stale/missing/malformed data and fallback semantics.\n- Add tests for keymap resolution, command routing, and critical render helper behavior.\n\nAcceptance criteria\n- Unit coverage targets high-risk runtime modules introduced by the overhaul.\n- Regressions in state transitions and data mapping are caught before integration tests.\n- Tests are deterministic and fast enough for routine development loops.","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-16T03:20:07.538477135Z","created_by":"ubuntu","updated_at":"2026-02-16T03:36:00.291963100Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["runtime","tests","tui","unit"],"dependencies":[{"issue_id":"bd-xzt.4.1","depends_on_id":"bd-xzt.2.10","type":"blocks","created_at":"2026-02-16T03:36:00.291903839Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.1","depends_on_id":"bd-xzt.2.2","type":"blocks","created_at":"2026-02-16T03:22:16.487982730Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.1","depends_on_id":"bd-xzt.2.3","type":"blocks","created_at":"2026-02-16T03:22:16.600654064Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.1","depends_on_id":"bd-xzt.2.6","type":"blocks","created_at":"2026-02-16T03:22:16.709528411Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.1","depends_on_id":"bd-xzt.2.9","type":"blocks","created_at":"2026-02-16T03:25:19.819964936Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.1","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:20:07.538477135Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.4.10","title":"Add deterministic replay regression suite using recorded daemon/state/telemetry traces","description":"Background\nReplay-based testing catches subtle regressions in state interpretation and rendering decisions with real-world data patterns.\n\nWork\n- Define canonical trace fixtures (pressure transitions, stale state, degraded telemetry, ballast events, policy transitions).\n- Replay traces through adapters/runtime and assert stable derived view-model/output invariants.\n- Add fixture update policy and compatibility checks to avoid silent baseline drift.\n\nAcceptance criteria\n- Replay suite detects regressions in data interpretation without requiring live daemon runs.\n- Trace fixtures include both normal and failure/degraded scenarios.\n- Replay assertions are deterministic across environments.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T03:31:11.934275204Z","created_by":"ubuntu","updated_at":"2026-02-16T03:31:45.753673156Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["determinism","replay","telemetry","tests"],"dependencies":[{"issue_id":"bd-xzt.4.10","depends_on_id":"bd-xzt.2.3","type":"blocks","created_at":"2026-02-16T03:31:45.335577149Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.10","depends_on_id":"bd-xzt.2.4","type":"blocks","created_at":"2026-02-16T03:31:45.440410583Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.10","depends_on_id":"bd-xzt.2.9","type":"blocks","created_at":"2026-02-16T03:31:45.548860305Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.10","depends_on_id":"bd-xzt.3.1","type":"blocks","created_at":"2026-02-16T03:31:45.649579578Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.10","depends_on_id":"bd-xzt.3.3","type":"blocks","created_at":"2026-02-16T03:31:45.753622441Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.10","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:31:11.934275204Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.4.11","title":"Add property-based tests for reducer invariants, navigation consistency, and scheduler safety","description":"Background\nProperty-based tests complement examples by discovering edge-case sequences in stateful UI logic.\n\nWork\n- Define invariants for reducer state transitions (no invalid focus states, bounded queues, consistent mode transitions).\n- Add property-based generators for event streams and input sequences.\n- Assert scheduler/backpressure invariants under randomized stress patterns.\n\nAcceptance criteria\n- Invariant violations are reproducible with minimized counterexamples.\n- Property suite covers critical state-machine and scheduling logic.\n- Tests run within practical CI time budgets.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T03:31:11.997276929Z","created_by":"ubuntu","updated_at":"2026-02-16T03:31:46.066100016Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["invariants","property","runtime","tests"],"dependencies":[{"issue_id":"bd-xzt.4.11","depends_on_id":"bd-xzt.2.2","type":"blocks","created_at":"2026-02-16T03:31:45.855469826Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.11","depends_on_id":"bd-xzt.2.6","type":"blocks","created_at":"2026-02-16T03:31:45.960735438Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.11","depends_on_id":"bd-xzt.2.7","type":"blocks","created_at":"2026-02-16T03:31:46.066018072Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.11","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:31:11.997276929Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.4.12","title":"Define structured e2e artifact schema (trace IDs, frame dumps, stderr/stdout bundles, timing)","description":"Background\nRich logs are only valuable if consistently structured and easy to correlate across suites and failures.\n\nWork\n- Define canonical artifact schema for dashboard tests (trace IDs, command context, timestamps, frame captures, logs, assertions).\n- Implement shared helpers in test/e2e scripts to emit schema-compliant artifacts.\n- Add validation checks ensuring failing tests always emit minimum diagnostic payloads.\n\nAcceptance criteria\n- Every dashboard test failure includes a standardized, machine-readable artifact bundle.\n- Artifact naming/retention conventions are documented and enforced.\n- Operators can correlate failures across unit/integration/e2e with shared trace IDs.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-16T03:31:24.882751136Z","created_by":"ubuntu","updated_at":"2026-02-16T04:44:59.610882799Z","closed_at":"2026-02-16T04:44:59.610815724Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["artifacts","e2e","logging","observability"],"dependencies":[{"issue_id":"bd-xzt.4.12","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:31:24.882751136Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.12","depends_on_id":"bd-xzt.4.9","type":"blocks","created_at":"2026-02-16T03:31:46.169064300Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.4.13","title":"Implement legacy-vs-new dashboard parity harness against frozen contract matrix","description":"Background\nTo guarantee no feature loss, we need explicit automated parity checks between baseline and overhauled behavior.\n\nWork\n- Encode baseline contract matrix from Track A as executable parity assertions.\n- Compare key outputs/behaviors across legacy and new dashboard modes under controlled fixtures.\n- Flag intentional deltas separately from regressions to keep parity signal honest.\n\nAcceptance criteria\n- Parity harness catches contract regressions before release signoff.\n- Intentional behavior changes require explicit annotation and approval.\n- Harness outputs clear diff artifacts for rapid triage.","status":"in_progress","priority":0,"issue_type":"task","created_at":"2026-02-16T03:31:24.983617053Z","created_by":"ubuntu","updated_at":"2026-02-16T05:19:27.391535125Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["contracts","parity","regression","tests"],"dependencies":[{"issue_id":"bd-xzt.4.13","depends_on_id":"bd-xzt.1.1","type":"blocks","created_at":"2026-02-16T03:31:46.275327330Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.13","depends_on_id":"bd-xzt.2.1","type":"blocks","created_at":"2026-02-16T03:31:46.380538280Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.13","depends_on_id":"bd-xzt.2.3","type":"blocks","created_at":"2026-02-16T03:31:46.482911859Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.13","depends_on_id":"bd-xzt.3.1","type":"blocks","created_at":"2026-02-16T03:31:46.597517133Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.13","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:31:24.983617053Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.4.14","title":"Add failure-injection test suite for state/log adapter degradations and recovery","description":"## Background\nDashboard reliability must be proven under partial subsystem failure, not assumed. Adapter degradations (state corruption, sqlite/jsonl errors, permissions) are high-risk paths that require explicit failure injection and recovery assertions.\n\n## Goals\n- Build deterministic failure-injection coverage for dashboard data adapters and preference persistence boundaries.\n- Verify degraded-mode UX communicates data quality/state clearly while preserving core operator controls.\n- Verify recovery transitions when faults clear, including state reconciliation and indicator reset behavior.\n\n## Fault Matrix Scope\n- Daemon state source: missing file, stale file, malformed JSON, incompatible schema versions.\n- Telemetry source: sqlite unavailable/locked, query failure, JSONL append/read failure.\n- Preferences source: corrupt preference payload, permission denied, atomic write interruption.\n- Environment failures: read-only filesystem paths, transient permission flips, delayed IO surface.\n\n## Test + Logging Requirements\n- Unit tests: adapter error mapping, retry/backoff policy, degradation-state reducers.\n- Integration tests: mixed-fault scenarios across state + telemetry + preference adapters.\n- E2E scripts: fault injection drills with scripted operator recovery actions and expected UI markers.\n- Logging artifacts per scenario: scenario_id, injection_point, expected_mode, observed_mode, transition_timestamps, trace_id.\n\n## Acceptance Criteria\n- Adapter/runtime degradations are deterministic, operator-visible, and non-panicking.\n- Recovery transitions are validated end-to-end (including indicator clear and data freshness recovery).\n- Failure-injection suite is part of quality gates and documented in verification runbooks.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-16T03:33:59.256072615Z","created_by":"ubuntu","updated_at":"2026-02-16T05:24:08.492248556Z","closed_at":"2026-02-16T05:24:08.492165881Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["adapters","failure-injection","reliability","tests"],"dependencies":[{"issue_id":"bd-xzt.4.14","depends_on_id":"bd-xzt.2.10","type":"blocks","created_at":"2026-02-16T03:36:00.060316792Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.14","depends_on_id":"bd-xzt.2.3","type":"blocks","created_at":"2026-02-16T03:35:59.725172952Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.14","depends_on_id":"bd-xzt.2.4","type":"blocks","created_at":"2026-02-16T03:35:59.836462831Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.14","depends_on_id":"bd-xzt.2.9","type":"blocks","created_at":"2026-02-16T03:35:59.955931618Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.14","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:33:59.256072615Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":366,"issue_id":"bd-xzt.4.14","author":"Dicklesworthstone","text":"Dependency rationale: bd-xzt.4.14 depends on state/telemetry/schema/preferences layers (bd-xzt.2.3, bd-xzt.2.4, bd-xzt.2.9, bd-xzt.2.10). This forces fault-injection coverage to span the full adapter surface, including preference corruption and recovery, before runbook and docs signoff.","created_at":"2026-02-16T03:37:42Z"}]}
{"id":"bd-xzt.4.2","title":"Expand integration tests for dashboard command semantics and state-file contract behavior","description":"Background\nCurrent integration coverage does not adequately protect dashboard runtime behavior.\n\nWork\n- Add integration tests for dashboard command execution path and argument semantics.\n- Verify stale-state, missing-state, and fallback behavior through realistic fixtures.\n- Verify legacy constraints remain enforced (refresh floor, dashboard JSON rejection, safe teardown behavior).\n\nAcceptance criteria\n- Integration tests fail on contract regressions that would affect operators.\n- Tests are explicit about expected behavior for degraded data conditions.\n- Coverage includes both happy-path and critical error-path scenarios.","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-16T03:20:12.518810534Z","created_by":"ubuntu","updated_at":"2026-02-16T03:36:00.530847354Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli","contracts","integration","tests"],"dependencies":[{"issue_id":"bd-xzt.4.2","depends_on_id":"bd-xzt.1.1","type":"blocks","created_at":"2026-02-16T03:22:16.934927024Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.2","depends_on_id":"bd-xzt.2.1","type":"blocks","created_at":"2026-02-16T03:22:17.048149560Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.2","depends_on_id":"bd-xzt.2.10","type":"blocks","created_at":"2026-02-16T03:36:00.411921684Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.2","depends_on_id":"bd-xzt.2.3","type":"blocks","created_at":"2026-02-16T03:22:17.156281157Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.2","depends_on_id":"bd-xzt.2.8","type":"blocks","created_at":"2026-02-16T03:22:17.259230113Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.2","depends_on_id":"bd-xzt.2.9","type":"blocks","created_at":"2026-02-16T03:25:19.984172474Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.2","depends_on_id":"bd-xzt.3.1","type":"blocks","created_at":"2026-02-16T03:22:17.369315457Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.2","depends_on_id":"bd-xzt.3.11","type":"blocks","created_at":"2026-02-16T03:36:00.530804805Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.2","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:20:12.518810534Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.4.3","title":"Add snapshot/golden tests for key screens across terminal sizes and color modes","description":"Background\nComplex TUI layouts regress subtly; snapshots provide low-friction guardrails for visual structure drift.\n\nWork\n- Add snapshot/golden fixtures for overview, timeline, explainability, and ballast screens.\n- Cover narrow/medium/wide dimensions and no-color/high-contrast variants where practical.\n- Add fixture review guidance to keep snapshots maintainable and meaningful.\n\nAcceptance criteria\n- Snapshot diffs make layout regressions obvious and actionable.\n- Tests avoid brittle noise by stabilizing dynamic fields where appropriate.\n- Snapshot suite runs as part of standard quality gates.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T03:20:18.913753308Z","created_by":"ubuntu","updated_at":"2026-02-16T03:36:00.647056300Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["accessibility","layout","snapshot","tests"],"dependencies":[{"issue_id":"bd-xzt.4.3","depends_on_id":"bd-xzt.3.1","type":"blocks","created_at":"2026-02-16T03:22:17.472568572Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.3","depends_on_id":"bd-xzt.3.11","type":"blocks","created_at":"2026-02-16T03:36:00.647000506Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.3","depends_on_id":"bd-xzt.3.2","type":"blocks","created_at":"2026-02-16T03:22:17.587026801Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.3","depends_on_id":"bd-xzt.3.3","type":"blocks","created_at":"2026-02-16T03:22:17.705991695Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.3","depends_on_id":"bd-xzt.3.5","type":"blocks","created_at":"2026-02-16T03:22:17.812690069Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.3","depends_on_id":"bd-xzt.3.8","type":"blocks","created_at":"2026-02-16T03:22:17.918633500Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.3","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:20:18.913753308Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.4.4","title":"Overhaul scripts/e2e_test.sh dashboard section with real interactive coverage and rich case logs","description":"Background\nThe current e2e dashboard coverage still contains stub-era assumptions; this must be upgraded for the new cockpit.\n\nWork\n- Replace dashboard stub checks with real smoke/behavior assertions against the new runtime.\n- Add deterministic checks for startup, render loop liveness, key-driven exit, and degraded-mode indicators.\n- Ensure per-case logs capture command, exit status, elapsed time, and relevant stdout/stderr artifacts.\n\nAcceptance criteria\n- E2E suite validates real dashboard behavior instead of placeholder output.\n- Log artifacts are detailed enough to diagnose failures without rerunning immediately.\n- E2E remains CI/operator friendly (clear pass/fail summary and artifact locations).","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-16T03:20:25.526304684Z","created_by":"ubuntu","updated_at":"2026-02-16T03:31:46.806370117Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["dashboard","e2e","logging","tests"],"dependencies":[{"issue_id":"bd-xzt.4.4","depends_on_id":"bd-xzt.2.8","type":"blocks","created_at":"2026-02-16T03:22:18.033061302Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.4","depends_on_id":"bd-xzt.3.1","type":"blocks","created_at":"2026-02-16T03:22:18.214221281Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.4","depends_on_id":"bd-xzt.3.7","type":"blocks","created_at":"2026-02-16T03:22:18.321482759Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.4","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:20:25.526304684Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.4","depends_on_id":"bd-xzt.4.12","type":"blocks","created_at":"2026-02-16T03:31:46.806330092Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.4","depends_on_id":"bd-xzt.4.9","type":"blocks","created_at":"2026-02-16T03:31:46.701766293Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.4.5","title":"Add stress/performance tests for long-running dashboard sessions and bursty telemetry","description":"Background\nThe dashboard will run for long periods during active agent workloads; perf regressions must be caught proactively.\n\nWork\n- Add stress scenarios for high refresh frequency, large event streams, and intermittent adapter failures.\n- Measure/assert frame-time, CPU usage envelope, and memory stability against budgets.\n- Capture performance traces/log summaries suitable for regression comparison over time.\n\nAcceptance criteria\n- Stress suite catches sustained-loop regressions that unit tests miss.\n- Performance metrics are compared against explicit thresholds from acceptance gates.\n- Results are logged in a format that supports trend tracking.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T03:20:31.849521323Z","created_by":"ubuntu","updated_at":"2026-02-16T03:22:18.722472277Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["dashboard","performance","stress","tests"],"dependencies":[{"issue_id":"bd-xzt.4.5","depends_on_id":"bd-xzt.2.7","type":"blocks","created_at":"2026-02-16T03:22:18.503199700Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.5","depends_on_id":"bd-xzt.2.8","type":"blocks","created_at":"2026-02-16T03:22:18.606459949Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.5","depends_on_id":"bd-xzt.3.6","type":"blocks","created_at":"2026-02-16T03:22:18.722421882Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.5","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:20:31.849521323Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.4.6","title":"Create quality-gate runbook for rch check/clippy/test + dashboard e2e/perf suites","description":"Background\nA massive overhaul needs one authoritative quality-gate sequence for local and CI execution.\n\nWork\n- Define ordered gate execution using required remote compilation flow (`rch exec` for CPU-heavy checks).\n- Include dashboard unit/integration/snapshot/e2e/stress suites in gate definition.\n- Define artifact capture and failure triage expectations for each gate stage.\n\nAcceptance criteria\n- Gate sequence is explicit, reproducible, and automation-friendly.\n- Failures identify which quality dimension regressed (correctness, UX contract, performance, reliability).\n- Gate policy is referenced by rollout and release tasks.","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-16T03:20:38.653732831Z","created_by":"ubuntu","updated_at":"2026-02-16T03:36:00.175138061Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["ci","quality-gates","rch","tests"],"dependencies":[{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.1.5","type":"blocks","created_at":"2026-02-16T03:22:19.070059689Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:20:38.653732831Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4.1","type":"blocks","created_at":"2026-02-16T03:22:19.170780344Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4.10","type":"blocks","created_at":"2026-02-16T03:31:47.333582804Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4.11","type":"blocks","created_at":"2026-02-16T03:31:47.433800158Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4.12","type":"blocks","created_at":"2026-02-16T03:31:47.540964023Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4.13","type":"blocks","created_at":"2026-02-16T03:31:47.650148871Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4.14","type":"blocks","created_at":"2026-02-16T03:36:00.175097294Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4.2","type":"blocks","created_at":"2026-02-16T03:22:19.270149219Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4.3","type":"blocks","created_at":"2026-02-16T03:22:19.372141354Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4.4","type":"blocks","created_at":"2026-02-16T03:22:19.469537937Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4.5","type":"blocks","created_at":"2026-02-16T03:22:19.573441390Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4.7","type":"blocks","created_at":"2026-02-16T03:22:19.671172770Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4.8","type":"blocks","created_at":"2026-02-16T03:25:20.950881846Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.6","depends_on_id":"bd-xzt.4.9","type":"blocks","created_at":"2026-02-16T03:31:47.227783523Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.4.7","title":"Add fallback/rollback verification matrix (legacy path toggle, degraded data, terminal recovery)","description":"Background\nRollout safety depends on proven escape hatches, not assumptions.\n\nWork\n- Define and test scenarios for legacy dashboard toggle, degraded telemetry, stale state, and runtime failure recovery.\n- Verify rollback actions restore expected operator capabilities without manual surgery.\n- Ensure rollback testing includes terminal-state integrity checks.\n\nAcceptance criteria\n- Rollback procedures are validated by automated tests or reproducible scripts.\n- Safety fallback behavior is exercised under realistic failure triggers.\n- Rollback verification is part of final release gates.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T03:20:44.480957310Z","created_by":"ubuntu","updated_at":"2026-02-16T03:24:15.368460510Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["fallback","rollback","safety","tests"],"dependencies":[{"issue_id":"bd-xzt.4.7","depends_on_id":"bd-xzt.2.1","type":"blocks","created_at":"2026-02-16T03:24:15.368413783Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.7","depends_on_id":"bd-xzt.2.8","type":"blocks","created_at":"2026-02-16T03:24:15.266855880Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.7","depends_on_id":"bd-xzt.3.7","type":"blocks","created_at":"2026-02-16T03:24:15.165194684Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.7","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:20:44.480957310Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.7","depends_on_id":"bd-xzt.5.3","type":"blocks","created_at":"2026-02-16T03:24:15.063581819Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.4.8","title":"Add scenario-driven dashboard e2e drills (pressure escalation, ballast response, explainability traceability)","description":"Background\nSimple smoke tests are insufficient; we need realistic scenario drills that mirror how operators use SBH under stress.\n\nWork\n- Add e2e scenarios that simulate pressure transitions and verify dashboard state transitions.\n- Validate ballast-related dashboard signals against expected command/runtime behavior.\n- Validate explainability trace linkage from incident event to rationale panes/artifacts.\n\nAcceptance criteria\n- Scenario suite catches cross-component regressions (monitor/control/scanner/logging/dashboard integration).\n- Drill logs are rich enough for post-mortem use.\n- Scenario outcomes are deterministic enough for CI usage or clearly documented if environment-sensitive.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T03:24:54.357738567Z","created_by":"ubuntu","updated_at":"2026-02-16T03:36:00.764367469Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["e2e","incident","scenarios","tests"],"dependencies":[{"issue_id":"bd-xzt.4.8","depends_on_id":"bd-xzt.3.1","type":"blocks","created_at":"2026-02-16T03:25:20.409922628Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.8","depends_on_id":"bd-xzt.3.11","type":"blocks","created_at":"2026-02-16T03:36:00.764318598Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.8","depends_on_id":"bd-xzt.3.3","type":"blocks","created_at":"2026-02-16T03:25:20.519617120Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.8","depends_on_id":"bd-xzt.3.5","type":"blocks","created_at":"2026-02-16T03:25:20.624036499Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.8","depends_on_id":"bd-xzt.3.9","type":"blocks","created_at":"2026-02-16T03:25:20.732405019Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.8","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:24:54.357738567Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.8","depends_on_id":"bd-xzt.4.10","type":"blocks","created_at":"2026-02-16T03:31:47.124180833Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.8","depends_on_id":"bd-xzt.4.12","type":"blocks","created_at":"2026-02-16T03:31:47.015564429Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.8","depends_on_id":"bd-xzt.4.4","type":"blocks","created_at":"2026-02-16T03:25:20.840931235Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.8","depends_on_id":"bd-xzt.4.9","type":"blocks","created_at":"2026-02-16T03:31:46.908468701Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.4.9","title":"Build PTY-driven dashboard interaction harness for automated keyflow tests","description":"Background\nReliable automated testing of full-screen terminal apps requires a PTY harness that can drive input and capture render behavior.\n\nWork\n- Build or integrate a PTY harness that launches `sbh dashboard` and injects key sequences deterministically.\n- Capture terminal output/frame snapshots with timing metadata suitable for assertions.\n- Provide helpers for common flows (startup, navigation, command palette open/close, quit paths).\n\nAcceptance criteria\n- Interactive flows can be tested headlessly in CI-like environments.\n- Harness captures enough context to debug flaky interaction failures.\n- Harness APIs are reusable by smoke and scenario e2e suites.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-16T03:31:11.907323026Z","created_by":"ubuntu","updated_at":"2026-02-16T04:34:33.869598047Z","closed_at":"2026-02-16T04:34:33.869488842Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["e2e","interaction","pty","tests"],"dependencies":[{"issue_id":"bd-xzt.4.9","depends_on_id":"bd-xzt.2.1","type":"blocks","created_at":"2026-02-16T03:31:45.119965786Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.9","depends_on_id":"bd-xzt.2.8","type":"blocks","created_at":"2026-02-16T03:31:45.226002762Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.4.9","depends_on_id":"bd-xzt.4","type":"parent-child","created_at":"2026-02-16T03:31:11.907323026Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.5","title":"Track E: Rollout, documentation, migration safety, and operator adoption","description":"Purpose\nShip the overhaul safely: clear operator docs, migration toggles, fallback strategy, and release criteria that minimize incident risk.\n\nScope\n- Update README + operator/testing docs for new dashboard workflows.\n- Provide rollout gates and rollback path (legacy dashboard switch + kill switch behavior).\n- Capture final parity evidence and handoff notes for future maintainers.\n\nWhy this matters\nEven a technically excellent TUI fails if operators cannot trust rollout behavior or quickly recover during incidents.\n\n## Success Criteria\n- Rollout controls, rollback procedures, and go/no-go signoff are evidence-backed and reproducible.\n- Operator and maintainer docs match actual runtime/test behavior at release time.\n- Post-release monitoring and deprecation policy are explicit and operationally safe.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-16T03:17:42.819138846Z","created_by":"ubuntu","updated_at":"2026-02-16T03:30:39.013941168Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["docs","operations","rollout","tui"],"dependencies":[{"issue_id":"bd-xzt.5","depends_on_id":"bd-xzt","type":"parent-child","created_at":"2026-02-16T03:17:42.819138846Z","created_by":"ubuntu","metadata":"{}","thread_id":""}],"comments":[{"id":360,"issue_id":"bd-xzt.5","author":"Dicklesworthstone","text":"Rollout posture\n\nDefault-switch decision must be evidence-driven and reversible.\n\nMinimum release expectations:\n- objective pass on acceptance/perf/error budgets,\n- validated fallback and rollback controls,\n- operator docs updated before cutover,\n- post-release monitoring defined in advance.\n\nDo not accept “we can fix forward” as the primary mitigation for operator-facing regressions.","created_at":"2026-02-16T03:23:04Z"}]}
{"id":"bd-xzt.5.1","title":"Update README/operator docs with new dashboard workflows, screens, and keybindings","description":"Background\nThe overhaul changes how operators interact with SBH in real time; docs must match reality at launch.\n\nWork\n- Update README dashboard sections with new capabilities and usage patterns.\n- Add screen-by-screen operator guidance for core incident workflows.\n- Document keybindings, command palette usage, and degraded-mode interpretation.\n\nAcceptance criteria\n- Operators can perform core workflows using docs alone.\n- Documentation reflects final command/runtime behavior exactly.\n- Troubleshooting entries include new dashboard-specific failure modes.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T03:20:50.514090943Z","created_by":"ubuntu","updated_at":"2026-02-16T03:36:00.994979951Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["docs","operators","readme","tui"],"dependencies":[{"issue_id":"bd-xzt.5.1","depends_on_id":"bd-xzt.3.10","type":"blocks","created_at":"2026-02-16T03:31:47.759012077Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.1","depends_on_id":"bd-xzt.3.11","type":"blocks","created_at":"2026-02-16T03:36:00.994935809Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.1","depends_on_id":"bd-xzt.3.8","type":"blocks","created_at":"2026-02-16T03:22:19.770182473Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.1","depends_on_id":"bd-xzt.3.9","type":"blocks","created_at":"2026-02-16T03:25:21.181929493Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.1","depends_on_id":"bd-xzt.5","type":"parent-child","created_at":"2026-02-16T03:20:50.514090943Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.1","depends_on_id":"bd-xzt.5.3","type":"blocks","created_at":"2026-02-16T03:22:19.871389038Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.5.2","title":"Update testing/logging docs for new dashboard verification and artifact expectations","description":"Background\nFuture maintainers need a single source of truth for how to validate and debug dashboard behavior.\n\nWork\n- Update docs/testing-and-logging.md with new unit/integration/snapshot/e2e/perf coverage map.\n- Document required log artifacts and naming conventions for failing dashboard tests.\n- Include quick triage guidance for common failure classes.\n\nAcceptance criteria\n- Test and logging docs align with implemented quality gates.\n- A maintainer can run/interpret the dashboard verification stack without tribal knowledge.\n- Documentation is explicit about remote compilation requirements for heavy checks.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T03:20:55.391435781Z","created_by":"ubuntu","updated_at":"2026-02-16T03:36:01.100804480Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["docs","e2e","logging","testing"],"dependencies":[{"issue_id":"bd-xzt.5.2","depends_on_id":"bd-xzt.4.12","type":"blocks","created_at":"2026-02-16T03:31:47.859812993Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.2","depends_on_id":"bd-xzt.4.13","type":"blocks","created_at":"2026-02-16T03:31:47.964172259Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.2","depends_on_id":"bd-xzt.4.14","type":"blocks","created_at":"2026-02-16T03:36:01.100755538Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.2","depends_on_id":"bd-xzt.4.4","type":"blocks","created_at":"2026-02-16T03:22:19.975415321Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.2","depends_on_id":"bd-xzt.4.6","type":"blocks","created_at":"2026-02-16T03:22:20.091915331Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.2","depends_on_id":"bd-xzt.4.8","type":"blocks","created_at":"2026-02-16T03:25:21.068165343Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.2","depends_on_id":"bd-xzt.5","type":"parent-child","created_at":"2026-02-16T03:20:55.391435781Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.5.3","title":"Define and implement phased rollout controls (default switch, legacy fallback flag, kill switch)","description":"Background\nA hard cutover without guard rails is unnecessary risk for an operator-critical interface.\n\nWork\n- Define phased rollout approach with explicit default-switch criteria.\n- Ensure legacy fallback control and emergency kill switch behavior are deterministic and documented.\n- Integrate rollout controls with test gates and rollback verification.\n\nAcceptance criteria\n- Operators can reliably switch between new and fallback behavior during incidents.\n- Control semantics are unambiguous and tested.\n- Rollout progression requires objective evidence from verification track.","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-16T03:21:00.621961762Z","created_by":"ubuntu","updated_at":"2026-02-16T03:31:48.174470458Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["fallback","operations","rollout","safety"],"dependencies":[{"issue_id":"bd-xzt.5.3","depends_on_id":"bd-xzt.2.1","type":"blocks","created_at":"2026-02-16T03:31:48.069699070Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.3","depends_on_id":"bd-xzt.2.8","type":"blocks","created_at":"2026-02-16T03:31:48.174418060Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.3","depends_on_id":"bd-xzt.3.7","type":"blocks","created_at":"2026-02-16T03:22:20.189620923Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.3","depends_on_id":"bd-xzt.5","type":"parent-child","created_at":"2026-02-16T03:21:00.621961762Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.5.4","title":"Run final parity + quality signoff and publish go/no-go decision artifact","description":"Background\nBefore locking in the new dashboard as default, we need a final evidence-based release decision.\n\nWork\n- Execute full acceptance and quality-gate matrix.\n- Produce parity checklist evidence for baseline contracts and upgraded features.\n- Publish go/no-go summary with unresolved risks, mitigations, and explicit owner signoff.\n\nAcceptance criteria\n- Go/no-go decision cites concrete evidence, not intuition.\n- Any residual risk is documented with an operational mitigation plan.\n- Decision artifact is archived where future maintainers can locate it quickly.","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-16T03:21:08.190524195Z","created_by":"ubuntu","updated_at":"2026-02-16T03:31:48.402802842Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["parity","quality","release","signoff"],"dependencies":[{"issue_id":"bd-xzt.5.4","depends_on_id":"bd-xzt.3.10","type":"blocks","created_at":"2026-02-16T03:31:48.402759871Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.4","depends_on_id":"bd-xzt.4.13","type":"blocks","created_at":"2026-02-16T03:31:48.285232087Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.4","depends_on_id":"bd-xzt.4.6","type":"blocks","created_at":"2026-02-16T03:22:20.413887226Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.4","depends_on_id":"bd-xzt.5","type":"parent-child","created_at":"2026-02-16T03:21:08.190524195Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.4","depends_on_id":"bd-xzt.5.1","type":"blocks","created_at":"2026-02-16T03:22:20.525115910Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.4","depends_on_id":"bd-xzt.5.2","type":"blocks","created_at":"2026-02-16T03:22:20.641309958Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.4","depends_on_id":"bd-xzt.5.3","type":"blocks","created_at":"2026-02-16T03:22:20.752382520Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.5.5","title":"Define post-rollout monitoring, incident playbook updates, and maintainer handoff package","description":"Background\nSustained reliability requires clear post-release observability and ownership transfer artifacts.\n\nWork\n- Define post-rollout monitoring signals and alert thresholds for dashboard health/regressions.\n- Update incident playbook snippets to incorporate new cockpit workflows.\n- Produce maintainer handoff notes (architecture map, known limitations, next improvements).\n\nAcceptance criteria\n- Post-release monitoring can detect and triage dashboard regressions quickly.\n- Incident runbooks reflect the new operator surface.\n- Handoff package reduces future archaeology time for contributors.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-16T03:21:13.497770738Z","created_by":"ubuntu","updated_at":"2026-02-16T03:31:48.506291077Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["handoff","monitoring","operations","post-release"],"dependencies":[{"issue_id":"bd-xzt.5.5","depends_on_id":"bd-xzt.3.10","type":"blocks","created_at":"2026-02-16T03:31:48.506235193Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.5","depends_on_id":"bd-xzt.5","type":"parent-child","created_at":"2026-02-16T03:21:13.497770738Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.5","depends_on_id":"bd-xzt.5.4","type":"blocks","created_at":"2026-02-16T03:22:20.855039519Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xzt.5.6","title":"Decide legacy dashboard code deprecation path and long-term fallback retention policy","description":"Background\nAfter migration, we need a deliberate decision about how long to retain legacy dashboard code and switches.\n\nWork\n- Define criteria for removing vs retaining legacy dashboard implementation.\n- Evaluate maintenance/security cost of long-lived fallback paths.\n- Document final deprecation timeline and cleanup tasks if removal is approved.\n\nAcceptance criteria\n- Legacy retention/removal decision is explicit and justified.\n- Maintenance burden and risk tradeoffs are documented for future teams.\n- If removal is chosen, cleanup plan avoids abrupt loss of incident recovery options.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-16T03:24:59.565116350Z","created_by":"ubuntu","updated_at":"2026-02-16T03:31:48.629116668Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["deprecation","legacy","maintenance","rollout"],"dependencies":[{"issue_id":"bd-xzt.5.6","depends_on_id":"bd-xzt.4.13","type":"blocks","created_at":"2026-02-16T03:31:48.629062096Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.6","depends_on_id":"bd-xzt.5","type":"parent-child","created_at":"2026-02-16T03:24:59.565116350Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.6","depends_on_id":"bd-xzt.5.3","type":"blocks","created_at":"2026-02-16T03:25:21.294734758Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.6","depends_on_id":"bd-xzt.5.4","type":"blocks","created_at":"2026-02-16T03:25:21.404493199Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-xzt.5.6","depends_on_id":"bd-xzt.5.5","type":"blocks","created_at":"2026-02-16T03:25:21.517414061Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-z0j","title":"Set restrictive permissions on state.json temp files","description":"state.json temp files created during atomic writes don't set restrictive file permissions. On multi-user systems the daemon state could be readable by other users. Fix: set 0o600 permissions on temp files before rename.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-02-15T22:50:35.590610947Z","created_by":"ubuntu","updated_at":"2026-02-15T22:58:59.046101709Z","closed_at":"2026-02-15T22:58:59.046015017Z","source_repo":".","compaction_level":0,"original_size":0}
